<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS DevOps Study App</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #f5f5f5; }
        .container { max-width: 900px; margin: 0 auto; padding: 20px; }
        .header { background: #232f3e; color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; }
        .progress-bar { background: #ddd; height: 10px; border-radius: 5px; margin: 10px 0; }
        .progress { background: #ff9900; height: 100%; border-radius: 5px; transition: width 0.3s; }
        .question-card { background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-bottom: 20px; }
        .question-text { font-size: 18px; line-height: 1.6; margin-bottom: 20px; }
        .question-type { background: #e3f2fd; color: #1976d2; padding: 8px 16px; border-radius: 20px; font-size: 14px; font-weight: bold; margin-bottom: 15px; display: inline-block; }
        .options { margin: 20px 0; }
        .option { background: #f8f9fa; border: 2px solid #e9ecef; padding: 15px; margin: 10px 0; border-radius: 8px; cursor: pointer; transition: all 0.3s; position: relative; }
        .option:hover { border-color: #ff9900; }
        .option.selected { border-color: #ff9900; background: #fff3cd; }
        .option.correct { border-color: #28a745; background: #d4edda; }
        .option.incorrect { border-color: #dc3545; background: #f8d7da; }
        .option.partial { border-color: #ffc107; background: #fff3cd; }
        .option-checkbox { position: absolute; right: 15px; top: 50%; transform: translateY(-50%); width: 20px; height: 20px; }
        .controls { display: flex; gap: 15px; justify-content: center; margin-top: 20px; }
        .btn { padding: 12px 24px; border: none; border-radius: 6px; cursor: pointer; font-size: 16px; transition: all 0.3s; }
        .btn-primary { background: #ff9900; color: white; }
        .btn-primary:hover { background: #e68900; }
        .btn-secondary { background: #6c757d; color: white; }
        .btn-secondary:hover { background: #545b62; }
        .btn:disabled { background: #ccc; cursor: not-allowed; }
        .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px; }
        .stat-card { background: white; padding: 20px; border-radius: 8px; text-align: center; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        .stat-number { font-size: 24px; font-weight: bold; color: #ff9900; }
        .review-section { background: white; padding: 20px; border-radius: 10px; margin-top: 20px; }
        .wrong-answer { background: #fff3cd; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #ffc107; }
        .hidden { display: none; }
        .explanation { margin-top: 20px; padding: 15px; border-radius: 8px; }
        .explanation.correct { background: #d4edda; border-left: 4px solid #28a745; }
        .explanation.incorrect { background: #f8d7da; border-left: 4px solid #dc3545; }
        .explanation.partial { background: #fff3cd; border-left: 4px solid #ffc107; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üöÄ AWS DevOps Professional Study App</h1>
            <div class="progress-bar">
                <div class="progress" id="progressBar"></div>
            </div>
            <p>Ng√†y <span id="currentDay">3</span> - C√¢u <span id="currentQuestion">1</span>/<span id="totalQuestions">0</span></p>
        </div>

        <div class="stats">
            <div class="stat-card">
                <div class="stat-number" id="correctCount">0</div>
                <div>C√¢u ƒë√∫ng</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="wrongCount">0</div>
                <div>C√¢u sai</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="accuracy">0%</div>
                <div>ƒê·ªô ch√≠nh x√°c</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="timeSpent">0:00</div>
                <div>Th·ªùi gian</div>
            </div>
        </div>

        <div id="studyMode" class="question-card">
            <div class="question-type" id="questionType">Single Choice</div>
            <div class="question-text" id="questionText">
                ƒêang t·∫£i c√¢u h·ªèi...
            </div>
            <div class="options" id="optionsContainer">
                <!-- Options will be loaded here -->
            </div>
            <div class="controls">
                <button class="btn btn-secondary" onclick="previousQuestion()">‚¨ÖÔ∏è C√¢u tr∆∞·ªõc</button>
                <button class="btn btn-primary" onclick="submitAnswer()" id="submitBtn" disabled>X√°c nh·∫≠n</button>
                <button class="btn btn-secondary" onclick="nextQuestion()" id="nextBtn" disabled>C√¢u ti·∫øp ‚û°Ô∏è</button>
            </div>
        </div>

        <div id="reviewMode" class="review-section hidden">
            <h2>üìä K·∫øt qu·∫£ h·ªçc t·∫≠p</h2>
            <div id="reviewStats"></div>
            <div id="wrongAnswers"></div>
            <div class="controls">
                <button class="btn btn-primary" onclick="restartStudy()">üîÑ H·ªçc l·∫°i</button>
                <button class="btn btn-secondary" onclick="exportResults()">üíæ Xu·∫•t k·∫øt qu·∫£</button>
            </div>
        </div>
    </div>

    <script>
        // Sample questions with both single and multiple choice
        let questions = [
    {
        "id": 1,
        "text": "A company uses AWS Directory Service for Microsoft Active Directory as its identity provider (IdP). The company requires all infrastructure to be defined and deployed by AWS CloudFormation.A DevOps engineer needs to create a fleet of Windows-based Amazon EC2 instances to host an application. The DevOps engineer has created a CloudFormation template that contains an EC2 launch template, IAM role, EC2 security group, and EC2 Auto Scaling group. The DevOps engineer must implement a solution that joins all EC2 instances to the domain of the AWS Managed Microsoft AD directory.Which solution will meet these requirements with the MOST operational efficiency?",
        "options": [
            "In the CloudFormation template, update the launch template to include specific tags that propagate on launch. Create an AWS::SSM::Association resource to associate the AWS-JoinDirectoryServiceDomain Automation runbook with the EC2 instances that have the specified tags. Define the required parameters to join the AWS Managed Microsoft AD directory. Attach the AmazonSSMManagedInstanceCore and AmazonSSMDirectoryServiceAccess AWS managed policies to the IAM role that the EC2 instances use.",
            "In the CloudFormation template, create an AWS::SSM::Document resource that joins the EC2 instance to the AWS Managed Microsoft AD domain by using the parameters for the existing directory. Update the launch template to include the SSMAssociation property to use the new SSM document. Attach the AmazonSSMManagedInstanceCore and AmazonSSMDirectoryServiceAccess AWS managed policies to the IAM role that the EC2 instances use.",
            "Store the existing AWS Managed Microsoft AD domain administrator credentials in AWS Secrets Manager. In the CloudFormation template, update the EC2 launch template to include user data. Configure the user data to pull the administrator credentials from Secrets Manager and to join the AWS Managed Microsoft AD domain. Attach the AmazonSSMManagedInstanceCore and SecretsManagerReadWrite AWS managed policies to the IAM role that the EC2 instances use.",
            "Store the existing AWS Managed Microsoft AD domain connection details in AWS Secrets Manager. In the CloudFormation template, create an AWS::SSM::Association resource to associate the AWS-CreateManagedWindowsInstanceWithApproval Automation runbook with the EC2 Auto Scaling group. Pass the ARNs for the parameters from Secrets Manager to join the domain. Attach the AmazonSSMDirectoryServiceAccess and SecretsManagerReadWrite AWS managed policies to the IAM role that the EC2 instances use."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 2,
        "text": "A company has an AWS CodeDeploy application. The application has a deployment group that uses a single tag group to identify instances for the deployment of Application. The single tag group configuration identifies instances that have Environment=Production and Name=ApplicationA tags for the deployment of ApplicationA.The company launches an additional Amazon EC2 instance with Department=Marketing, Environment=Production, and Name=ApplicationB tags. On the next CodeDeploy deployment of Application, the additional instance has ApplicationA installed on it. A DevOps engineer needs to configure the existing deployment group to prevent ApplicationA from being installed on the additional instance.Which solution will meet these requirements?",
        "options": [
            "Change the current single tag group to include the Department=Marketing, Environment=production, and Name=ApplicationA tags.",
            "Change the current single tag group to include only the Environment=Production tag. Add another single tag group that includes only the Name=ApplicationA tag.",
            "Add another single tag group that includes only the Department=Marketing tag. Keep the Environment=Production and Name=ApplicationA tags with the current single tag group.",
            "Change the current single tag group to include only the Environment=Production tag. Add another single tag group that includes only the Department=Marketing tag."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 3,
        "text": "A healthcare services company is concerned about the growing costs of software licensing for an application for monitoring patient wellness. The company wants to create an audit process to ensure that the application is running exclusively on Amazon EC2 Dedicated Hosts. A DevOps engineer must create a workflow to audit the application to ensure compliance.What steps should the engineer take to meet this requirement with the LEAST administrative overhead?",
        "options": [
            "Use AWS Config. Identify all EC2 instances to be audited by enabling Config Recording on all Amazon EC2 resources for the region. Create a custom AWS Config rule that triggers an AWS Lambda function by using the \"config-rule-change -triggered\" blueprint. Modify the Lambda evaluateCompliance() function to verify host placement to return a NON_COMPLIANT result if the instance is not running on an EC2 Dedicated Host. Use the AWS Config report to address noncompliant instances.",
            "Use AWS Systems Manager Configuration Compliance. Use calls to the put-compliance-items API action to scan and build a database of noncompliant EC2 instances based on their host placement configuration. Use an Amazon DynamoDB table to store these instance IDs for fast access. Generate a report through Systems Manager by calling the list-compliance-summaries API action.",
            "Use AWS CloudTrail. Identify all EC2 instances to be audited by analyzing all calls to the EC2 RunCommand API action. Invoke an AWS Lambda function that analyzes the host placement of the instance. Store the EC2 instance ID of noncompliant resources in an Amazon RDS for MySQL DB instance. Generate a report by querying the RDS instance and exporting the query results to a CSV text file.",
            "Use custom Java code running on an EC2 instance. Set up EC2 Auto Scaling for the instance depending on the number of instances to be checked. Send the list of noncompliant EC2 instance IDs to an Amazon SQS queue. Set up another worker instance to process instance IDs from the SQS queue and write them to Amazon DynamoDUse an AWS Lambda function to terminate noncompliant instance IDs obtained from the queue, and send them to an Amazon SNS email topic for distribution."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 4,
        "text": "A company uses AWS Organizations to manage its AWS accounts. The company has a root OU that has a child OU. The root OU has an SCP that allows all actions on all resources. The child OU has an SCP that allows all actions for Amazon DynamoDB and AWS Lambda, and denies all other actions.The company has an AWS account that is named vendor-data in the child OU. A DevOps engineer has an IAM user that is attached to the Administrator Access IAM policy in the vendor-data account. The DevOps engineer attempts to launch an Amazon EC2 instance in the vendor-data account but receives an access denied error.Which change should the DevOps engineer make to launch the EC2 instance in the vendor-data account?",
        "options": [
            "Update the SCP in the child OU to allow all actions for Amazon EC2.",
            "Attach the AmazonEC2FullAccess IAM policy to the IAM user.",
            "Create a new SCP that allows all actions for Amazon EC2. Attach the SCP to the vendor-data account.",
            "Create a new SCP that allows all actions for Amazon EC2. Attach the SCP to the root OU."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 5,
        "text": "A DevOps engineer is planning to deploy a Ruby-based application to production. The application needs to interact with an Amazon RDS for MySQL database and should have automatic scaling and high availability. The stored data in the database is critical and should persist regardless of the state of the application stack.The DevOps engineer needs to set up an automated deployment strategy for the application with automatic rollbacks. The solution also must alert the application team when a deployment fails.Which combination of steps will meet these requirements? (Choose three.)",
        "options": [
            "Deploy the application on AWS Elastic Beanstalk. Deploy a separate Amazon RDS for MySQL DB instance outside of Elastic Beanstalk.",
            "Use the immutable deployment method to deploy new application versions.",
            "Use the rolling deployment method to deploy new application versions.",
            "Configure an Amazon EventBridge rule to monitor AWS Health events. Use an Amazon Simple Notification Service (Amazon SNS) topic as a target to alert the application team.",
            "Deploy the application on AWS Elastic Beanstalk. Deploy an Amazon RDS for MySQL DB instance as part of the Elastic Beanstalk configuration.",
            "Configure a notification email address that alerts the application team in the AWS Elastic Beanstalk configuration."
        ],
        "correct": [
            0,
            1,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 6,
        "text": "A company sells products through an ecommerce web application. The company wants a dashboard that shows a pie chart of product transaction details. The company wants to integrate the dashboard with the company's existing Amazon CloudWatch dashboards.Which solution will meet these requirements with the MOST operational efficiency?",
        "options": [
            "Update the ecommerce application to emit a JSON object to a CloudWatch log group for each processed transaction. Create an AWS Lambda function to aggregate and write the results to Amazon DynamoDB. Create a Lambda subscription filter for the log file. Attach the results to the desired CloudWatch dashboard.",
            "Update the ecommerce application to use AWS X-Ray for instrumentation. Create a new X-Ray subsegment. Add an annotation for each processed transaction. Use X-Ray traces to query the data and to visualize the results in a pie chart format. Attach the results to the desired CloudWatch dashboard.",
            "Update the ecommerce application to emit a JSON object to a CloudWatch log group for each processed transaction. Use CloudWatch Logs Insights to query the log group and to visualize the results in a pie chart format. Attach the results to the desired CloudWatch dashboard.",
            "Update the ecommerce application to emit a JSON object to an Amazon S3 bucket for each processed transaction. Use Amazon Athena to query the S3 bucket and to visualize the results in a pie chart format. Export the results from Athena. Attach the results to the desired CloudWatch dashboard."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 7,
        "text": "A company runs a workload on Amazon EC2 instances. The company needs a control that requires the use of Instance Metadata Service Version 2 (IMDSv2) on all EC2 instances in the AWS account. If an EC2 instance does not prevent the use of Instance Metadata Service Version 1 (IMDSv1), the EC2 instance must be terminated.Which solution will meet these requirements?",
        "options": [
            "Create an Amazon EventBridge rule for the EC2 instance launch successful event. Send the event to an AWS Lambda function to inspect the EC2 metadata and to terminate the instance.",
            "Create a permissions boundary that prevents the ec2:RunInstance action if the ec2:MetadataHttpTokens condition key is not set to a value of required. Attach the permissions boundary to the IAM role that was used to launch the instance.",
            "Set up AWS Config in the account. Use a managed rule to check EC2 instances. Configure the rule to remediate the findings by using AWS Systems Manager Automation to terminate the instance.",
            "Set up Amazon Inspector in the account. Configure Amazon Inspector to activate deep inspection for EC2 instances. Create an Amazon EventBridge rule for an Inspector2 finding. Set an AWS Lambda function as the target to terminate the instance."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 8,
        "text": "A company manages AWS accounts for application teams in AWS Control Tower. Individual application teams are responsible for securing their respective AWS accounts.A DevOps engineer needs to enable Amazon GuardDuty for all AWS accounts in which the application teams have not already enabled GuardDuty. The DevOps engineer is using AWS CloudFormation StackSets from the AWS Control Tower management account.How should the DevOps engineer configure the CloudFormation template to prevent failure during the StackSets deployment?",
        "options": [
            "Use the Conditions section of the CloudFormation template to enable GuardDuty in accounts where GuardDuty is not already enabled.",
            "Manually discover the list of AWS account IDs where GuardDuty is not enabled. Use the CloudFormation Fn::ImportValue intrinsic function to import the list of account IDs into the CloudFormation template to skip deployment for the listed AWS accounts.",
            "Create a CloudFormation custom resource that invokes an AWS Lambda function. Configure the Lambda function to conditionally enable GuardDuty if GuardDuty is not already enabled in the accounts.",
            "Use the CloudFormation Fn::GetAtt intrinsic function to check whether GuardDuty is already enabled. If GuardDuty is not already enabled, use the Resources section of the CloudFormation template to enable GuardDuty."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 9,
        "text": "A company's application runs on Amazon EC2 instances. The application writes to a log file that records the username, date, time, and source IP address of the login. The log is published to a log group in Amazon CloudWatch Logs.The company is performing a root cause analysis for an event that occurred on the previous day. The company needs to know the number of logins for a specific user from the past 7 days.Which solution will provide this information?",
        "options": [
            "Create a CloudWatch Logs subscription on the log group. Use a filter pattern that matches the username. Publish a CloudWatch metric that sums the number of logins over the past 7 days.",
            "Create a CloudWatch Logs Insights query that uses an aggregation function to count the number of logins for the username over the past 7 days. Run the query against the log group.",
            "Create a CloudWatch dashboard. Add a number widget that has a filter pattern that counts the number of logins for the username over the past 7 days directly from the log group.",
            "Create a CloudWatch Logs metric filter on the log group. Use a filter pattern that matches the username. Publish a CloudWatch metric that sums the number of logins over the past 7 days."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 10,
        "text": "A company has an application and a CI/CD pipeline. The CI/CD pipeline consists of an AWS CodePipeline pipeline and an AWS CodeBuild project. The CodeBuild project runs tests against the application as part of the build process and outputs a test report. The company must keep the test reports for 90 days.Which solution will meet these requirements?",
        "options": [
            "Add a new stage in the CodePipeline pipeline after the stage that contains the CodeBuild project. Create an Amazon S3 bucket to store the reports. Configure an S3 deploy action type in the new CodePipeline stage with the appropriate path and format for the reports.",
            "Add a report group in the CodeBuild project buildspec file with the appropriate path and format for the reports. Create an Amazon S3 bucket to store the reports. Configure the report group as an artifact in the CodeBuild project buildspec file. Configure the S3 bucket as the artifact destination. Set the object expiration to 90 days.",
            "Add a report group in the CodeBuild project buildspec file with the appropriate path and format for the reports. Create an Amazon S3 bucket to store the reports. Configure an Amazon EventBridge rule that invokes an AWS Lambda function to copy the reports to the S3 bucket when a build is completed. Create an S3 Lifecycle rule to expire the objects after 90 days.",
            "Add a new stage in the CodePipeline pipeline. Configure a test action type with the appropriate path and format for the reports. Configure the report expiration time to be 90 days in the CodeBuild project buildspec file."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 11,
        "text": "A DevOps engineer notices that all Amazon EC2 instances running behind an Application Load Balancer in an Auto Scaling group are failing to respond to user requests. The EC2 instances are also failing target group HTTP health checks.Upon inspection, the engineer notices the application process was not running in any EC2 instances. There are a significant number of out of memory messages in the system logs. The engineer needs to improve the resilience of the application to cope with a potential application memory leak. Monitoring and notifications should be enabled to alert when there is an issue.Which combination of actions will meet these requirements? (Choose two.)",
        "options": [
            "Change the Auto Scaling configuration to replace the instances when they fail the load balancer's health checks.",
            "Change the target group health checks from HTTP to TCP to check if the port where the application is listening is reachable.",
            "Change the target group health check HealthCheckIntervalSeconds parameter to reduce the interval between health checks.",
            "Enable the available memory consumption metric within the Amazon CloudWatch dashboard for the entire Auto Scaling group. Create an alarm when the memory utilization is high. Associate an Amazon SNS topic to the alarm to receive notifications when the alarm goes off.",
            "Use the Amazon CloudWatch agent to collect the memory utilization of the EC2 instances in the Auto Scaling group. Create an alarm when the memory utilization is high and associate an Amazon SNS topic to receive a notification."
        ],
        "correct": [
            0,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 12,
        "text": "A company is developing an application that will generate log events. The log events consist of five distinct metrics every one tenth of a second and produce a large amount of data.The company needs to configure the application to write the logs to Amazon Timestream. The company will configure a daily query against the Timestream table.Which combination of steps will meet these requirements with the FASTEST query performance? (Choose three.)",
        "options": [
            "Configure the memory store retention period to be longer than the magnetic store retention period.",
            "Treat each log as a single-measure record.",
            "Use batch writes to write multiple log events in a single write operation.",
            "Treat each log as a multi-measure record.",
            "Configure the memory store retention period to be shorter than the magnetic store retention period.",
            "Write each log event as a single write operation."
        ],
        "correct": [
            2,
            3,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 13,
        "text": "A company hired a penetration tester to simulate an internal security breach. The tester performed port scans on the company's Amazon EC2 instances. The company's security measures did not detect the port scans.The company needs a solution that automatically provides notification when port scans are performed on EC2 instances. The company creates and subscribes to an Amazon Simple Notification Service (Amazon SNS) topic.What should the company do next to meet the requirement?",
        "options": [
            "Ensure that Amazon GuardDuty is enabled. Create an Amazon CloudWatch alarm for detected EC2 and port scan findings. Connect the alarm to the SNS topic.",
            "Ensure that Amazon Inspector is enabled. Create an Amazon EventBridge event for detected CVEs that cause open port vulnerabilities. Connect the event to the SNS topic.",
            "Ensure that Amazon Inspector is enabled. Create an Amazon EventBridge event for detected network reachability findings that indicate port scans. Connect the event to the SNS topic.",
            "Ensure that AWS CloudTrail is enabled. Create an AWS Lambda function to analyze the CloudTrail logs for unusual amounts of traffic from an IP address range. Connect the Lambda function to the SNS topic."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 14,
        "text": "A company has an AWS Control Tower landing zone. The company's DevOps team creates a workload OU. A development OU and a production OU are nested under the workload OU. The company grants users full access to the company's AWS accounts to deploy applications.The DevOps team needs to allow only a specific management IAM role to manage the IAM roles and policies of any AWS accounts in only the production OU.Which combination of steps will meet these requirements? (Choose two.)",
        "options": [
            "Create an SCP that allows IAM related actions. Attach the SCP to the development OU.",
            "Ensure that the FullAWSAccess SCP is applied at the organization root.",
            "Create an SCP that denies IAM related actions with a condition to exclude the management IAM role. Attach the SCP to the production OU.",
            "Create an SCP that denies IAM related actions with a condition to exclude the management IAM role. Attach the SCP to the workload OU.",
            "Create an SCP that denies full access with a condition to exclude the management IAM role for the organization root."
        ],
        "correct": [
            1,
            2
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 15,
        "text": "A company uses an organization in AWS Organizations to manage several AWS accounts that the company's developers use. The company requires all data to be encrypted in transit.Multiple Amazon S3 buckets that were created in developer accounts allow unencrypted connections. A DevOps engineer must enforce encryption of data in transit for all existing S3 buckets that are created in accounts in the organization.Which solution will meet these requirements?",
        "options": [
            "Turn on AWS Config for the organization. Deploy a conformance pack that uses the s3-bucket-ssl-requests-only managed rule and an AWS Systems Manager Automation runbook. Use a runbook that adds a bucket policy statement to deny access to an S3 bucket when the value of the s3:x-amz-server-side-encryption-aws-kms-key-id condition key is null.",
            "Use AWS CloudFormation StackSets to deploy an AWS Network Firewall firewall to each account. Route all inbound requests to the AWS environment through the firewall. Deploy a policy to block access to all inbound requests on port 80.",
            "Turn on AWS Config for the organization. Deploy a conformance pack that uses the s3-bucket-ssl-requests-only managed rule and an AWS Systems Manager Automation runbook. Use a runbook that adds a bucket policy statement to deny access to an S3 bucket when the value of the aws:SecureTransport condition key is false.",
            "Use AWS CloudFormation StackSets to deploy an AWS Network Firewall firewall to each account. Route all outbound requests from the AWS environment through the firewall. Deploy a policy to block access to all outbound requests on port 80."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 16,
        "text": "A company has deployed a critical application in two AWS Regions. The application uses an Application Load Balancer (ALB) in both Regions. The company has Amazon Route 53 alias DNS records for both ALBs.The company uses Amazon Route 53 Application Recovery Controller to ensure that the application can fail over between the two Regions. The Route 53 ARC configuration includes a routing control for both Regions. The company uses Route 53 ARC to perform quarterly disaster recovery (DR) tests.During the most recent DR test, a DevOps engineer accidentally turned off both routing controls. The company needs to ensure that at least one routing control is turned on at all times.Which solution will meet these requirements?",
        "options": [
            "In Route 53 ARC, create a new resource set. Configure the resource set with an AWS::Route53::HealthCheck resource type. Specify the ARNs of the two routing controls as the target resource. Create a new readiness check for the resource set.",
            "In Route 53 ARC, create a new gating safety rule. Apply the assertion safety rule to the two routing controls. Configure the rule with the OR type with a threshold of 1.",
            "In Route 53 ARC, create a new resource set. Configure the resource set with an AWS::Route53RecoveryReadiness::DNSTargetResource resource type. Add the domain names of the two Route 53 alias DNS records as the target resource. Create a new readiness check for the resource set.",
            "In Route 53 ARC, create a new assertion safety rule. Apply the assertion safety rule to the two routing controls. Configure the rule with the ATLEAST type with a threshold of 1."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 17,
        "text": "A company has multiple development teams in different business units that work in a shared single AWS account. All Amazon EC2 resources that are created in the account must include tags that specify who created the resources. The tagging must occur within the first hour of resource creation.A DevOps engineer needs to add tags to the created resources that include the user ID that created the resource and the cost center ID. The DevOps engineer configures an AWS Lambda function with the cost center mappings to tag the resources. The DevOps engineer also sets up AWS CloudTrail in the AWS account. An Amazon S3 bucket stores the CloudTrail event logs.Which solution will meet the tagging requirements?",
        "options": [
            "Create a recurring hourly Amazon EventBridge scheduled rule that invokes the Lambda function. Modify the Lambda function to read the logs from the S3 bucket.",
            "Create an S3 event notification on the S3 bucket to invoke the Lambda function for s3:ObjectTagging:Put events. Enable bucket versioning on the S3 bucket.",
            "Enable server access logging on the S3 bucket. Create an S3 event notification on the S3 bucket for s3:ObjectTagging:* events.",
            "Create an Amazon EventBridge rule that uses Amazon EC2 as the event source. Configure the rule to match events delivered by CloudTrail. Configure the rule to target the Lambda function."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 18,
        "text": "A company runs an application for multiple environments in a single AWS account. An AWS CodePipeline pipeline uses a development Amazon Elastic Container Service (Amazon ECS) cluster to test an image for the application from an Amazon Elastic Container Registry (Amazon ECR) repository. The pipeline promotes the image to a production ECS cluster.The company needs to move the production cluster into a separate AWS account in the same AWS Region. The production cluster must be able to download the images over a private connection.Which solution will meet these requirements?",
        "options": [
            "Set a repository policy on the production ECR repository in the main AWS account. Configure the repository policy to allow the production ECS tasks in the separate AWS account to pull images from the main account. Configure the production ECS task execution role to have permission to download the image from the ECR repository.",
            "Use Amazon ECR VPC endpoints and an Amazon S3 gateway endpoint. In the separate AWS account, create an ECR repository. Set the repository policy to allow the production ECS tasks to pull images from the main AWS account. Configure the production ECS task execution role to have permission to download the image from the ECR repository.",
            "Use Amazon ECR VPC endpoints and an Amazon S3 gateway endpoint. Set a repository policy on the production ECR repository in the main AWS account. Configure the repository policy to allow the production ECS tasks in the separate AWS account to pull images from the main account. Configure the production ECS task execution role to have permission to download the image from the ECR repository.",
            "Configure ECR private image replication in the main AWS account. Activate cross-account replication. Define the destination account ID of the separate AWS account."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 19,
        "text": "A company is launching an application that stores raw data in an Amazon S3 bucket. Three applications need to access the data to generate reports. The data must be redacted differently for each application before the applications can access the data.Which solution will meet these requirements?",
        "options": [
            "Create an S3 access point that uses the raw data‚Äôs S3 bucket as the destination. For each application, create an S3 Object Lambda access point that uses the S3 access point. Configure the AWS Lambda function for each S3 Object Lambda access point to redact data when objects are retrieved. Configure each application to consume data from its own S3 Object Lambda access point",
            "Create an Amazon Kinesis data stream. Create an AWS Lambda function that is invoked by object creation events in the raw data‚Äôs S3 bucket. Program the Lambda function to redact data for each application. Publish the data on the Kinesis data stream. Configure each application to consume data from the Kinesis data stream.",
            "Create an S3 bucket for each application. Configure S3 Same-Region Replication (SRR) from the raw data's S3 bucket to each application's S3 bucket. Configure each application to consume data from its own S3 bucket.",
            "For each application, create an S3 access point that uses the raw data's S3 bucket as the destination. Create an AWS Lambda function that is invoked by object creation events in the raw data's S3 bucket. Program the Lambda function to redact data for each application. Store the data in each application's S3 access point. Configure each application to consume data from its own S3 access point."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 20,
        "text": "A company has multiple development groups working in a single shared AWS account. The senior manager of the groups wants to be alerted via a third-party API call when the creation of resources approaches the service limits for the account.Which solution will accomplish this with the LEAST amount of development effort?",
        "options": [
            "Add an AWS Config custom rule that runs periodically, checks the AWS service limit status, and streams notifications to an Amazon Simple Notification Service (Amazon SNS) topic. Deploy an AWS Lambda function that notifies the senior manager, and subscribe the Lambda function to the SNS topic.",
            "Deploy an AWS Lambda function that refreshes AWS Health Dashboard checks, and configure an Amazon EventBridge rule to run the Lambda function periodically. Create another EventBridge rule with an event pattern matching Health Dashboard events and a target Lambda function. In the target Lambda function, notify the senior manager.",
            "Deploy an AWS Lambda function that refreshes AWS Trusted Advisor checks, and configure an Amazon EventBridge rule to run the Lambda function periodically. Create another EventBridge rule with an event pattern matching Trusted Advisor events and a target Lambda function. In the target Lambda function, notify the senior manager.",
            "Create an Amazon EventBridge rule that runs periodically and targets an AWS Lambda function. Within the Lambda function, evaluate the current state of the AWS environment and compare deployed resource values to resource limits on the account. Notify the senior manager if the account is approaching a service limit."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 21,
        "text": "A company uses AWS Control Tower and AWS CloudFormation to manage its AWS accounts and to create AWS resources. The company requires all Amazon S3 buckets to be encrypted with AWS Key Management Service (AWS KMS) when the S3 buckets are created in a CloudFormation stack.Which solution will meet this requirement?",
        "options": [
            "Use AWS Organizations. Create an AWS Config organizational rule to check whether a KMS encryption key is enabled for all S3 buckets. Deploy the rule. Create and apply an SCP to prevent users from stopping and deleting AWS Config across all AWS accounts,",
            "Use AWS Control Tower with a multi-account environment. Configure and enable proactive AWS Control Tower controls on all OUs with CloudFormation hooks.",
            "Use AWS Control Tower with a multi-account environment. Configure and enable detective AWS Control Tower controls on all OUs with CloudFormation hooks.",
            "Use AWS Organizations. Attach an SCP that denies the s3:PutObject permission if the request does not include an x-amz-server-side-encryption header that requests server-side encryption with AWS KMS keys (SSE-KMS)."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 22,
        "text": "A company is refactoring applications to use AWS. The company identifies an internal web application that needs to make Amazon S3 API calls in a specific AWS account.The company wants to use its existing identity provider (IdP) auth.company.com for authentication. The IdP supports only OpenID Connect (OIDC). A DevOps engineer needs to secure the web application's access to the AWS account.Which combination of steps will meet these requirements? (Choose three.)",
        "options": [
            "Configure AWS IAM Identity Center (AWS Single Sign-On). Configure an IdP. Upload the IdP metadata from the existing IdP.",
            "Configure the web application to use the GetFederationToken API operation to retrieve temporary credentials. Use the temporary credentials to make the S3 API calls.",
            "Create an IAM role that has a policy that allows the necessary S3 actions. Configure the role's trust policy to allow the OIDC IP to assume the role if the sts.amazon.com:aud context key is appid_from_idp.",
            "Configure the web application to use the AssumeRoleWithWebIdentity API operation to retrieve temporary credentials. Use the temporary credentials to make the S3 API calls.",
            "Create an IAM role that has a policy that allows the necessary S3 actions. Configure the role's trust policy to allow the OIDC IP to assume the role if the auth.company.com:aud context key is appid_from_idp.",
            "Create an IAM IdP by using the provider URL, audience, and signature from the existing IP."
        ],
        "correct": [
            3,
            4,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 23,
        "text": "A company's security policies require the use of security hardened AMIs in production environments. A DevOps engineer has used EC2 Image Builder to create a pipeline that builds the AMIs on a recurring schedule.The DevOps engineer needs to update the launch templates of the company's Auto Scaling groups. The Auto Scaling groups must use the newest AMIs during the launch of Amazon EC2 instances.Which solution will meet these requirements with the MOST operational efficiency?",
        "options": [
            "Configure an Amazon EventBridge rule to receive new AMI events from Image Builder. Target an AWS Lambda function that updates the launch templates of the Auto Scaling groups with the newest AMI ID.",
            "Configure the launch template to use a value from AWS Systems Manager Parameter Store for the AMI ID. Configure the Image Builder pipeline to update the Parameter Store value with the newest AMI ID.",
            "Configure an Amazon EventBridge rule to receive new AMI events from Image Builder. Target an AWS Systems Manager Run Command document that updates the launch templates of the Auto Scaling groups with the newest AMI ID.",
            "Configure the Image Builder distribution settings to update the launch templates with the newest AMI IConfigure the Auto Scaling groups to use the newest version of the launch template."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 24,
        "text": "A company uses AWS WAF to protect its cloud infrastructure. A DevOps engineer needs to give an operations team the ability to analyze log messages from AWS WAF. The operations team needs to be able to create alarms for specific patterns in the log output.Which solution will meet these requirements with the LEAST operational overhead?",
        "options": [
            "Create an Amazon S3 bucket for the log output. Configure AWS WAF to send log outputs to the S3 bucket. Instruct the operations team to create AWS Lambda functions that detect each desired log message pattern. Configure the Lambda functions to publish to an Amazon Simple Notification Service (Amazon SNS) topic.",
            "Create an Amazon OpenSearch Service cluster and appropriate indexes. Configure an Amazon Kinesis Data Firehose delivery stream to stream log data to the indexes. Use OpenSearch Dashboards to create filters and widgets.",
            "Create an Amazon S3 bucket for the log output. Configure AWS WAF to send log outputs to the S3 bucket. Use Amazon Athena to create an external table definition that fits the log message pattern. Instruct the operations team to write SQL queries and to create Amazon CloudWatch metric filters for the Athena queries.",
            "Create an Amazon CloudWatch Logs log group. Configure the appropriate AWS WAF web ACL to send log messages to the log group. Instruct the operations team to create CloudWatch metric filters."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 25,
        "text": "A company's application teams use AWS CodeCommit repositories for their applications. The application teams have repositories in multiple AWS accounts. All accounts are in an organization in AWS Organizations.Each application team uses AWS IAM Identity Center (AWS Single Sign-On) configured with an external IdP to assume a developer IAM role. The developer role allows the application teams to use Git to work with the code in the repositories.A security audit reveals that the application teams can modify the main branch in any repository. A DevOps engineer must implement a solution that allows the application teams to modify the main branch of only the repositories that they manage.Which combination of steps will meet these requirements? (Choose three.)",
        "options": [
            "Update the SAML assertion to pass the user's team name. Update the IAM role's trust policy to add an access-team session tag that has the team name.",
            "For each CodeCommit repository, add an access-team tag that has the value set to the name of the associated team.",
            "Attach an SCP to the accounts. Include the following statement:",
            "Create an IAM permissions boundary in each account. Include the following statement:",
            "Create an approval rule template for each account. Associate the template with all repositories. Add the \"aws:ResourceTag/access-team\": \"$ ;{aws:PrincipalTag/access-team}\" condition to the approval rule template.",
            "Create an approval rule template for each team in the Organizations management account. Associate the template with all the repositories. Add the developer role ARN as an approver."
        ],
        "correct": [
            0,
            1,
            2
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 26,
        "text": "A company has an AWS Control Tower landing zone that manages its organization in AWS Organizations. The company created an OU structure that is based on the company's requirements. The company's DevOps team has established the core accounts for the solution and an account for all centralized AWS CloudFormation and AWS Service Catalog solutions.The company wants to offer a series of customizations that an account can request through AWS Control Tower.Which combination of steps will meet these requirements? (Choose three.)",
        "options": [
            "Deploy the Customizations for AWS Control Tower (CfCT) CloudFormation stack.",
            "Create an IAM role that is named AWSControlTowerBlueprintAccess. Configure the role with a trust policy that allows the AWSControlTowerAdmin role in the management account to assume the role. Attach the AWSServiceCatalogAdminFullAccess IAM policy to the AWSControlTowerBlueprintAccess role.",
            "Create a CloudFormation stack set for each CloudFormation template. Enable automatic deployment for each stack set. Create a CloudFormation stack instance that targets specific OUs.",
            "Create a Service Catalog product for each CloudFormation template.",
            "Create a CloudFormation template that contains the resources for each customization.",
            "Enable trusted access for CloudFormation with Organizations by using service-managed permissions."
        ],
        "correct": [
            1,
            3,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 27,
        "text": "A DevOps engineer is building a solution that uses Amazon Simple Queue Service (Amazon SQS) standard queues. The solution also includes an AWS Lambda function and an Amazon DynamoDB table. The Lambda function pulls content from an SQS queue event source and writes the content to the DynamoDB table.The solution must maximize the scalability of Lambda and must prevent successfully processed SQS messages from being processed multiple times.Which solution will meet these requirements?",
        "options": [
            "Decrease the batch window to 1 second when configuring the Lambda function's event source mapping.",
            "Decrease the batch size to 1 when configuring the Lambda function's event source mapping.",
            "Include the ReportBatchItemFailures value in the FunctionResponseTypes list in the Lambda function's event source mapping.",
            "Set the queue visibility timeout on the Lambda function's event source mapping to account for invocation throttling of the Lambda function."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 28,
        "text": "A company has deployed a complex container-based workload on AWS. The workload uses Amazon Managed Service for Prometheus for monitoring. The workload runs in an AmazonElastic Kubernetes Service (Amazon EKS) cluster in an AWS account.The company‚Äôs DevOps team wants to receive workload alerts by using the company‚Äôs Amazon Simple Notification Service (Amazon SNS) topic. The SNS topic is in the same AWS account as the EKS cluster.Which combination of steps will meet these requirements? (Choose three.)",
        "options": [
            "Create an alert manager configuration for the SNS topic.",
            "Create an OpenID Connect (OIDC) provider for the EKS cluster. Create a cluster service account. Grant the account the sns:Publish permission and the sns:GetTopicAttributes permission by using an IAM role.",
            "Modify the IAM role that Amazon Managed Service for Prometheus uses. Grant the role the sns:Publish permission and the sns:GetTopicAttributes permission for the SNS topic.",
            "Use the Amazon Managed Service for Prometheus remote write URL to send alerts to the SNS topic",
            "Modify the access policy of the SNS topic. Grant the aps.amazonaws.com service principal the sns:Publish permission and the sns:GetTopicAttributes permission for the SNS topic.",
            "Create an alerting rule that checks the availability of each of the workload‚Äôs containers."
        ],
        "correct": [
            0,
            4,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 29,
        "text": "A company uses an organization in AWS Organizations to manage its AWS accounts. The company's automation account contains a CI/CD pipeline that creates and configures new AWS accounts.The company has a group of internal service teams that provide services to accounts in the organization. The service teams operate out of a set of services accounts. The service teams want to receive an AWS CloudTrail event in their services accounts when the CreateAccount API call creates a new account.How should the company share this CloudTrail event with the service accounts?",
        "options": [
            "Create a custom Amazon EventBridge event bus in the services accounts. Update the custom event bus to allow events from the automation account. Create an EventBridge rule in the services account that directly listens to CloudTrail events from the automation account.",
            "Create an Amazon EventBridge rule in the automation account to send account creation events to the default event bus in the services accounts. Update the default event bus in the services accounts to allow events from the automation account.",
            "Create a custom Amazon EventBridge event bus in the automation account and the services accounts. Create an EventBridge rule and policy that connects the custom event buses that are in the automation account and the services accounts.",
            "Create a custom Amazon EventBridge event bus in the automation account. Create an EventBridge rule and policy that connects the custom event bus to the default event buses in the services accounts."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 30,
        "text": "A company is migrating from its on-premises data center to AWS. The company currently uses a custom on-premises Cl/CD pipeline solution to build and package software.The company wants its software packages and dependent public repositories to be available in AWS CodeArtifact to facilitate the creation of application-specific pipelines.Which combination of steps should the company take to update the CI/CD pipeline solution and to configure CodeArtifact with the LEAST operational overhead? (Choose two.)",
        "options": [
            "Create a new Amazon S3 bucket. Generate a presigned URL that allows the PutObject request. Update the on-premises CI/CD pipeline to use the presigned URL to publish the packages from the on-premises location to the S3 bucket. Create an AWS Lambda function that runs when packages are created in the bucket through a put command. Configure the Lambda function to publish the packages to CodeArtifact.",
            "For each public repository, create a CodeArutact repository that is configured with an external connection. Configure the dependent repositories as upstream public repositories.",
            "Update the C1ICD pipeline to create a VM image that contains newly packaged software. Use AWS Import/Export to make the VM image available as an Amazon EC2 AMI. Launch the AMI with an attached IAM instance profile that allows CodeArtifact actions. Use AWS CLI commands to publish the packages to a CodeArtifact repository.",
            "Create a Codeartitact repository that is configured with a set of external connections to the public repositories. Configure the external connections to be downstream of the repository.",
            "Create an AWS Identity and Access Management Roles Anywhere trust anchor. Create an IAM role that allows CodeArtifact actions and that has a trust relationship on the trust anchor. Update the on-premises CI/CD pipeline to assume the new IAM role and to publish the packages to CodeArtifact."
        ],
        "correct": [
            1,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 31,
        "text": "A company has a new AWS account that teams will use to deploy various applications. The teams will create many Amazon S3 buckets for application-specific purposes and to store AWS CloudTrail logs. The company has enabled Amazon Macie for the account.A DevOps engineer needs to optimize the Macie costs for the account without compromising the account's functionality.Which solutions will meet these requirements? (Choose two.)",
        "options": [
            "Exclude S3 buckets that have public read access from automated discovery.",
            "Configure discovery jobs to include S3 objects based on the last modified criterion.",
            "Configure discovery jobs to include S3 objects that are tagged as production only.",
            "Exclude S3 buckets that contain CloudTrail logs from automated discovery.",
            "Configure scheduled daily discovery jobs for all S3 buckets in the account."
        ],
        "correct": [
            1,
            3
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 32,
        "text": "A company uses an Amazon API Gateway regional REST API to host its application API. The REST API has a custom domain. The REST API's default endpoint is deactivated.The company's internal teams consume the API. The company wants to use mutual TLS between the API and the internal teams as an additional layer of authentication.Which combination of steps will meet these requirements? (Choose two.)",
        "options": [
            "Upload the provisioned client certificate to an Amazon S3 bucket. Configure the API Gateway mutual TLS to use the client certificate that is stored in the S3 bucket as the trust store.",
            "Use AWS Certificate Manager (ACM) to create a private certificate authority (CA). Provision a client certificate that is signed by the private CA.",
            "Upload the provisioned client certificate private key to an Amazon S3 bucket. Configure the API Gateway mutual TLS to use the private key that is stored in the S3 bucket as the trust store.",
            "Provision a client certificate that is signed by a public certificate authority (CA). Import the certificate into AWS Certificate Manager (ACM).",
            "Upload the root private certificate authority (CA) certificate to an Amazon S3 bucket. Configure the API Gateway mutual TLS to use the private CA certificate that is stored in the S3 bucket as the trust store."
        ],
        "correct": [
            1,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 33,
        "text": "A company builds an application that uses an Application Load Balancer in front of Amazon EC2 instances that are in an Auto Scaling group. The application is stateless. The Auto Scaling group uses a custom AMI that is fully prebuilt. The EC2 instances do not have a custom bootstrapping process.The AMI that the Auto Scaling group uses was recently deleted. The Auto Scaling group's scaling activities show failures because the AMI ID does not exist.Which combination of steps should a DevOps engineer take to meet these requirements? (Choose three.)",
        "options": [
            "Create a new launch template that uses the new AMI.",
            "Reduce the Auto Scaling group's desired capacity to 0.",
            "Increase the Auto Scaling group's desired capacity by 1.",
            "Create a new AMI by copying the most recent public AMI of the operating system that the EC2 instances use.",
            "Update the Auto Scaling group to use the new launch template.",
            "Create a new AMI from a running EC2 instance in the Auto Scaling group."
        ],
        "correct": [
            0,
            4,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 34,
        "text": "A DevOps engineer is implementing governance controls for a company that requires its infrastructure to be housed within the United States. The engineer must restrict which AWS Regions can be used, and ensure an alert is sent as soon as possible if any activity outside the governance policy takes place. The controls should be automatically enabled on any new Region outside the United States (US).Which combination of actions will meet these requirements? (Choose two.)",
        "options": [
            "Create an AWS Organizations SCP that denies access to all non-global services in non-US Regions. Attach the policy to the root of the organization.",
            "Use an AWS Lambda function that checks for AWS service activity and deploy it to all Regions. Write an Amazon EventBridge rule that runs the Lambda function every hour, sending an alert if activity is found in a non-US Region.",
            "Configure AWS CloudTrail to send logs to Amazon CloudWatch Logs and enable it for all Regions. Use a CloudWatch Logs metric filter to send an alert on any service activity in non-US Regions.",
            "Use an AWS Lambda function to query Amazon Inspector to look for service activity in non-US Regions and send alerts if any activity is found.",
            "Write an SCP using the aws:RequestedRegion condition key limiting access to US Regions. Apply the policy to all users, groups, and roles."
        ],
        "correct": [
            0,
            2
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 35,
        "text": "A company is reviewing its IAM policies. One policy written by the DevOps engineer has been flagged as too permissive. The policy is used by an AWS Lambda function that issues a stop command to Amazon EC2 instances tagged with Environment: NonProduction over the weekend. The current policy is:What changes should the engineer make to achieve a policy of least permission? (Choose three.)",
        "options": [
            "Add the following conditional expression:",
            "Add the following conditional expression:",
            "Add the following conditional expression:",
            "Change \"Resource\": \"*\"to \"Resource\": \"arn:aws:ec2:*:*:instance/*\"",
            "Change \"Action\": \"ec2:*\"to \"Action\": \"ec2:StopInstances\"",
            "Add the following conditional expression:"
        ],
        "correct": [
            3
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 36,
        "text": "A company is launching an application. The application must use only approved AWS services. The account that runs the application was created less than 1 year ago and is assigned to an AWS Organizations OU.The company needs to create a new Organizations account structure. The account structure must have an appropriate SCP that supports the use of only services that are currently active in the AWS account. The company will use AWS Identity and Access Management (IAM) Access Analyzer in the solution.Which solution will meet these requirements?",
        "options": [
            "Create an SCP that denies the services that IAM Access Analyzer identifies. Create an OU for the account. Move the account into the new OU. Attach the new SCP to the new OU.",
            "Create an SCP that allows the services that IAM Access Analyzer identifies. Create an OU for the account. Move the account into the new OU. Attach the new SCP to the management account. Detach the default FullAWSAccess SCP from the new OU.",
            "Create an SCP that allows the services that IAM Access Analyzer identifies. Create an OU for the account. Move the account into the new OU. Attach the new SCP to the new OU. Detach the default FullAWSAccess SCP from the new OU.",
            "Create an SCP that allows the services that IAM Access Analyzer identifies. Attach the new SCP to the organization's root."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 37,
        "text": "A company runs a web application that extends across multiple Availability Zones. The company uses an Application Load Balancer (ALB) for routing, AWS Fargate for the application, and Amazon Aurora for the application data. The company uses AWS CloudFormation templates to deploy the application. The company stores all Docker images in an Amazon Elastic Container Registry (Amazon ECR) repository in the same AWS account and AWS Region.A DevOps engineer needs to establish a disaster recovery (DR) process in another Region. The solution must meet an RPO of 8 hours and an RTO of 2 hours. The company sometimes needs more than 2 hours to build the Docker images from the Dockerfile.Which solution will meet the RTO and RPO requirements MOST cost-effectively?",
        "options": [
            "Copy the CloudFormation templates to an Amazon S3 bucket in the DR Region. Configure Aurora automated backup Cross-Region Replication. Configure ECR Cross-Region Replication. In case of DR, use the CloudFormation template with the most recent Aurora snapshot and the Docker image from the local ECR repository to launch a new CloudFormation stack in the DR Region. Update the application DNS records to point to the new ALB.",
            "Copy the CloudFormation templates to an Amazon S3 bucket in the DR Region. Deploy a second application CloudFormation stack in the DR Region. Reconfigure Aurora to be a global database. Update both CloudFormation stacks when a new application release in the current Region is needed. In case of DR, update the application DNS records to point to the new ALB.",
            "Copy the CloudFormation templates and the Dockerfile to an Amazon S3 bucket in the DR Region. Use AWS Backup to configure automated Aurora cross-Region hourly snapshots. In case of DR, build the most recent Docker image and upload the Docker image to an ECR repository in the DR Region. Use the CloudFormation template that has the most recent Aurora snapshot and the Docker image from the ECR repository to launch a new CloudFormation stack in the DR Region. Update the application DNS records to point to the new ALB.",
            "Copy the CloudFormation templates to an Amazon S3 bucket in the DR Region. Use Amazon EventBridge to schedule an AWS Lambda function to take an hourly snapshot of the Aurora database and of the most recent Docker image in the ECR repository. Copy the snapshot and the Docker image to the DR Region. In case of DR, use the CloudFormation template with the most recent Aurora snapshot and the Docker image from the local ECR repository to launch a new CloudFormation stack in the DR Region."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 38,
        "text": "A company needs to ensure that flow logs remain configured for all existing and new VPCs in its AWS account. The company uses an AWS CloudFormation stack to manage its VPCs. The company needs a solution that will work for any VPCs that any IAM user creates.Which solution will meet these requirements?",
        "options": [
            "Turn on AWS Config. Create an AWS Config rule to check whether VPC flow logs are turned on. Configure automatic remediation to turn on VPC flow logs.",
            "Add the AWS::EC2::FlowLog resource to the CloudFormation stack that creates the VPCs.",
            "Create an organization in AWS Organizations. Add the company's AWS account to the organization. Create an SCP to prevent users from modifying VPC flow logs.",
            "Create an IAM policy to deny the use of API calls for VPC flow logs. Attach the IAM policy to all IAM users."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 39,
        "text": "A company runs applications in an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The EKS cluster uses an Application Load Balancer to route traffic to the applications that run in the cluster.A new application that was migrated to the EKS cluster is performing poorly. All the other applications in the EKS cluster maintain appropriate operation. The new application scales out horizontally to the preconfigured maximum number of pods immediately upon deployment, before any user traffic routes to the web application.Which solution will resolve the scaling behavior of the web application in the EKS cluster?",
        "options": [
            "Implement the Cluster Autoscaler.",
            "Implement the AWS Load Balancer Controller in the EKS cluster.",
            "Implement the Horizontal Pod Autoscaler in the EKS cluster.",
            "Implement the Vertical Pod Autoscaler in the EKS cluster."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 40,
        "text": "A company uses an organization in AWS Organizations to manage its AWS accounts. The company recently acquired another company that has standalone AWS accounts. The acquiring company's DevOps team needs to consolidate the administration of the AWS accounts for both companies and retain full administrative control of the accounts. The DevOps team also needs to collect and group findings across all the accounts to implement and maintain a security posture.Which combination of steps should the DevOps team take to meet these requirements? (Choose two.)",
        "options": [
            "Invite the acquired company's AWS accounts to join the organization. Create the OrganizationAccountAccessRole IAM role in the invited accounts. Grant permission to the management account to assume the role.",
            "Invite the acquired company's AWS accounts to join the organization. Create an SCP that has full administrative privileges. Attach the SCP to the management account.",
            "Use Amazon Inspector to collect and group findings across all accounts. Designate an account in the organization as the delegated administrator account for Amazon Inspector.",
            "Use AWS Security Hub to collect and group findings across all accounts. Use Security Hub to automatically detect new accounts as the accounts are added to the organization.",
            "Use AWS Firewall Manager to collect and group findings across all accounts. Enable all features for the organization. Designate an account in the organization as the delegated administrator account for Firewall Manager."
        ],
        "correct": [
            0,
            3
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 41,
        "text": "A software team is using AWS CodePipeline to automate its Java application release pipeline. The pipeline consists of a source stage, then a build stage, and then a deploy stage. Each stage contains a single action that has a runOrder value of 1.The team wants to integrate unit tests into the existing release pipeline. The team needs a solution that deploys only the code changes that pass all unit tests.Which solution will meet these requirements?",
        "options": [
            "Modify the deploy stage. Add a test action that has a runOrder value of 1. Use AWS CodeDeploy as the action provider to run unit tests.",
            "Modify the build stage. Add a test action that has a runOrder value of 2. Use AWS CodeBuild as the action provider to run unit tests.",
            "Modify the build stage. Add a test action that has a runOrder value of 1. Use AWS CodeDeploy as the action provider to run unit tests.",
            "Modify the deploy stage. Add a test action that has a runOrder value of 2. Use AWS CodeBuild as the action provider to run unit tests."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 42,
        "text": "A company deploys a web application on Amazon EC2 instances that are behind an Application Load Balancer (ALB). The company stores the application code in an AWS CodeCommit repository. When code is merged to the main branch, an AWS Lambda function invokes an AWS CodeBuild project. The CodeBuild project packages the code, stores the packaged code in AWS CodeArtifact, and invokes AWS Systems Manager Run Command to deploy the packaged code to the EC2 instances.Previous deployments have resulted in defects, EC2 instances that are not running the latest version of the packaged code, and inconsistencies between instances.Which combination of actions should a DevOps engineer take to implement a more reliable deployment solution? (Choose two.)",
        "options": [
            "Create an Amazon S3 bucket. Modify the CodeBuild project to store the packages in the S3 bucket instead of in CodeArtifact. Use deploy actions in CodeDeploy to deploy the artifact to the EC2 instances.",
            "Create individual Lambda functions that use AWS CodeDeploy instead of Systems Manager to run build, test, and deploy actions.",
            "Create an AWS CodeDeploy application and a deployment group to deploy the packaged code to the EC2 instances. Configure the ALB for the deployment group.",
            "Create a pipeline in AWS CodePipeline that uses the CodeCommit repository as a source provider. Configure pipeline stages that run the CodeBuild project in parallel to build and test the application. In the pipeline, pass the CodeBuild project output artifact to an AWS CodeDeploy action.",
            "Create a pipeline in AWS CodePipeline that uses the CodeCommit repository as a source provider. Create separate pipeline stages that run a CodeBuild project to build and then test the application. In the pipeline, pass the CodeBuild project output artifact to an AWS CodeDeploy action."
        ],
        "correct": [
            2,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 43,
        "text": "A company uses Amazon RDS for all databases in its AWS accounts. The company uses AWS Control Tower to build a landing zone that has an audit and logging account. All databases must be encrypted at rest for compliance reasons. The company's security engineer needs to receive notification about any noncompliant databases that are in the company‚Äôs accounts.Which solution will meet these requirements with the MOST operational efficiency?",
        "options": [
            "Create a custom AWS Config rule in every account to determine whether the RDS storage is encrypted. Create an Amazon Simple Notification Service (Amazon SNS) topic in the audit account. Create an Amazon EventBidge rule to filter noncompliant events from the AWS Control Tower control (guardrail) to notify the SNS topic. Subscribe the security engineer's email address to the SNS topic.",
            "Use AWS CloudFormation StackSets to deploy AWS Lambda functions to every account. Write the Lambda function code to determine whether the RDS storage is encrypted in the account the function is deployed to. Send the findings as an Amazon CloudWatch metric to the management account. Create an Amazon Simple Notification Service (Amazon SNS) topic. Create a CloudWatch alarm that notifies the SNS topic when metric thresholds are met. Subscribe the security engineer's email address to the SNS topic.",
            "Launch an Amazon C2 instance. Run an hourly cron job by using the AWS CLI to determine whether the RDS storage is encrypted in each AWS account. Store the results in an RDS database. Notify the security engineer by sending email messages from the EC2 instance when noncompliance is detected",
            "Use AWS Control Tower to activate the optional detective control (guardrail) to determine whether the RDS storage is encrypted. Create an Amazon Simple Notification Service (Amazon SNS) topic in the company's audit account. Create an Amazon EventBridge rule to filter noncompliant events from the AWS Control Tower control (guardrail) to notify the SNS topic. Subscribe the security engineer's email address to the SNS topic."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 44,
        "text": "A DevOps engineer is setting up a container-based architecture. The engineer has decided to use AWS CloudFormation to automatically provision an Amazon ECS cluster and an Amazon EC2 Auto Scaling group to launch the EC2 container instances. After successfully creating the CloudFormation stack, the engineer noticed that, even though the ECS cluster and the EC2 instances were created successfully and the stack finished the creation, the EC2 instances were associating with a different cluster.How should the DevOps engineer update the CloudFormation template to resolve this issue?",
        "options": [
            "Reference the ECS cluster in the AWS::CloudFormation::CustomResource resource to trigger an AWS Lambda function that registers the EC2 instances with the appropriate ECS cluster.",
            "Reference the EC2 instances in the AWS::ECS::Cluster resource and reference the ECS cluster in the AWS::ECS::Service resource.",
            "Reference the ECS cluster in the AWS::EC2::Instance resource of the UserData property.",
            "Reference the ECS cluster in the AWS::AutoScaling::LaunchConfiguration resource of the UserData property."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 45,
        "text": "An ecommerce company uses a large number of Amazon Elastic Block Store (Amazon EBS) backed Amazon EC2 instances. To decrease manual work across all the instances, a DevOps engineer is tasked with automating restart actions when EC2 instance retirement events are scheduled.How can this be accomplished?",
        "options": [
            "Create a scheduled Amazon EventBridge rule to run an AWS Systems Manager Automation runbook that checks if any EC2 instances are scheduled for retirement once a week. If the instance is scheduled for retirement, the runbook will hibernate the instance.",
            "Enable EC2 Auto Recovery on all of the instances. Create an AWS Config rule to limit the recovery to occur during a maintenance window only.",
            "Set up an AWS Health Amazon EventBridge rule to run AWS Systems Manager Automation runbooks that stop and start the EC2 instance when a retirement scheduled event occurs.",
            "Reboot all EC2 instances during an approved maintenance window that is outside of standard business hours. Set up Amazon CloudWatch alarms to send a notification in case any instance is failing EC2 instance status checks."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 46,
        "text": "A DevOps engineer has created an AWS CloudFormation template that deploys an application on Amazon EC2 instances. The EC2 instances run Amazon Linux. The application is deployed to the EC2 instances by using shell scripts that contain user data. The EC2 instances have an IAM instance profile that has an IAM role with the AmazonSSMManagedinstanceCore managed policy attached.The DevOps engineer has modified the user data in the CloudFormation template to install a new version of the application. The engineer has also applied the stack update. However, the application was not updated on the running EC2 instances. The engineer needs to ensure that the changes to the application are installed on the running EC2 instances.Which combination of steps will meet these requirements? (Choose two.)",
        "options": [
            "Configure the user data content to use the Multipurpose Internet Mail Extensions (MIME) multipart format. Set the scripts-user parameter to always in the text/cloud-config section.",
            "Refactor the user data command to use an AWS Systems Manager document (SSM document). Use Systems Manager State Manager to create an association between the SSM document and the EC2 instances.",
            "Configure an EC2 launch template for the EC2 instances. Create a new EC2 Auto Scaling group. Associate the Auto Scaling group with the EC2 launch template. Use the AutoScalingScheduledAction update policy for the Auto Scaling group.",
            "Refactor the user data commands to use an AWS Systems Manager document (SSM document). Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 instances.",
            "Refactor the user data commands to use the cfn-init helper script. Update the user data to install and configure the cfn-hup and cfn-init helper scripts to monitor and apply the metadata changes."
        ],
        "correct": [
            1,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 47,
        "text": "A company requires its internal business teams to launch resources through pre-approved AWS CloudFormation templates only. The security team requires automated monitoring when resources drift from their expected state.Which strategy should be used to meet these requirements?",
        "options": [
            "Allow users to deploy CloudFormation stacks using a CloudFormation service role only. Use AWS Config rules to detect when resources have drifted from their expected state.",
            "Allow users to deploy CloudFormation stacks using a CloudFormation service role only. Use CloudFormation drift detection to detect when resources have drifted from their expected state.",
            "Allow users to deploy CloudFormation stacks using AWS Service Catalog only. Enforce the use of a launch constraint. Use AWS Config rules to detect when resources have drifted from their expected state.",
            "Allow users to deploy CloudFormation stacks using AWS Service Catalog only. Enforce the use of a template constraint. Use Amazon EventBridge notifications to detect when resources have drifted from their expected state."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 48,
        "text": "A DevOps team uses AWS CodePipeline, AWS CodeBuild, and AWS CodeDeploy to deploy an application. The application is a REST API that uses AWS Lambda functions and Amazon API Gateway. Recent deployments have introduced errors that have affected many customers.The DevOps team needs a solution that reverts to the most recent stable version of the application when an error is detected. The solution must affect the fewest customers possible.Which solution will meet these requirements with the MOST operational efficiency?",
        "options": [
            "Set the deployment configuration in CodeDeploy to LambdaAllAtOnce. Configure automatic rollbacks on the deployment group. Create an Amazon CloudWatch alarm that detects HTTP Bad Gateway errors on API Gateway. Configure the deployment group to roll back when the number of alarms meets the alarm threshold.",
            "Set the deployment configuration in CodeDeploy to LambdaAllAtOnce. Configure manual rollbacks on the deployment group. Create an Amazon Simple Notification Service (Amazon SNS) topic to send notifications every time a deployment fails. Configure the SNS topic to invoke a new Lambda function that stops the current deployment and starts the most recent successful deployment.",
            "Set the deployment configuration in CodeDeploy to LambdaCanary10Percent10Minutes. Configure automatic rollbacks on the deployment group. Create an Amazon CloudWatch alarm that detects HTTP Bad Gateway errors on API Gateway. Configure the deployment group to roll back when the number of alarms meets the alarm threshold.",
            "Set the deployment configuration in CodeDeploy to LambdaCanary10Percent10Minutes. Configure manual rollbacks on the deployment group. Create a metric filter on an Amazon CloudWatch log group for API Gateway to monitor HTTP Bad Gateway errors. Configure the metric filter to invoke a new Lambda function that stops the current deployment and starts the most recent successful deployment."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 49,
        "text": "A company is using AWS CodePipeline to deploy an application. According to a new guideline, a member of the company's security team must sign off on any application changes before the changes are deployed into production. The approval must be recorded and retained.Which combination of actions will meet these requirements? (Choose two.)",
        "options": [
            "Create an AWS CloudTrail trail to deliver logs to Amazon S3.",
            "Configure CodePipeline to write actions to an Amazon S3 bucket at the end of each pipeline stage.",
            "Configure CodePipeline to write actions to Amazon CloudWatch Logs.",
            "Create a CodePipeline custom action to invoke an AWS Lambda function for approval. Create a policy that gives the security team access to manage CodePipeline custom actions.",
            "Create a CodePipeline manual approval action before the deployment step. Create a policy that grants the security team access to approve manual approval stages."
        ],
        "correct": [
            0,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 50,
        "text": "A company recently deployed its web application on AWS. The company is preparing for a large-scale sales event and must ensure that the web application can scale to meet the demand.The application's frontend infrastructure includes an Amazon CloudFront distribution that has an Amazon S3 bucket as an origin. The backend infrastructure includes an Amazon API Gateway API, several AWS Lambda functions, and an Amazon Aurora DB cluster.The company's DevOps engineer conducts a load test and identifies that the Lambda functions can fulfil the peak number of requests. However, the DevOps engineer notices request latency during the initial burst of requests. Most of the requests to the Lambda functions produce queries to the database. A large portion of the invocation time is used to establish database connections.Which combination of steps will provide the application with the required scalability? (Choose three.)",
        "options": [
            "Use Amazon RDS Proxy to create a proxy for the Aurora database. Update the Lambda functions to use the proxy endpoints for database connections.",
            "Configure a higher reserved concurrency for the Lambda functions.",
            "Refactor the Lambda functions. Move the code blocks that initialize database connections into the function handlers.",
            "Convert the DB cluster to an Aurora global database. Add additional Aurora Replicas in AWS Regions based on the locations of the company's customers.",
            "Configure a higher provisioned concurrency for the Lambda functions."
        ],
        "correct": [
            3,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 51,
        "text": "A company has configured an Amazon S3 event source on an AWS Lambda function. The company needs the Lambda function to run when a new object is created or an existing object is modified in a particular S3 bucket. The Lambda function will use the S3 bucket name and the S3 object key of the incoming event to read the contents of the created or modified S3 object. The Lambda function will parse the contents and save the parsed contents to an Amazon DynamoDB table.The Lambda function's execution role has permissions to read from the S3 bucket and to write to the DynamoDB table. During testing, a DevOps engineer discovers that the Lambda function does not run when objects are added to the S3 bucket or when existing objects are modified.Which solution will resolve this problem?",
        "options": [
            "Increase the memory of the Lambda function to give the function the ability to process large files from the S3 bucket.",
            "Provision space in the /tmp folder of the Lambda function to give the function the ability to process large files from the S3 bucket.",
            "Create a resource policy on the Lambda function to grant Amazon S3 the permission to invoke the Lambda function for the S3 bucket.",
            "Configure an Amazon Simple Queue Service (Amazon SQS) queue as an OnFailure destination for the Lambda function."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 52,
        "text": "A DevOps engineer has developed an AWS Lambda function. The Lambda function starts an AWS CloudFormation drift detection operation on all supported resources for a specific CloudFormation stack. The Lambda function then exits its invocation.The DevOps engineer has created an Amazon EventBridge scheduled rule that invokes the Lambda function every hour. An Amazon Simple Notification Service (Amazon SNS) topic already exists in the AWS account. The DevOps engineer has subscribed to the SNS topic to receive notifications.The DevOps engineer needs to receive a notification as soon as possible when drift is detected in this specific stack configuration.Which solution will meet these requirements?",
        "options": [
            "Configure Amazon GuardDuty in the account with drift detection for all CloudFormation stacks. Create a second EventBridge rule that reacts to the GuardDuty drift detection event finding for the specific CloudFormation stack. Configure the SNS topic as a target of the second EventBridge rule.",
            "Configure the existing EventBridge rule to also target the SNS topic. Configure an SNS subscription filter policy to match the CloudFormation stack. Attach the subscription filter policy to the SNS topic.",
            "Create a second Lambda function to query the CloudFormation API for the drift detection results for the stack. Configure the second Lambda function to publish a message to the SNS topic if drift is detected. Adjust the existing EventBridge rule to also target the second Lambda function.",
            "Configure AWS Config in the account. Use the cloudformation-stack-drift-detection-check managed rule. Create a second EventBridge rule that reacts to a compliance change event for the CloudFormation stack. Configure the SNS topic as a target of the second EventBridge rule."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    }
]

        let currentQuestionIndex = 0;
        let userAnswers = [];
        let startTime = Date.now();
        let timer;

        function initializeApp() {
            document.getElementById('totalQuestions').textContent = questions.length;
            loadQuestion();
            startTimer();
            updateStats();
        }

        function loadQuestion() {
            const question = questions[currentQuestionIndex];
            document.getElementById('questionText').innerHTML = `
                <strong>C√¢u ${question.id}:</strong><br><br>
                ${question.text}
            `;
            
            // Set question type indicator
            const typeElement = document.getElementById('questionType');
            if (question.type === 'multiple') {
                typeElement.textContent = `Multiple Choice (Choose ${question.correct.length})`;
                typeElement.style.background = '#fff3cd';
                typeElement.style.color = '#856404';
            } else {
                typeElement.textContent = 'Single Choice';
                typeElement.style.background = '#e3f2fd';
                typeElement.style.color = '#1976d2';
            }
            
            const optionsContainer = document.getElementById('optionsContainer');
            optionsContainer.innerHTML = '';
            
            question.options.forEach((option, index) => {
                const optionDiv = document.createElement('div');
                optionDiv.className = 'option';
                optionDiv.innerHTML = `
                    <strong>${String.fromCharCode(65 + index)}.</strong> ${option}
                    ${question.type === 'multiple' ? '<input type="checkbox" class="option-checkbox">' : ''}
                `;
                
                if (question.type === 'multiple') {
                    optionDiv.onclick = () => toggleMultipleOption(index);
                } else {
                    optionDiv.onclick = () => selectSingleOption(index);
                }
                
                optionDiv.dataset.index = index;
                optionsContainer.appendChild(optionDiv);
            });

            document.getElementById('currentQuestion').textContent = currentQuestionIndex + 1;
            document.getElementById('submitBtn').disabled = true;
            document.getElementById('nextBtn').disabled = true;
            updateProgressBar();
        }

        function selectSingleOption(index) {
            document.querySelectorAll('.option').forEach(opt => opt.classList.remove('selected'));
            document.querySelector(`[data-index="${index}"]`).classList.add('selected');
            document.getElementById('submitBtn').disabled = false;
        }

        function toggleMultipleOption(index) {
            const option = document.querySelector(`[data-index="${index}"]`);
            const checkbox = option.querySelector('.option-checkbox');
            
            if (option.classList.contains('selected')) {
                option.classList.remove('selected');
                checkbox.checked = false;
            } else {
                option.classList.add('selected');
                checkbox.checked = true;
            }
            
            // Enable submit if at least one option is selected
            const selectedCount = document.querySelectorAll('.option.selected').length;
            document.getElementById('submitBtn').disabled = selectedCount === 0;
        }

        function getSelectedAnswers() {
            const question = questions[currentQuestionIndex];
            const selected = [];
            
            document.querySelectorAll('.option.selected').forEach(opt => {
                selected.push(parseInt(opt.dataset.index));
            });
            
            return selected.sort((a, b) => a - b); // Sort for comparison
        }

        function submitAnswer() {
            const selectedAnswers = getSelectedAnswers();
            if (selectedAnswers.length === 0) return;

            const question = questions[currentQuestionIndex];
            const correctAnswers = [...question.correct].sort((a, b) => a - b);
            
            // Calculate correctness
            let isCorrect = false;
            let isPartial = false;
            
            if (question.type === 'single') {
                isCorrect = selectedAnswers.length === 1 && selectedAnswers[0] === correctAnswers[0];
            } else {
                // Multiple choice scoring
                const selectedSet = new Set(selectedAnswers);
                const correctSet = new Set(correctAnswers);
                
                if (selectedAnswers.length === correctAnswers.length && 
                    selectedAnswers.every(ans => correctSet.has(ans))) {
                    isCorrect = true;
                } else {
                    // Partial credit if some answers are correct
                    const correctSelected = selectedAnswers.filter(ans => correctSet.has(ans));
                    const incorrectSelected = selectedAnswers.filter(ans => !correctSet.has(ans));
                    
                    if (correctSelected.length > 0 && incorrectSelected.length === 0) {
                        isPartial = true; // Selected some correct, no incorrect
                    }
                }
            }

            userAnswers[currentQuestionIndex] = {
                questionId: question.id,
                selected: selectedAnswers,
                correct: correctAnswers,
                isCorrect: isCorrect,
                isPartial: isPartial,
                timeSpent: Date.now() - startTime,
                type: question.type
            };

            // Show results
            document.querySelectorAll('.option').forEach((opt, index) => {
                const isSelectedCorrect = correctAnswers.includes(index);
                const isSelectedByUser = selectedAnswers.includes(index);
                
                if (isSelectedCorrect) {
                    opt.classList.add('correct');
                } else if (isSelectedByUser) {
                    opt.classList.add('incorrect');
                }
                
                opt.onclick = null; // Disable clicking
            });

            // Show explanation
            const explanationDiv = document.createElement('div');
            let resultClass = 'incorrect';
            let resultText = '‚ùå Sai r·ªìi!';
            
            if (isCorrect) {
                resultClass = 'correct';
                resultText = '‚úÖ Ch√≠nh x√°c!';
            } else if (isPartial) {
                resultClass = 'partial';
                resultText = '‚ö†Ô∏è ƒê√∫ng m·ªôt ph·∫ßn!';
            }
            
            explanationDiv.className = `explanation ${resultClass}`;
            explanationDiv.innerHTML = `
                <strong>${resultText}</strong><br>
                <strong>ƒê√°p √°n ƒë√∫ng:</strong> ${correctAnswers.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                <strong>B·∫°n ch·ªçn:</strong> ${selectedAnswers.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                <em>Gi·∫£i th√≠ch:</em> ${question.explanation}
            `;
            document.getElementById('optionsContainer').appendChild(explanationDiv);

            document.getElementById('submitBtn').style.display = 'none';
            document.getElementById('nextBtn').disabled = false;
            updateStats();
        }

        function nextQuestion() {
            if (currentQuestionIndex < questions.length - 1) {
                currentQuestionIndex++;
                loadQuestion();
                document.getElementById('submitBtn').style.display = 'inline-block';
            } else {
                showReview();
            }
        }

        function previousQuestion() {
            if (currentQuestionIndex > 0) {
                currentQuestionIndex--;
                loadQuestion();
                document.getElementById('submitBtn').style.display = 'inline-block';
            }
        }

        function updateStats() {
            const answered = userAnswers.filter(a => a).length;
            const correct = userAnswers.filter(a => a && a.isCorrect).length;
            const partial = userAnswers.filter(a => a && a.isPartial).length;
            const accuracy = answered > 0 ? Math.round(((correct + partial * 0.5) / answered) * 100) : 0;

            document.getElementById('correctCount').textContent = correct + (partial > 0 ? ` (+${partial} partial)` : '');
            document.getElementById('wrongCount').textContent = answered - correct - partial;
            document.getElementById('accuracy').textContent = accuracy + '%';
        }

        function updateProgressBar() {
            const progress = ((currentQuestionIndex + 1) / questions.length) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        }

        function startTimer() {
            timer = setInterval(() => {
                const elapsed = Math.floor((Date.now() - startTime) / 1000);
                const minutes = Math.floor(elapsed / 60);
                const seconds = elapsed % 60;
                document.getElementById('timeSpent').textContent = 
                    `${minutes}:${seconds.toString().padStart(2, '0')}`;
            }, 1000);
        }

        function showReview() {
            clearInterval(timer);
            document.getElementById('studyMode').classList.add('hidden');
            document.getElementById('reviewMode').classList.remove('hidden');

            const correct = userAnswers.filter(a => a.isCorrect).length;
            const partial = userAnswers.filter(a => a.isPartial).length;
            const total = userAnswers.length;
            const accuracy = Math.round(((correct + partial * 0.5) / total) * 100);

            document.getElementById('reviewStats').innerHTML = `
                <div class="stats">
                    <div class="stat-card">
                        <div class="stat-number">${correct}/${total}</div>
                        <div>Ho√†n to√†n ƒë√∫ng</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">${partial}</div>
                        <div>ƒê√∫ng m·ªôt ph·∫ßn</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">${accuracy}%</div>
                        <div>ƒêi·ªÉm t·ªïng</div>
                    </div>
                </div>
            `;

            // Show wrong answers for review
            const wrongAnswers = userAnswers.filter(a => !a.isCorrect);
            if (wrongAnswers.length > 0) {
                document.getElementById('wrongAnswers').innerHTML = `
                    <h3>üîÑ C√¢u c·∫ßn √¥n l·∫°i (${wrongAnswers.length} c√¢u):</h3>
                    ${wrongAnswers.map(a => `
                        <div class="wrong-answer">
                            <strong>C√¢u ${a.questionId} (${a.type === 'multiple' ? 'Multiple' : 'Single'} Choice):</strong><br>
                            B·∫°n ch·ªçn: ${a.selected.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                            ƒê√°p √°n ƒë√∫ng: ${a.correct.map(i => String.fromCharCode(65 + i)).join(', ')}
                            ${a.isPartial ? ' <span style="color: #856404;">(ƒê√∫ng m·ªôt ph·∫ßn)</span>' : ''}
                        </div>
                    `).join('')}
                `;
            }
        }

        function restartStudy() {
            currentQuestionIndex = 0;
            userAnswers = [];
            startTime = Date.now();
            document.getElementById('studyMode').classList.remove('hidden');
            document.getElementById('reviewMode').classList.add('hidden');
            initializeApp();
        }

        function exportResults() {
            const results = {
                date: new Date().toLocaleDateString('vi-VN'),
                day: 1,
                questions: questions.length,
                correct: userAnswers.filter(a => a.isCorrect).length,
                partial: userAnswers.filter(a => a.isPartial).length,
                accuracy: Math.round(((userAnswers.filter(a => a.isCorrect).length + userAnswers.filter(a => a.isPartial).length * 0.5) / userAnswers.length) * 100),
                wrongQuestions: userAnswers.filter(a => !a.isCorrect).map(a => ({
                    id: a.questionId,
                    type: a.type,
                    selected: a.selected,
                    correct: a.correct,
                    isPartial: a.isPartial
                })),
                timeSpent: document.getElementById('timeSpent').textContent
            };

            const blob = new Blob([JSON.stringify(results, null, 2)], {type: 'application/json'});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `aws-devops-results-${new Date().toISOString().split('T')[0]}.json`;
            a.click();
        }

        // Initialize app when page loads
        window.onload = initializeApp;
    </script>
</body>
</html>
