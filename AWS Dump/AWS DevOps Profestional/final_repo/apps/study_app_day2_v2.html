<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS DevOps Study App</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #f5f5f5; }
        .container { max-width: 900px; margin: 0 auto; padding: 20px; }
        .header { background: #232f3e; color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; }
        .progress-bar { background: #ddd; height: 10px; border-radius: 5px; margin: 10px 0; }
        .progress { background: #ff9900; height: 100%; border-radius: 5px; transition: width 0.3s; }
        .question-card { background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-bottom: 20px; }
        .question-text { font-size: 18px; line-height: 1.6; margin-bottom: 20px; }
        .question-type { background: #e3f2fd; color: #1976d2; padding: 8px 16px; border-radius: 20px; font-size: 14px; font-weight: bold; margin-bottom: 15px; display: inline-block; }
        .options { margin: 20px 0; }
        .option { background: #f8f9fa; border: 2px solid #e9ecef; padding: 15px; margin: 10px 0; border-radius: 8px; cursor: pointer; transition: all 0.3s; position: relative; }
        .option:hover { border-color: #ff9900; }
        .option.selected { border-color: #ff9900; background: #fff3cd; }
        .option.correct { border-color: #28a745; background: #d4edda; }
        .option.incorrect { border-color: #dc3545; background: #f8d7da; }
        .option.partial { border-color: #ffc107; background: #fff3cd; }
        .option-checkbox { position: absolute; right: 15px; top: 50%; transform: translateY(-50%); width: 20px; height: 20px; }
        .controls { display: flex; gap: 15px; justify-content: center; margin-top: 20px; }
        .btn { padding: 12px 24px; border: none; border-radius: 6px; cursor: pointer; font-size: 16px; transition: all 0.3s; }
        .btn-primary { background: #ff9900; color: white; }
        .btn-primary:hover { background: #e68900; }
        .btn-secondary { background: #6c757d; color: white; }
        .btn-secondary:hover { background: #545b62; }
        .btn:disabled { background: #ccc; cursor: not-allowed; }
        .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px; }
        .stat-card { background: white; padding: 20px; border-radius: 8px; text-align: center; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        .stat-number { font-size: 24px; font-weight: bold; color: #ff9900; }
        .review-section { background: white; padding: 20px; border-radius: 10px; margin-top: 20px; }
        .wrong-answer { background: #fff3cd; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #ffc107; }
        .hidden { display: none; }
        .explanation { margin-top: 20px; padding: 15px; border-radius: 8px; }
        .explanation.correct { background: #d4edda; border-left: 4px solid #28a745; }
        .explanation.incorrect { background: #f8d7da; border-left: 4px solid #dc3545; }
        .explanation.partial { background: #fff3cd; border-left: 4px solid #ffc107; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üöÄ AWS DevOps Professional Study App</h1>
            <div class="progress-bar">
                <div class="progress" id="progressBar"></div>
            </div>
            <p>Ng√†y <span id="currentDay">2</span> - C√¢u <span id="currentQuestion">1</span>/<span id="totalQuestions">0</span></p>
        </div>

        <div class="stats">
            <div class="stat-card">
                <div class="stat-number" id="correctCount">0</div>
                <div>C√¢u ƒë√∫ng</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="wrongCount">0</div>
                <div>C√¢u sai</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="accuracy">0%</div>
                <div>ƒê·ªô ch√≠nh x√°c</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="timeSpent">0:00</div>
                <div>Th·ªùi gian</div>
            </div>
        </div>

        <div id="studyMode" class="question-card">
            <div class="question-type" id="questionType">Single Choice</div>
            <div class="question-text" id="questionText">
                ƒêang t·∫£i c√¢u h·ªèi...
            </div>
            <div class="options" id="optionsContainer">
                <!-- Options will be loaded here -->
            </div>
            <div class="controls">
                <button class="btn btn-secondary" onclick="previousQuestion()">‚¨ÖÔ∏è C√¢u tr∆∞·ªõc</button>
                <button class="btn btn-primary" onclick="submitAnswer()" id="submitBtn" disabled>X√°c nh·∫≠n</button>
                <button class="btn btn-secondary" onclick="nextQuestion()" id="nextBtn" disabled>C√¢u ti·∫øp ‚û°Ô∏è</button>
            </div>
        </div>

        <div id="reviewMode" class="review-section hidden">
            <h2>üìä K·∫øt qu·∫£ h·ªçc t·∫≠p</h2>
            <div id="reviewStats"></div>
            <div id="wrongAnswers"></div>
            <div class="controls">
                <button class="btn btn-primary" onclick="restartStudy()">üîÑ H·ªçc l·∫°i</button>
                <button class="btn btn-secondary" onclick="exportResults()">üíæ Xu·∫•t k·∫øt qu·∫£</button>
            </div>
        </div>
    </div>

    <script>
        // Sample questions with both single and multiple choice
        let questions = [
    {
        "id": 1,
        "text": "A company runs an application on Amazon EC2 instances. The company uses a series of AWS CloudFormation stacks to define the application resources. A developer performs updates by building and testing the application on a laptop and then uploading the build output and CloudFormation stack templates to Amazon S3. The developer's peers review the changes before the developer performs the CloudFormation stack update and installs a new version of the application onto the EC2 instances.The deployment process is prone to errors and is time-consuming when the developer updates each EC2 instance with the new application. The company wants to automate as much of the application deployment process as possible while retaining a final manual approval step before the modification of the application or resources.The company already has moved the source code for the application and the CloudFormation templates to AWS CodeCommit. The company also has created an AWS CodeBuild project to build and test the application.Which combination of steps will meet the company‚Äôs requirements? (Choose two.)",
        "options": [
            "Create an application group and a deployment group in AWS CodeDeploy. Install the CodeDeploy agent on the EC2 instances.",
            "Use AWS CodePipeline to invoke the CodeBuild job, run the CloudFormation update, and pause for a manual approval step. After approval, start the AWS CodeDeploy deployment.",
            "Use AWS CodePipeline to invoke the CodeBuild job, create CloudFormation change sets for each of the application stacks, and pause for a manual approval step. After approval, run the CloudFormation change sets and start the AWS CodeDeploy deployment.",
            "Create an application revision and a deployment group in AWS CodeDeploy. Create an environment in CodeDeploy. Register the EC2 instances to the CodeDeploy environment.",
            "Use AWS CodePipeline to invoke the CodeBuild job, create CloudFormation change sets for each of the application stacks, and pause for a manual approval step. After approval, start the AWS CodeDeploy deployment."
        ],
        "correct": [
            0,
            2
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 2,
        "text": "A DevOps engineer manages a web application that runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an EC2 Auto Scaling group across multiple Availability Zones. The engineer needs to implement a deployment strategy that:Launches a second fleet of instances with the same capacity as the original fleet.Maintains the original fleet unchanged while the second fleet is launched.Transitions traffic to the second fleet when the second fleet is fully deployed.Terminates the original fleet automatically 1 hour after transition.Which solution will satisfy these requirements?",
        "options": [
            "Use two AWS Elastic Beanstalk environments to perform a blue/green deployment from the original environment to the new one. Create an application version lifecycle policy to terminate the original environment in 1 hour.",
            "Use AWS CodeDeploy with a deployment group configured with a blue/green deployment configuration Select the option Terminate the original instances in the deployment group with a waiting period of 1 hour.",
            "Use an AWS CloudFormation template with a retention policy for the ALB set to 1 hour. Update the Amazon Route 53 record to reflect the new ALB.",
            "Use AWS Elastic Beanstalk with the configuration set to Immutable. Create an .ebextension using the Resources key that sets the deletion policy of the ALB to 1 hour, and deploy the application."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 3,
        "text": "A company has enabled all features for its organization in AWS Organizations. The organization contains 10 AWS accounts. The company has turned on AWS CloudTrail in all the accounts. The company expects the number of AWS accounts in the organization to increase to 500 during the next year. The company plans to use multiple OUs for these accounts.The company has enabled AWS Config in each existing AWS account in the organization. A DevOps engineer must implement a solution that enables AWS Config automatically for all future AWS accounts that are created in the organization.Which solution will meet this requirement?",
        "options": [
            "In the organization's management account, create an Amazon EventBridge rule that reacts to a CreateAccount API call. Configure the rule to invoke an AWS Systems Manager Automation runbook to enable AWS Config for the account.",
            "In the organization's management account, create an AWS CloudFormation stack set to enable AWS Config. Configure the stack set to deploy automatically when an account is created through Organizations.",
            "In the organization's management account, create an Amazon EventBridge rule that reacts to a CreateAccount API call. Configure the rule to invoke an AWS Lambda function that enables trusted access to AWS Config for the organization.",
            "In the organization's management account, create an SCP that allows the appropriate AWS Config API calls to enable AWS Config. Apply the SCP to the root-level OU."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 4,
        "text": "A company is running an application on Amazon EC2 instances in an Auto Scaling group. Recently, an issue occurred that prevented EC2 instances from launching successfully, and it took several hours for the support team to discover the issue. The support team wants to be notified by email whenever an EC2 instance does not start successfully.Which action will accomplish this?",
        "options": [
            "Create a status check alarm on Amazon EC2 to send a notification to an Amazon SNS topic whenever a status check fail occurs.",
            "Configure the Auto Scaling group to send a notification to an Amazon SNS topic whenever a failed instance launch occurs.",
            "Add a health check to the Auto Scaling group to invoke an AWS Lambda function whenever an instance status is impaired.",
            "Create an Amazon CloudWatch alarm that invokes an AWS Lambda function when a failed AttachInstances Auto Scaling API call is made."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 5,
        "text": "A company is performing vulnerability scanning for all Amazon EC2 instances across many accounts. The accounts are in an organization in AWS Organizations. Each account's VPCs are attached to a shared transit gateway. The VPCs send traffic to the internet through a central egress VPC. The company has enabled Amazon Inspector in a delegated administrator account and has enabled scanning for all member accounts.A DevOps engineer discovers that some EC2 instances are listed in the \"not scanning\" tab in Amazon Inspector.Which combination of actions should the DevOps engineer take to resolve this issue? (Choose three.)",
        "options": [
            "Configure EC2 Instance Connect for the EC2 instances that Amazon Inspector is not scanning.",
            "Grant inspector:StartAssessmentRun permissions to the IAM role that the DevOps engineer is using.",
            "Associate the target EC2 instances with security groups that allow outbound communication on port 443 to the AWS Systems Manager service endpoint.",
            "Create a managed-instance activation. Use the Activation Code and the Activation ID to register the EC2 instances.",
            "Associate the target EC2 instances with instance profiles that grant permissions to communicate with AWS Systems Manager.",
            "Verify that AWS Systems Manager Agent is installed and is running on the EC2 instances that Amazon Inspector is not scanning."
        ],
        "correct": [
            2,
            4,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 6,
        "text": "A company is developing a new application. The application uses AWS Lambda functions for its compute tier. The company must use a canary deployment for any changes to the Lambda functions. Automated rollback must occur if any failures are reported.The company‚Äôs DevOps team needs to create the infrastructure as code (IaC) and the CI/CD pipeline for this solution.Which combination of steps will meet these requirements? (Choose three.)",
        "options": [
            "Create an Amazon CloudWatch alarm for each Lambda function. Configure the alarms to enter the ALARM state if any errors are detected. Configure an evaluation period, dimensions for each Lambda function and version, and the namespace as AWS/Lambda on the Errors metric.",
            "Create an AWS CodeCommit repository. Create an AWS CodePipeline pipeline. Use the CodeCommit repository in a new source stage that starts the pipeline. Create an AWS CodeDeploy deployment group that is configured for canary deployments with a DeploymentPreference type of Canary10Percent10Minutes. Upload the AWS CloudFormation template and source code to the CodeCommit repository. In the CodeCommit repository, create an appspec.yml file that includes the commands to deploy the CloudFormation template.",
            "Create an Amazon CloudWatch composite alarm for all the Lambda functions. Configure an evaluation period and dimensions for Lambda. Configure the alarm to enter the ALARM state if any errors are detected or if there is insufficient data.",
            "Create an AWS CodeCommit repository. Create an AWS CodePipeline pipeline. Use the CodeCommit repository in a new source stage that starts the pipeline. Create an AWS CodeBuild project to deploy the AWS Serverless Application Model (AWS SAM) template. Upload the template and source code to the CodeCommit repository. In the CodeCommit repository, create a buildspec.yml file that includes the commands to build and deploy the SAM application.",
            "Create an AWS Serverless Application Model (AWS SAM) template for the application. Define each Lambda function in the template by using the AWS::Serverless::Function resource type. For each function, include configurations for the AutoPublishAlias property and the DeploymentPreference property. Configure the deployment configuration type to LambdaCanary10Percent10Minutes.",
            "Create an AWS CloudFormation template for the application. Define each Lambda function in the template by using the AWS::Lambda::Function resource type. In the template, include a version for the Lambda function by using the AWS::Lambda::Version resource type. Declare the CodeSha256 property. Configure an AWS::Lambda::Alias resource that references the latest version of the Lambda function."
        ],
        "correct": [
            0,
            3,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 7,
        "text": "A DevOps engineer needs to apply a core set of security controls to an existing set of AWS accounts. The accounts are in an organization in AWS Organizations. Individual teams will administer individual accounts by using the AdministratorAccess AWS managed policy. For all accounts. AWS CloudTrail and AWS Config must be turned on in all available AWS Regions. Individual account administrators must not be able to edit or delete any of the baseline resources. However, individual account administrators must be able to edit or delete their own CloudTrail trails and AWS Config rules.Which solution will meet these requirements in the MOST operationally efficient way?",
        "options": [
            "Create an AWS CloudFormation template that defines the standard account resources. Deploy the template to all accounts from the organization's management account by using Cloud Formation StackSets Create an SCP that prevents updates or deletions to CloudTrail resources or AWS Config resources unless the principal is an administrator of the organization's management account.",
            "Create an AWS CloudFormation template that defines the standard account resources. Deploy the template to all accounts from the organization's management account by using CloudFormation StackSets. Set the stack policy to deny Update:Delete actions.",
            "Designate an AWS Config management account. Create AWS Config recorders in all accounts by using AWS CloudFormation StackSets. Deploy AWS Config rules to the organization by using the AWS Config management account. Create a CloudTrail organization trail in the organization‚Äôs management account. Deny modification or deletion of the AWS Config recorders by using an SCP.",
            "Enable AWS Control Tower. Enroll the existing accounts in AWS Control Tower. Grant the individual account administrators access to CloudTrail and AWS Config."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 8,
        "text": "A company wants to set up a continuous delivery pipeline. The company stores application code in a private GitHub repository. The company needs to deploy the application components to Amazon Elastic Container Service (Amazon ECS). Amazon EC2, and AWS Lambda. The pipeline must support manual approval actions.Which solution will meet these requirements?",
        "options": [
            "Use AWS CodeDeploy with GitHub integration to deploy the application.",
            "Use AWS CodePipeline with AWS CodeDeploy as the deploy provider.",
            "Use AWS CodePipeline with AWS Elastic Beanstalk as the deploy provider.",
            "Use AWS CodePipeline with Amazon ECS. Amazon EC2, and Lambda as deploy providers."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 9,
        "text": "A company uses AWS CloudFormation stacks to deploy updates to its application. The stacks consist of different resources. The resources include AWS Auto Scaling groups, Amazon EC2 instances, Application Load Balancers (ALBs), and other resources that are necessary to launch and maintain independent stacks. Changes to application resources outside of CloudFormation stack updates are not allowed.The company recently attempted to update the application stack by using the AWS CLI. The stack failed to update and produced the following error message: ‚ÄúERROR: both the deployment and the CloudFormation stack rollback failed. The deployment failed because the following resource(s) failed to update: [AutoScalingGroup].‚ÄùThe stack remains in a status of UPDATE_ROLLBACK_FAILED.Which solution will resolve this issue?",
        "options": [
            "Update the subnet mappings that are configured for the ALBs. Run the aws cloudformation update-stack-set AWS CLI command.",
            "Update the IAM role by providing the necessary permissions to update the stack. Run the aws cloudformation continue-update-rollback AWS CLI command.",
            "Delete the Auto Scaling group resource. Run the aws cloudformation rollback-stack AWS CLI command.",
            "Submit a request for a quota increase for the number of EC2 instances for the account. Run the aws cloudformation cancel-update-stack AWS CLI command."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 10,
        "text": "A company manages an application that stores logs in Amazon CloudWatch Logs. The company wants to archive the logs to an Amazon S3 bucket. Logs are rarely accessed after 90 days and must be retained for 10 years.Which combination of steps should a DevOps engineer take to meet these requirements? (Choose two.)",
        "options": [
            "Configure a CloudWatch Logs subscription filter to use AWS Glue to transfer all logs to an S3 bucket.",
            "Configure the S3 bucket lifecycle policy to transition logs to Reduced Redundancy after 90 days and to expire logs after 3.650 days.",
            "Configure a CloudWatch Logs subscription filter to use Amazon Kinesis Data Firehose to stream all logs to an S3 bucket.",
            "Configure a CloudWatch Logs subscription filter to stream all logs to an S3 bucket.",
            "Configure the S3 bucket lifecycle policy to transition logs to S3 Glacier after 90 days and to expire logs after 3.650 days."
        ],
        "correct": [
            2,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 11,
        "text": "A DevOps engineer has automated a web service deployment by using AWS CodePipeline with the following steps:1. An AWS CodeBuild project compiles the deployment artifact and runs unit tests.2. An AWS CodeDeploy deployment group deploys the web service to Amazon EC2 instances in the staging environment.3. A CodeDeploy deployment group deploys the web service to EC2 instances in the production environment.The quality assurance (QA) team requests permission to inspect the build artifact before the deployment to the production environment occurs. The QA team wants to run an internal penetration testing tool to conduct manual tests. The tool will be invoked by a REST API call.Which combination of actions should the DevOps engineer take to fulfill this request? (Choose two.)",
        "options": [
            "Insert a manual approval action between the test actions and deployment actions of the pipeline.",
            "Update the CodeDeploy deployment groups so that they require manual approval to proceed.",
            "Update the pipeline to invoke an AWS Lambda function that calls the REST API for the penetration testing tool.",
            "Modify the buildspec.yml file for the compilation stage to require manual approval before completion.",
            "Update the pipeline to directly call the REST API for the penetration testing tool."
        ],
        "correct": [
            0,
            2
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 12,
        "text": "A production account has a requirement that any Amazon EC2 instance that has been logged in to manually must be terminated within 24 hours. All applications in the production account are using Auto Scaling groups with the Amazon CloudWatch Logs agent configured.How can this process be automated?",
        "options": [
            "Create an Amazon CloudWatch alarm that will be invoked by the login event. Configure the alarm to send to an Amazon Simple Queue Service (Amazon SQS) queue. Use a group of worker instances to process messages from the queue, which then schedules an Amazon EventBridge rule to be invoked.",
            "Create a CloudWatch Logs subscription to an AWS Step Functions application. Configure an AWS Lambda function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Create an Amazon EventBridge rule to invoke a second Lambda function once a day that will terminate all instances with this tag.",
            "Create an Amazon CloudWatch alarm that will be invoked by the login event. Send the notification to an Amazon Simple Notification Service (Amazon SNS) topic that the operations team is subscribed to, and have them terminate the EC2 instance within 24 hours.",
            "Create a CloudWatch Logs subscription to an AWS Lambda function. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Create an Amazon EventBridge rule to invoke a daily Lambda function that terminates all instances with this tag."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 13,
        "text": "A company has 20 service teams. Each service team is responsible for its own microservice. Each service team uses a separate AWS account for its microservice and a VPC with the 192.168.0.0/22 CIDR block. The company manages the AWS accounts with AWS Organizations.Each service team hosts its microservice on multiple Amazon EC2 instances behind an Application Load Balancer. The microservices communicate with each other across the public internet. The company‚Äôs security team has issued a new guideline that all communication between microservices must use HTTPS over private network connections and cannot traverse the public internet.A DevOps engineer must implement a solution that fulfills these obligations and minimizes the number of changes for each service team.Which solution will meet these requirements?",
        "options": [
            "Create a new AWS account in AWS Organizations. Create a VPC in this account, and use AWS Resource Access Manager to share the private subnets of this VPC with the organization. Instruct the service teams to launch a new Network Load Balancer (NLB) and EC2 instances that use the shared private subnets. Use the NLB DNS names for communication between microservices.",
            "Create a Network Load Balancer (NLB) in each of the microservice VPCs. Use AWS PrivateLink to create VPC endpoints in each AWS account for the NLBs. Create subscriptions to each VPC endpoint in each of the other AWS accounts. Use the VPC endpoint DNS names for communication between microservices.",
            "Create a Network Load Balancer (NLB) in each of the microservice VPCs. Create VPC peering connections between each of the microservice VPCs. Update the route tables for each VPC to use the peering links. Use the NLB DNS names for communication between microservices.",
            "Create a new AWS account in AWS Organizations. Create a transit gateway in this account, and use AWS Resource Access Manager to share the transit gateway with the organization. In each of the microservice VPCs, create a transit gateway attachment to the shared transit gateway. Update the route tables of each VPC to use the transit gateway. Create a Network Load Balancer (NLB) in each of the microservice VPCs. Use the NLB DNS names for communication between microservices."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 14,
        "text": "A company has an application that runs on Amazon EC2 instances that are in an Auto Scaling group. When the application starts up. the application needs to process data from an Amazon S3 bucket before the application can start to serve requests.The size of the data that is stored in the S3 bucket is growing. When the Auto Scaling group adds new instances, the application now takes several minutes to download and process the data before the application can serve requests. The company must reduce the time that elapses before new EC2 instances are ready to serve requests.Which solution is the MOST cost-effective way to reduce the application startup time?",
        "options": [
            "Configure a warm pool for the Auto Scaling group with warmed EC2 instances in the Running state. Configure an autoscaling:EC2_INSTANCE_LAUNCHING lifecycle hook on the Auto Scaling group. Modify the application to complete the lifecycle hook when the application is ready to serve requests.",
            "Increase the maximum instance count of the Auto Scaling group. Configure an autoscaling:EC2_INSTANCE_LAUNCHING lifecycle hook on the Auto Scaling group. Modify the application to complete the lifecycle hook when the application is ready to serve requests.",
            "Increase the maximum instance count of the Auto Scaling group. Configure an autoscaling:EC2_INSTANCE_LAUNCHING lifecycle hook on the Auto Scaling group. Modify the application to complete the lifecycle hook and to place the new instance in the Standby state when the application is ready to serve requests.",
            "Configure a warm pool for the Auto Scaling group with warmed EC2 instances in the Stopped state. Configure an autoscaling:EC2_INSTANCE_LAUNCHING lifecycle hook on the Auto Scaling group. Modify the application to complete the lifecycle hook when the application is ready to serve requests."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 15,
        "text": "A company deploys updates to its Amazon API Gateway API several times a week by using an AWS CodePipeline pipeline. As part of the update process, the company exports the JavaScript SDK for the API from the API Gateway console and uploads the SDK to an Amazon S3 bucket.The company has configured an Amazon CloudFront distribution that uses the S3 bucket as an origin. Web clients then download the SDK by using the CloudFront distribution‚Äôs endpoint. A DevOps engineer needs to implement a solution to make the new SDK available automatically during new API deployments.Which solution will meet these requirements?",
        "options": [
            "Create an Amazon EventBridge rule that reacts to CreateDeployment events from aws.apigateway. Configure the rule to invoke an AWS Lambda function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and call the S3 API to invalidate the cache for the SDK path.",
            "Create a CodePipeline action immediately after the deployment stage of the API. Configure the action to invoke an AWS Lambda function. Configure the Lambda function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and create a CloudFront invalidation for the SDK path.",
            "Create a CodePipeline action immediately after the deployment stage of the API. Configure the action to use the CodePipeline integration with API Gateway to export the SDK to Amazon S3. Create another action that uses the CodePipeline integration with Amazon S3 to invalidate the cache for the SDK path.",
            "Create an Amazon EventBridge rule that reacts to UpdateStage events from aws.apigateway. Configure the rule to invoke an AWS Lambda function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and call the CloudFront API to create an invalidation for the SDK path."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 16,
        "text": "A DevOps engineer manages a large commercial website that runs on Amazon EC2. The website uses Amazon Kinesis Data Streams to collect and process web logs. The DevOps engineer manages the Kinesis consumer application, which also runs on Amazon EC2.Sudden increases of data cause the Kinesis consumer application to fall behind, and the Kinesis data streams drop records before the records can be processed. The DevOps engineer must implement a solution to improve stream handling.Which solution meets these requirements with the MOST operational efficiency?",
        "options": [
            "Convert the Kinesis consumer application to run as an AWS Lambda function. Configure the Kinesis data streams as the event source for the Lambda function to process the data streams.",
            "Horizontally scale the Kinesis consumer application by adding more EC2 instances based on the Amazon CloudWatch GetRecords.IteratorAgeMilliseconds metric. Increase the retention period of the Kinesis data streams.",
            "Modify the Kinesis consumer application to store the logs durably in Amazon S3. Use Amazon EMR to process the data directly on Amazon S3 to derive customer insights. Store the results in Amazon S3.",
            "Increase the number of shards in the Kinesis data streams to increase the overall throughput so that the consumer application processes the data faster."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 17,
        "text": "A DevOps engineer at a company is supporting an AWS environment in which all users use AWS IAM Identity Center (AWS Single Sign-On). The company wants to immediately disable credentials of any new IAM user and wants the security team to receive a notification.Which combination of steps should the DevOps engineer take to meet these requirements? (Choose three.)",
        "options": [
            "Create an Amazon EventBridge rule that reacts to an IAM GetLoginProfile API call in AWS CloudTrail.",
            "Create an Amazon Simple Notification Service (Amazon SNS) topic that is a target of the EventBridge rule. Subscribe the security team's group email address to the topic.",
            "Create an Amazon Simple Queue Service (Amazon SQS) queue that is a target of the Lambda function. Subscribe the security team's group email address to the queue.",
            "Create an AWS Lambda function that is a target of the EventBridge rule. Configure the Lambda function to disable any access keys and delete the login profiles that are associated with the IAM user.",
            "Create an Amazon EventBridge rule that reacts to an IAM CreateUser API call in AWS CloudTrail.",
            "Create an AWS Lambda function that is a target of the EventBridge rule. Configure the Lambda function to delete the login profiles that are associated with the IAM user."
        ],
        "correct": [
            1,
            3,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 18,
        "text": "A company wants to migrate its content sharing web application hosted on Amazon EC2 to a serverless architecture. The company currently deploys changes to its application by creating a new Auto Scaling group of EC2 instances and a new Elastic Load Balancer, and then shifting the traffic away using an Amazon Route 53 weighted routing policy.For its new serverless application, the company is planning to use Amazon API Gateway and AWS Lambda. The company will need to update its deployment processes to work with the new application. It will also need to retain the ability to test new features on a small number of users before rolling the features out to the entire user base.Which deployment strategy will meet these requirements?",
        "options": [
            "Use AWS CDK to deploy API Gateway and Lambda functions. When code needs to be changed, update the AWS CloudFormation stack and deploy the new version of the APIs and Lambda functions. Use a Route 53 failover routing policy for the canary release strategy.",
            "Use AWS Elastic Beanstalk to deploy API Gateway and Lambda functions. When code needs to be changed, deploy a new version of the API and Lambda functions. Shift traffic gradually using an Elastic Beanstalk blue/green deployment.",
            "Use AWS CloudFormation to deploy API Gateway and Lambda functions using Lambda function versions. When code needs to be changed, update the CloudFormation stack with the new Lambda code and update the API versions using a canary release strategy. Promote the new version when testing is complete.",
            "Use AWS OpsWorks to deploy API Gateway in the service layer and Lambda functions in a custom layer. When code needs to be changed, use OpsWorks to perform a blue/green deployment and shift traffic gradually."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 19,
        "text": "An application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). A DevOps engineer is using AWS CodeDeploy to release a new version. The deployment fails during the AllowTraffic lifecycle event, but a cause for the failure is not indicated in the deployment logs.What would cause this?",
        "options": [
            "The health checks specified for the ALB target group are misconfigured.",
            "The appspec.yml file contains an invalid script that runs in the AllowTraffic lifecycle hook.",
            "The CodeDeploy agent was not installed in the EC2 instances that are part of the ALB target group.",
            "The user who initiated the deployment does not have the necessary permissions to interact with the ALB."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 20,
        "text": "A company is using Amazon S3 buckets to store important documents. The company discovers that some S3 buckets are not encrypted. Currently, the company‚Äôs IAM users can create new S3 buckets without encryption. The company is implementing a new requirement that all S3 buckets must be encrypted.A DevOps engineer must implement a solution to ensure that server-side encryption is enabled on all existing S3 buckets and all new S3 buckets. The encryption must be enabled on new S3 buckets as soon as the S3 buckets are created. The default encryption type must be 256-bit Advanced Encryption Standard (AES-256).Which solution will meet these requirements?",
        "options": [
            "Set up and activate the s3-bucket-server-side-encryption-enabled AWS Config managed rule. Configure the rule to use the AWS-EnableS3BucketEncryption AWS Systems Manager Automation runbook as the remediation action. Manually run the re-evaluation process to ensure that existing S3 buckets are compliant.",
            "Configure an IAM policy that denies the s3:CreateBucket action if the s3:x-amz-server-side-encryption condition key has a value that is not AES-256. Create an IAM group for all the company‚Äôs IAM users. Associate the IAM policy with the IAM group.",
            "Create an AWS Lambda function that is invoked periodically by an Amazon EventBridge scheduled rule. Program the Lambda function to scan all current S3 buckets for encryption status and to set AES-256 as the default encryption for any S3 bucket that does not have an encryption configuration.",
            "Create an AWS Lambda function that is invoked by an Amazon EventBridge event rule. Define the rule with an event pattern that matches the creation of new S3 buckets. Program the Lambda function to parse the EventBridge event, check the configuration of the S3 buckets from the event, and set AES-256 as the default encryption."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 21,
        "text": "A company's application is currently deployed to a single AWS Region. Recently, the company opened a new office on a different continent. The users in the new office are experiencing high latency. The company's application runs on Amazon EC2 instances behind an Application Load Balancer (ALB) and uses Amazon DynamoDB as the database layer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones. A DevOps engineer is tasked with minimizing application response times and improving availability for users in both Regions.Which combination of actions should be taken to address the latency issues? (Choose three.)",
        "options": [
            "Create Amazon Route 53 records, health checks, and latency-based routing policies to route to the ALB.",
            "Create a new DynamoDB table in the new Region with cross-Region replication enabled.",
            "Create new ALB and Auto Scaling group resources in the new Region and configure the new ALB to direct traffic to the new Auto Scaling group.",
            "Create new ALB and Auto Scaling group global resources and configure the new ALB to direct traffic to the new Auto Scaling group.",
            "Convert the DynamoDB table to a global table.",
            "Create Amazon Route 53 aliases, health checks, and failover routing policies to route to the ALB."
        ],
        "correct": [
            0,
            2,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 22,
        "text": "A company has an application that runs on a fleet of Amazon EC2 instances. The application requires frequent restarts. The application logs contain error messages when a restart is required. The application logs are published to a log group in Amazon CloudWatch Logs.An Amazon CloudWatch alarm notifies an application engineer through an Amazon Simple Notification Service (Amazon SNS) topic when the logs contain a large number of restart-related error messages. The application engineer manually restarts the application on the instances after the application engineer receives a notification from the SNS topic.A DevOps engineer needs to implement a solution to automate the application restart on the instances without restarting the instances.Which solution will meet these requirements in the MOST operationally efficient manner?",
        "options": [
            "Configure an AWS Systems Manager Automation runbook that runs a script to restart the application on the instances. Configure an Amazon EventBridge rule that reacts when the CloudWatch alarm enters ALARM state. Specify the runbook as a target of the rule.",
            "Create an AWS Lambda function that restarts the application on the instances. Configure the Lambda function as an event destination of the SNS topic.",
            "Configure an AWS Systems Manager Automation runbook that runs a script to restart the application on the instances. Configure the SNS topic to invoke the runbook.",
            "Configure an AWS Systems Manager Automation runbook that runs a script to restart the application on the instances. Create an AWS Lambda function to invoke the runbook. Configure the Lambda function as an event destination of the SNS topic."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 23,
        "text": "A company has a guideline that every Amazon EC2 instance must be launched from an AMI that the company‚Äôs security team produces. Every month, the security team sends an email message with the latest approved AMIs to all the development teams.The development teams use AWS CloudFormation to deploy their applications. When developers launch a new service, they have to search their email for the latest AMIs that the security department sent. A DevOps engineer wants to automate the process that the security team uses to provide the AMI IDs to the development teams.What is the MOST scalable solution that meets these requirements?",
        "options": [
            "Direct the security team to use CloudFormation to create new versions of the AMIs and to list the AMI ARNs in an encrypted Amazon S3 object as part of the stack‚Äôs Outputs section. Instruct the developers to use a cross-stack reference to load the encrypted S3 object and obtain the most recent AMI ARNs.",
            "Direct the security team to use Amazon EC2 Image Builder to create new AMIs and to create an Amazon Simple Notification Service (Amazon SNS) topic so that every development team can receive notifications. When the development teams receive a notification, instruct them to write an AWS Lambda function that will update their CloudFormation stack with the most recent AMI ARNs.",
            "Direct the security team to use a CloudFormation stack to create an AWS CodePipeline pipeline that builds new AMIs and places the latest AMI ARNs in an encrypted Amazon S3 object as part of the pipeline output. Instruct the developers to use a cross-stack reference within their own CloudFormation template to obtain the S3 object location and the most recent AMI ARNs.",
            "Direct the security team to use Amazon EC2 Image Builder to create new AMIs and to place the AMI ARNs as parameters in AWS Systems Manager Parameter Store. Instruct the developers to specify a parameter of type SSM in their CloudFormation stack to obtain the most recent AMI ARNs from Parameter Store."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 24,
        "text": "A development team uses AWS CodeCommit, AWS CodePipeline, and AWS CodeBuild to develop and deploy an application. Changes to the code are submitted by pull requests. The development team reviews and merges the pull requests, and then the pipeline builds and tests the application.Over time, the number of pull requests has increased. The pipeline is frequently blocked because of failing tests. To prevent this blockage, the development team wants to run the unit and integration tests on each pull request before it is merged.Which solution will meet these requirements?",
        "options": [
            "Create an Amazon EventBridge rule to match pullRequestCreated events from CodeCommit Create a CodeBuild project to run the unit and integration tests. Configure the CodeBuild project as a target of the EventBridge rule that includes a custom event payload with the CodeCommit repository and branch information from the event.",
            "Create an Amazon EventBridge rule to match pullRequestCreated events from CodeCommit. Modify the existing CodePipeline pipeline to not run the deploy steps if the build is started from a pull request. Configure the EventBridge rule to run the pipeline with a custom payload that contains the CodeCommit repository and branch information from the event.",
            "Create a CodeBuild project to run the unit and integration tests. Create a CodeCommit notification rule that matches when a pull request is created or updated. Configure the notification rule to invoke the CodeBuild project.",
            "Create a CodeBuild project to run the unit and integration tests. Create a CodeCommit approval rule template. Configure the template to require the successful invocation of the CodeBuild project. Attach the approval rule to the project's CodeCommit repository."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 25,
        "text": "A company has many applications. Different teams in the company developed the applications by using multiple languages and frameworks. The applications run on premises and on different servers with different operating systems. Each team has its own release protocol and process. The company wants to reduce the complexity of the release and maintenance of these applications.The company is migrating its technology stacks, including these applications, to AWS. The company wants centralized control of source code, a consistent and automatic delivery pipeline, and as few maintenance tasks as possible on the underlying infrastructure.What should a DevOps engineer do to meet these requirements?",
        "options": [
            "Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build the applications one at a time. Use AWS CodeDeploy to deploy the applications to one centralized application server.",
            "Create one AWS CodeCommit repository for all applications. Put each application's code in a different branch. Merge the branches, and use AWS CodeBuild to build the applications. Use AWS CodeDeploy to deploy the applications to one centralized application server.",
            "Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build one Docker image for each application in Amazon Elastic Container Registry (Amazon ECR). Use AWS CodeDeploy to deploy the applications to Amazon Elastic Container Service (Amazon ECS) on infrastructure that AWS Fargate manages.",
            "Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build the applications one at a time and to create one AMI for each server. Use AWS CloudFormation StackSets to automatically provision and decommission Amazon EC2 fleets by using these AMIs."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 26,
        "text": "A company is using an AWS CodeBuild project to build and package an application. The packages are copied to a shared Amazon S3 bucket before being deployed across multiple AWS accounts.The buildspec.yml file contains the following:The DevOps engineer has noticed that anybody with an AWS account is able to download the artifacts.What steps should the DevOps engineer take to stop this?",
        "options": [
            "Modify the post_build command to use --acl public-read and configure a bucket policy that grants read access to the relevant AWS accounts only.",
            "Configure a default ACL for the S3 bucket that defines the set of authenticated users as the relevant AWS accounts only and grants read-only access.",
            "Modify the post_build command to remove --acl authenticated-read and configure a bucket policy that allows read access to the relevant AWS accounts only.",
            "Create an S3 bucket policy that grants read access to the relevant AWS accounts and denies read access to the principal ‚Äú*‚Äù."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 27,
        "text": "A business has an application that consists of five independent AWS Lambda functions.The DevOps engineer has built a CI/CD pipeline using AWS CodePipeline and AWS CodeBuild that builds, tests, packages, and deploys each Lambda function in sequence. The pipeline uses an Amazon EventBridge rule to ensure the pipeline starts as quickly as possible after a change is made to the application source code.After working with the pipeline for a few months, the DevOps engineer has noticed the pipeline takes too long to complete.What should the DevOps engineer implement to BEST improve the speed of the pipeline?",
        "options": [
            "Modify the CodePipeline configuration to run actions for each Lambda function in parallel by specifying the same runOrder.",
            "Modify each CodeBuild project to run within a VPC and use dedicated instances to increase throughput.",
            "Create a custom CodeBuild execution environment that includes a symmetric multiprocessing configuration to run the builds in parallel.",
            "Modify the CodeBuild projects within the pipeline to use a compute type with more available network throughput."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 28,
        "text": "An Amazon EC2 instance is running in a VPC and needs to download an object from a restricted Amazon S3 bucket. When the DevOps engineer tries to download the object, an AccessDenied error is received.What are the possible causes for this error? (Choose two.)",
        "options": [
            "The S3 bucket default encryption is enabled.",
            "The object has been moved to S3 Glacier.",
            "S3 Versioning is enabled.",
            "There is an error in the S3 bucket policy.",
            "There is an error in the IAM role configuration."
        ],
        "correct": [
            3,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 29,
        "text": "A company is implementing AWS CodePipeline to automate its testing process. The company wants to be notified when the execution state fails and used the following custom event pattern in Amazon EventBridge:Which type of events will match this event pattern?",
        "options": [
            "All rejected or failed approval actions across all the pipelines",
            "All the events across all pipelines",
            "Approval actions across all the pipelines",
            "Failed deploy and build actions across all the pipelines"
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 30,
        "text": "A company is hosting a static website from an Amazon S3 bucket. The website is available to customers at example.com. The company uses an Amazon Route 53 weighted routing policy with a TTL of 1 day. The company has decided to replace the existing static website with a dynamic web application. The dynamic web application uses an Application Load Balancer (ALB) in front of a fleet of Amazon EC2 instances.On the day of production launch to customers, the company creates an additional Route 53 weighted DNS record entry that points to the ALB with a weight of 255 and a TTL of 1 hour. Two days later, a DevOps engineer notices that the previous static website is displayed sometimes when customers navigate to example.com.How can the DevOps engineer ensure that the company serves only dynamic content for example.com?",
        "options": [
            "Configure webpage redirect requests on the S3 bucket with a hostname that redirects to the ALB.",
            "Delete all objects, including previous versions, from the S3 bucket that contains the static website content.",
            "Remove the weighted DNS record entry that points to the S3 bucket from the example.com hosted zone. Wait for DNS propagation to become complete.",
            "Update the weighted DNS record entry that points to the S3 bucket. Apply a weight of 0. Specify the domain reset option to propagate changes immediately."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 31,
        "text": "A company uses a single AWS account to test applications on Amazon EC2 instances. The company has turned on AWS Config in the AWS account and has activated the restricted-ssh AWS Config managed rule.The company needs an automated monitoring solution that will provide a customized notification in real time if any security group in the account is not compliant with the restricted-ssh rule. The customized notification must contain the name and ID of the noncompliant security group.A DevOps engineer creates an Amazon Simple Notification Service (Amazon SNS) topic in the account and subscribes the appropriate personnel to the topic.What should the DevOps engineer do next to meet these requirements?",
        "options": [
            "Create an Amazon EventBridge rule that matches an AWS Config evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure an input transformer for the EventBridge rule. Configure the EventBridge rule to publish a notification to the SNS topic.",
            "Configure AWS Config to send all evaluation results for the restricted-ssh rule to the SNS topic. Configure a filter policy on the SNS topic to send only notifications that contain the text of NON_COMPLIANT in the notification to subscribers.",
            "Create an Amazon EventBridge rule that matches all AWS Config evaluation results of NON_COMPLIANT. Configure an input transformer for the restricted-ssh rule. Configure the EventBridge rule to publish a notification to the SNS topic.",
            "Create an Amazon EventBridge rule that matches an AWS Config evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure the EventBridge rule to invoke AWS Systems Manager Run Command on the SNS topic to customize a notification and to publish the notification to the SNS topic."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 32,
        "text": "A company has deployed an application in a production VPC in a single AWS account. The application is popular and is experiencing heavy usage. The company‚Äôs security team wants to add additional security, such as AWS WAF, to the application deployment. However, the application's product manager is concerned about cost and does not want to approve the change unless the security team can prove that additional security is necessary.The security team believes that some of the application's demand might come from users that have IP addresses that are on a deny list. The security team provides the deny list to a DevOps engineer. If any of the IP addresses on the deny list access the application, the security team wants to receive automated notification in near real time so that the security team can document that the application needs additional security. The DevOps engineer creates a VPC flow log for the production VPC.Which set of additional steps should the DevOps engineer take to meet these requirements MOST cost-effectively?",
        "options": [
            "Create an Amazon S3 bucket for log files. Configure the VPC flow log to capture accepted traffic and to send the data to the S3 bucket. Configure an Amazon OpenSearch Service cluster and domain for the log files. Create an AWS Lambda function to retrieve the logs from the S3 bucket, format the logs, and load the logs into the OpenSearch Service cluster. Schedule the Lambda function to run every 5 minutes. Configure an alert and condition in OpenSearch Service to send alerts to the security team through an Amazon Simple Notification Service (Amazon SNS) topic when access from the IP addresses on the deny list is detected.",
            "Create an Amazon S3 bucket for log files. Configure the VPC flow log to capture all traffic and to send the data to the S3 bucket. Configure Amazon Athena to return all log files in the S3 bucket for IP addresses on the deny list. Configure Amazon QuickSight to accept data from Athena and to publish the data as a dashboard that the security team can access. Create a threshold alert of 1 for successful access. Configure the alert to automatically notify the security team as frequently as possible when the alert threshold is met.",
            "Create a log group in Amazon CloudWatch Logs. Create an Amazon S3 bucket to hold query results. Configure the VPC flow log to capture all traffic and to send the data to the log group. Deploy an Amazon Athena CloudWatch connector in AWS Lambda. Connect the connector to the log group. Configure Athena to periodically query for all accepted traffic from the IP addresses on the deny list and to store the results in the S3 bucket. Configure an S3 event notification to automatically notify the security team through an Amazon Simple Notification Service (Amazon SNS) topic when new objects are added to the S3 bucket.",
            "Create a log group in Amazon CloudWatch Logs. Configure the VPC flow log to capture accepted traffic and to send the data to the log group. Create an Amazon CloudWatch metric filter for IP addresses on the deny list. Create a CloudWatch alarm with the metric filter as input. Set the period to 5 minutes and the datapoints to alarm to 1. Use an Amazon Simple Notification Service (Amazon SNS) topic to send alarm notices to the security team."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 33,
        "text": "A company is using AWS Organizations to centrally manage its AWS accounts. The company has turned on AWS Config in each member account by using AWS CloudFormation StackSets. The company has configured trusted access in Organizations for AWS Config and has configured a member account as a delegated administrator account for AWS Config.A DevOps engineer needs to implement a new security policy. The policy must require all current and future AWS member accounts to use a common baseline of AWS Config rules that contain remediation actions that are managed from a central account. Non-administrator users who can access member accounts must not be able to modify this common baseline of AWS Config rules that are deployed into each member account.Which solution will meet these requirements?",
        "options": [
            "Create a CloudFormation template that contains the AWS Config rules and remediation actions. Deploy the template from the delegated administrator account by using AWS Config.",
            "Create a CloudFormation template that contains the AWS Config rules and remediation actions. Deploy the template from the Organizations management account by using CloudFormation StackSets.",
            "Create an AWS Config conformance pack that contains the AWS Config rules and remediation actions. Deploy the pack from the delegated administrator account by using AWS Config.",
            "Create an AWS Config conformance pack that contains the AWS Config rules and remediation actions. Deploy the pack from the Organizations management account by using CloudFormation StackSets."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 34,
        "text": "A company requires an RPO of 2 hours and an RTO of 10 minutes for its data and application at all times. An application uses a MySQL database and Amazon EC2 web servers. The development team needs a strategy for failover and disaster recovery.Which combination of deployment strategies will meet these requirements? (Choose two.)",
        "options": [
            "Set up the application in two Regions and use a multi-Region Auto Scaling group behind Application Load Balancers to manage the capacity based on demand. In the event of a disaster, adjust the Auto Scaling group‚Äôs desired instance count to increase baseline capacity in the failover Region.",
            "Set up the application in two Regions and use Amazon Route 53 failover-based routing that points to the Application Load Balancers in both Regions. Use health checks to determine the availability in a given Region. Use Auto Scaling groups in each Region to adjust capacity based on demand.",
            "Create an Amazon Aurora multi-master cluster across multiple Regions as the data store. Use a Network Load Balancer to balance the database traffic in different Regions.",
            "Create an Amazon Aurora global database in two Regions as the data store. In the event of a failure, promote the secondary Region as the primary for the application.",
            "Create an Amazon Aurora cluster in one Availability Zone across multiple Regions as the data store. Use Aurora‚Äôs automatic recovery capabilities in the event of a disaster."
        ],
        "correct": [
            1,
            3
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 35,
        "text": "A company is deploying a new application that uses Amazon EC2 instances. The company needs a solution to query application logs and AWS account API activity.Which solution will meet these requirements?",
        "options": [
            "Use the Amazon CloudWatch agent to send logs from the EC2 instances to Amazon S3. Use AWS CloudTrail to deliver the API logs to Amazon S3. Use Amazon Athena to query both sets of logs in Amazon S3.",
            "Use the Amazon CloudWatch agent to send logs from the EC2 instances to Amazon Kinesis. Configure AWS CloudTrail to deliver the API logs to Kinesis. Use Kinesis to load the data into Amazon Redshift. Use Amazon Redshift to query both sets of logs.",
            "Use the Amazon CloudWatch agent to send logs from the EC2 instances to Amazon CloudWatch Logs. Configure AWS CloudTrail to deliver the API logs to Amazon S3. Use CloudWatch to query both sets of logs.",
            "Use the Amazon CloudWatch agent to send logs from the EC2 instances to Amazon CloudWatch Logs. Configure AWS CloudTrail to deliver the API logs to CloudWatch Logs. Use CloudWatch Logs Insights to query both sets of logs."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 36,
        "text": "A DevOps engineer is deploying a new version of a company‚Äôs application in an AWS CodeDeploy deployment group associated with its Amazon EC2 instances. After some time, the deployment fails. The engineer realizes that all the events associated with the specific deployment ID are in a Skipped status, and code was not deployed in the instances associated with the deployment group.What are valid reasons for this failure? (Choose two.)",
        "options": [
            "The networking configuration does not allow the EC2 instances to reach the internet via a NAT gateway or internet gateway, and the CodeDeploy endpoint cannot be reached.",
            "An instance profile with proper permissions was not attached to the target EC2 instances.",
            "The target EC2 instances were not properly registered with the CodeDeploy endpoint.",
            "The IAM user who triggered the application deployment does not have permission to interact with the CodeDeploy endpoint.",
            "The appspec.yml file was not included in the application revision."
        ],
        "correct": [
            0,
            1
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 37,
        "text": "An application running on a set of Amazon EC2 instances in an Auto Scaling group requires a configuration file to operate. The instances are created and maintained with AWS CloudFormation. A DevOps engineer wants the instances to have the latest configuration file when launched, and wants changes to the configuration file to be reflected on all the instances with a minimal delay when the CloudFormation template is updated. Company policy requires that application configuration files be maintained along with AWS infrastructure configuration files in source control.Which solution will accomplish this?",
        "options": [
            "In the CloudFormation template, add an EC2 launch template resource. Place the configuration file content in the launch template. Configure the cfn-init script to run when the instance is launched, and configure the cfn-hup script to poll for updates to the configuration.",
            "In the CloudFormation template, add an AWS Config rule. Place the configuration file content in the rule‚Äôs InputParameters property, and set the Scope property to the EC2 Auto Scaling group. Add an AWS Systems Manager Resource Data Sync resource to the template to poll for updates to the configuration.",
            "In the CloudFormation template, add CloudFormation init metadata. Place the configuration file content in the metadata. Configure the cfn-init script to run when the instance is launched, and configure the cfn-hup script to poll for updates to the configuration.",
            "In the CloudFormation template, add an EC2 launch template resource. Place the configuration file content in the launch template. Add an AWS Systems Manager Resource Data Sync resource to the template to poll for updates to the configuration."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 38,
        "text": "A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances.Which solution will meet these requirements?",
        "options": [
            "Configure Amazon CloudWatch to detect vulnerabilities on the EC2 instances. Install the AWS Config daemon to capture system logs and view them in the AWS Config console.",
            "Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.",
            "Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the Amazon CloudWatch Agent to capture system logs and record them via Amazon CloudWatch Logs.",
            "Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to Amazon S3."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 39,
        "text": "A development team wants to use AWS CloudFormation stacks to deploy an application. However, the developer IAM role does not have the required permissions to provision the resources that are specified in the AWS CloudFormation template. A DevOps engineer needs to implement a solution that allows the developers to deploy the stacks. The solution must follow the principle of least privilege.Which solution will meet these requirements?",
        "options": [
            "Create an AWS CloudFormation service role that has the required permissions. Grant the developer IAM role a cloudformation:* action. Use the new service role during stack deployments.",
            "Create an IAM policy that allows full access to AWS CloudFormation. Attach the policy to the developer IAM role.",
            "Create an AWS CloudFormation service role that has the required permissions. Grant the developer IAM role the iam:PassRole permission. Use the new service role during stack deployments.",
            "Create an IAM policy that allows the developers to provision the required resources. Attach the policy to the developer IAM role."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 40,
        "text": "A company runs applications in AWS accounts that are in an organization in AWS Organizations. The applications use Amazon EC2 instances and Amazon S3.The company wants to detect potentially compromised EC2 instances, suspicious network activity, and unusual API activity in its existing AWS accounts and in any AWS accounts that the company creates in the future. When the company detects one of these events, the company wants to use an existing Amazon Simple Notification Service (Amazon SNS) topic to send a notification to its operational support team for investigation and remediation.Which solution will meet these requirements in accordance with AWS best practices?",
        "options": [
            "In the organization‚Äôs management account, create an AWS CloudTrail organization trail. Activate the organization trail in all AWS accounts in the organization. Create an SCP that enables VPC Flow Logs in each account in the organization. Configure AWS Security Hub for the organization. Create an Amazon EventBridge rule with an event pattern to match Security Hub events and to forward matching events to the SNS topic.",
            "In the organization‚Äôs management account, configure Amazon GuardDuty to add newly created AWS accounts by invitation and to send invitations to the existing AWS accounts. Create an AWS CloudFormation stack set that accepts the GuardDuty invitation and creates an Amazon EventBridge rule. Configure the rule with an event pattern to match GuardDuty events and to forward matching events to the SNS topic. Configure the CloudFormation stack set to deploy into all AWS accounts in the organization.",
            "In the organization‚Äôs management account, configure an AWS account as the AWS CloudTrail administrator account. In the CloudTrail administrator account, create a CloudTrail organization trail. Add the company‚Äôs existing AWS accounts to the organization trail. Create an SCP that enables VPC Flow Logs in each account in the organization. Configure AWS Security Hub for the organization. Create an Amazon EventBridge rule with an event pattern to match Security Hub events and to forward matching events to the SNS topic.",
            "In the organization‚Äôs management account, configure an AWS account as the Amazon GuardDuty administrator account. In the GuardDuty administrator account, add the company‚Äôs existing AWS accounts to GuardDuty as members. In the GuardDuty administrator account, create an Amazon EventBridge rule with an event pattern to match GuardDuty events and to forward matching events to the SNS topic."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 41,
        "text": "A DevOps engineer is working on a data archival project that requires the migration of on-premises data to an Amazon S3 bucket. The DevOps engineer develops a script that incrementally archives on-premises data that is older than 1 month to Amazon S3. Data that is transferred to Amazon S3 is deleted from the on-premises location. The script uses the S3 PutObject operation.During a code review, the DevOps engineer notices that the script does not verify whether the data was successfully copied to Amazon S3. The DevOps engineer must update the script to ensure that data is not corrupted during transmission. The script must use MD5 checksums to verify data integrity before the on-premises data is deleted.Which solutions for the script will meet these requirements? (Choose two.)",
        "options": [
            "Check the returned response for the ETag. Compare the returned ETag against the MD5 checksum.",
            "Include the checksum digest within the Metadata parameter as a name-value pair. After upload, use the S3 HeadObject operation to retrieve metadata from the object.",
            "Include the checksum digest within the tagging parameter as a URL query parameter.",
            "Include the MD5 checksum within the Content-MD5 parameter. Check the operation call‚Äôs return status to find out if an error was returned.",
            "Check the returned response for the VersionId. Compare the returned VersionId against the MD5 checksum."
        ],
        "correct": [
            0,
            3
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 42,
        "text": "A company is divided into teams. Each team has an AWS account, and all the accounts are in an organization in AWS Organizations. Each team must retain full administrative rights to its AWS account. Each team also must be allowed to access only AWS services that the company approves for use. AWS services must gain approval through a request and approval process.How should a DevOps engineer configure the accounts to meet these requirements?",
        "options": [
            "Use AWS CloudFormation StackSets to provision IAM policies in each account to deny access to restricted AWS services. In each account, configure AWS Config rules that ensure that the policies are attached to IAM principals in the account.",
            "Place all the accounts under a new top-level OU within the organization. Create an SCP that denies access to restricted AWS services. Attach the SCP to the OU.",
            "Create an SCP that allows access to only approved AWS services. Attach the SCP to the root OU of the organization. Remove the FullAWSAccess SCP from the root OU of the organization.",
            "Use AWS Control Tower to provision the accounts into OUs within the organization. Configure AWS Control Tower to enable AWS IAM Identity Center (AWS Single Sign-On). Configure IAM Identity Center to provide administrative access. Include deny policies on user roles for restricted AWS services."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 43,
        "text": "A company has developed a serverless web application that is hosted on AWS. The application consists of Amazon S3. Amazon API Gateway, several AWS Lambda functions, and an Amazon RDS for MySQL database. The company is using AWS CodeCommit to store the source code. The source code is a combination of AWS Serverless Application Model (AWS SAM) templates and Python code.A security audit and penetration test reveal that user names and passwords for authentication to the database are hardcoded within CodeCommit repositories. A DevOps engineer must implement a solution to automatically detect and prevent hardcoded secrets.What is the MOST secure solution that meets these requirements?",
        "options": [
            "Enable Amazon CodeGuru Profiler. Decorate the handler function with @with_lambda_profiler(). Manually review the recommendation report. Write the secret to AWS Systems Manager Parameter Store as a secure string. Update the SAM templates and the Python code to pull the secret from Parameter Store.",
            "Enable Amazon CodeGuru Profiler. Decorate the handler function with @with_lambda_profiler(). Manually review the recommendation report. Choose the option to protect the secret. Update the SAM templates and the Python code to pull the secret from AWS Secrets Manager.",
            "Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Manually check the code review for any recommendations. Choose the option to protect the secret. Update the SAM templates and the Python code to pull the secret from AWS Secrets Manager.",
            "Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Manually check the code review for any recommendations. Write the secret to AWS Systems Manager Parameter Store as a string. Update the SAM templates and the Python code to pull the secret from Parameter Store."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 44,
        "text": "A company recently created a new AWS Control Tower landing zone in a new organization in AWS Organizations. The landing zone must be able to demonstrate compliance with the Center for Internet Security (CIS) Benchmarks for AWS Foundations.The company‚Äôs security team wants to use AWS Security Hub to view compliance across all accounts. Only the security team can be allowed to view aggregated Security Hub findings. In addition, specific users must be able to view findings from their own accounts within the organization. All accounts must be enrolled in Security Hub after the accounts are created.Which combination of steps will meet these requirements in the MOST automated way? (Choose three.)",
        "options": [
            "In the organization‚Äôs management account, create an Amazon EventBridge rule that reacts to the CreateManagedAccount event. Create an AWS Lambda function that uses the Security Hub CreateMembers API operation to add new accounts to Security Hub. Configure the EventBridge rule to invoke the Lambda function.",
            "Turn on trusted access for Security Hub in the organization‚Äôs management account. Create a new security account by using AWS Control Tower. Configure the new security account as the delegated administrator account for Security Hub. In the new security account, provide Security Hub with the CIS Benchmarks for AWS Foundations standards.",
            "Create an AWS IAM Identity Center (AWS Single Sign-On) permission set that includes the required permissions. Use the CreateAccountAssignment API operation to associate the security team users with the permission set and with the delegated security account.",
            "Create an SCP that explicitly denies any user who is not on the security team from accessing Security Hub.",
            "In Security Hub, turn on automatic enablement.",
            "Turn on trusted access for Security Hub in the organization‚Äôs management account. From the management account, provide Security Hub with the CIS Benchmarks for AWS Foundations standards."
        ],
        "correct": [
            1,
            2,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 45,
        "text": "A company is hosting a web application in an AWS Region. For disaster recovery purposes, a second region is being used as a standby. Disaster recovery requirements state that session data must be replicated between regions in near-real time and 1% of requests should route to the secondary region to continuously verify system functionality. Additionally, if there is a disruption in service in the main region, traffic should be automatically routed to the secondary region, and the secondary region must be able to scale up to handle all traffic.How should a DevOps engineer meet these requirements?",
        "options": [
            "In both regions, launch the application in Auto Scaling groups and use DynamoDB for session data. Use a Route 53 failover routing policy with health checks to distribute the traffic across the regions.",
            "In both regions, deploy the application on AWS Elastic Beanstalk and use Amazon DynamoDB global tables for session data. Use an Amazon Route 53 weighted routing policy with health checks to distribute the traffic across the regions.",
            "In both regions, launch the application in Auto Scaling groups and use DynamoDB global tables for session data. Enable an Amazon CloudFront weighted distribution across regions. Point the Amazon Route 53 DNS record at the CloudFront distribution.",
            "In both regions, deploy the application in AWS Lambda, exposed by Amazon API Gateway, and use Amazon RDS for PostgreSQL with cross-region replication for session data. Deploy the web application with client-side logic to call the API Gateway directly."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 46,
        "text": "A company‚Äôs DevOps engineer is working in a multi-account environment. The company uses AWS Transit Gateway to route all outbound traffic through a network operations account. In the network operations account, all account traffic passes through a firewall appliance for inspection before the traffic goes to an internet gateway.The firewall appliance sends logs to Amazon CloudWatch Logs and includes event severities of CRITICAL, HIGH, MEDIUM, LOW, and INFO. The security team wants to receive an alert if any CRITICAL events occur.What should the DevOps engineer do to meet these requirements?",
        "options": [
            "Use AWS Firewall Manager to apply consistent policies across all accounts. Create an Amazon EventBridge event rule that is invoked by Firewall Manager events that are CRITICAL. Define an Amazon Simple Notification Service (Amazon SNS) topic as a target. Subscribe the security team‚Äôs email address to the topic.",
            "Create an Amazon CloudWatch metric filter by using a search for CRITICAL events. Publish a custom metric for the finding. Use a CloudWatch alarm based on the custom metric to publish a notification to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team‚Äôs email address to the topic.",
            "Enable Amazon GuardDuty in the network operations account. Configure GuardDuty to monitor flow logs. Create an Amazon EventBridge event rule that is invoked by GuardDuty events that are CRITICAL. Define an Amazon Simple Notification Service (Amazon SNS) topic as a target. Subscribe the security team‚Äôs email address to the topic.",
            "Create an Amazon CloudWatch Synthetics canary to monitor the firewall state. If the firewall reaches a CRITICAL state or logs a CRITICAL event, use a CloudWatch alarm to publish a notification to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team‚Äôs email address to the topic."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 47,
        "text": "A company wants to use a grid system for a proprietary enterprise in-memory data store on top of AWS. This system can run in multiple server nodes in any Linux-based distribution. The system must be able to reconfigure the entire cluster every time a node is added or removed. When adding or removing nodes, an /etc/cluster/nodes.config file must be updated, listing the IP addresses of the current node members of that cluster.The company wants to automate the task of adding new nodes to a cluster.What can a DevOps engineer do to meet these requirements?",
        "options": [
            "Create an Amazon S3 bucket and upload a version of the /etc/cluster/nodes.config file. Create a crontab script that will poll for that S3 file and download it frequently. Use a process manager, such as Monit or systemd, to restart the cluster services when it detects that the new file was modified. When adding a node to the cluster, edit the file‚Äôs most recent members. Upload the new file to the S3 bucket.",
            "Create a user data script that lists all members of the current security group of the cluster and automatically updates the /etc/cluster/nodes.config file whenever a new instance is added to the cluster.",
            "Use AWS OpsWorks Stacks to layer the server nodes of that cluster. Create a Chef recipe that populates the content of the /etc/cluster/nodes.config file and restarts the service by using the current members of the layer. Assign that recipe to the Configure lifecycle event.",
            "Put the file nodes.config in version control. Create an AWS CodeDeploy deployment configuration and deployment group based on an Amazon EC2 tag value for the cluster nodes. When adding a new node to the cluster, update the file with all tagged instances, and make a commit in version control. Deploy the new file and restart the services."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 48,
        "text": "A company has developed an AWS Lambda function that handles orders received through an API. The company is using AWS CodeDeploy to deploy the Lambda function as the final stage of a CI/CD pipeline.A DevOps engineer has noticed there are intermittent failures of the ordering API for a few seconds after deployment. After some investigation, the DevOps engineer believes the failures are due to database changes not having fully propagated before the Lambda function is invoked.How should the DevOps engineer overcome this?",
        "options": [
            "Add a ValidateService hook to the AppSpec file that inspects incoming traffic and rejects the payload if dependent services, such as the database, are not yet ready.",
            "Add a BeforeAllowTraffic hook to the AppSpec file that tests and waits for any necessary database changes before traffic can flow to the new version of the Lambda function.",
            "Add an AfterAllowTraffic hook to the AppSpec file that forces traffic to wait for any pending database changes before allowing the new version of the Lambda function to respond.",
            "Add a BeforeInstall hook to the AppSpec file that tests and waits for any necessary database changes before deploying the new version of the Lambda function."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 49,
        "text": "A DevOps engineer is architecting a continuous development strategy for a company‚Äôs software as a service (SaaS) web application running on AWS. For application and security reasons, users subscribing to this application are distributed across multiple Application Load Balancers (ALBs), each of which has a dedicated Auto Scaling group and fleet of Amazon EC2 instances. The application does not require a build stage, and when it is committed to AWS CodeCommit, the application must trigger a simultaneous deployment to all ALBs, Auto Scaling groups, and EC2 fleets.Which architecture will meet these requirements with the LEAST amount of configuration?",
        "options": [
            "Create a single AWS CodePipeline pipeline that deploys the application in parallel using a single AWS CodeDeploy application and unique deployment group for each ALB-Auto Scaling group pair.",
            "Create a single AWS CodePipeline pipeline that deploys the application in parallel using unique AWS CodeDeploy applications and deployment groups created for each ALB-Auto Scaling group pair.",
            "Create an AWS CodePipeline pipeline for each ALB-Auto Scaling group pair that deploys the application using an AWS CodeDeploy application and deployment group created for the same ALB-Auto Scaling group pair.",
            "Create a single AWS CodePipeline pipeline that deploys the application using a single AWS CodeDeploy application and single deployment group."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 50,
        "text": "A company has its AWS accounts in an organization in AWS Organizations. AWS Config is manually configured in each AWS account. The company needs to implement a solution to centrally configure AWS Config for all accounts in the organization The solution also must record resource changes to a central account.Which combination of actions should a DevOps engineer perform to meet these requirements? (Choose two.)",
        "options": [
            "Configure a delegated administrator account for AWS Config. Enable trusted access for AWS Config in the organization.",
            "Create an AWS Config organization aggregator in the delegated administrator account. Configure data collection from all AWS accounts in the organization and from all AWS Regions.",
            "Create an AWS CloudFormation template to create an AWS Config aggregator. Configure a CloudFormation stack set to deploy the template to all accounts in the organization.",
            "Configure a delegated administrator account for AWS Config. Create a service-linked role for AWS Config in the organization‚Äôs management account.",
            "Create an AWS Config organization aggregator in the organization's management account. Configure data collection from all AWS accounts in the organization and from all AWS Regions."
        ],
        "correct": [
            0,
            1
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 51,
        "text": "A development team uses AWS CodeCommit for version control for applications. The development team uses AWS CodePipeline, AWS CodeBuild. and AWS CodeDeploy for CI/CD infrastructure. In CodeCommit, the development team recently merged pull requests that did not pass long-running tests in the code base. The development team needed to perform rollbacks to branches in the codebase, resulting in lost time and wasted effort.A DevOps engineer must automate testing of pull requests in CodeCommit to ensure that reviewers more easily see the results of automated tests as part of the pull request review.What should the DevOps engineer do to meet this requirement?",
        "options": [
            "Create an Amazon EventBridge rule that reacts to the pullRequestStatusChanged event. Create an AWS Lambda function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild badge as a comment on the pull request so that developers will see the badge in their code review.",
            "Create an Amazon EventBridge rule that reacts to the pullRequestCreated event. Create an AWS Lambda function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild test results as a comment on the pull request when the test results are complete.",
            "Create an Amazon EventBridge rule that reacts to pullRequestCreated and pullRequestSourceBranchUpdated events. Create an AWS Lambda function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild badge as a comment on the pull request so that developers will see the badge in their code review.",
            "Create an Amazon EventBridge rule that reacts to the pullRequestStatusChanged event. Create an AWS Lambda function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild test results as a comment on the pull request when the test results are complete."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 52,
        "text": "A video-sharing company stores its videos in Amazon S3. The company has observed a sudden increase in video access requests, but the company does not know which videos are most popular. The company needs to identify the general access pattern for the video files. This pattern includes the number of users who access a certain file on a given day, as well as the number of pull requests for certain files.How can the company meet these requirements with the LEAST amount of effort?",
        "options": [
            "Activate S3 server access logging. Use Amazon Athena to create an external table with the log files. Use Athena to create a SQL query to analyze the access patterns.",
            "Activate S3 server access logging. Import the access logs into an Amazon Aurora database. Use an Aurora SQL query to analyze the access patterns.",
            "Record an Amazon CloudWatch Logs log message for every S3 object access event. Configure a CloudWatch Logs log stream to write the file access information, such as user, S3 bucket, and file key, to an Amazon Kinesis Data Analytics for SQL application. Perform a sliding window analysis.",
            "Invoke an AWS Lambda function for every S3 object access event. Configure the Lambda function to write the file access information, such as user. S3 bucket, and file key, to an Amazon Aurora database. Use an Aurora SQL query to analyze the access patterns."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    }
]
        let currentQuestionIndex = 0;
        let userAnswers = [];
        let startTime = Date.now();
        let timer;

        function initializeApp() {
            document.getElementById('totalQuestions').textContent = questions.length;
            loadQuestion();
            startTimer();
            updateStats();
        }

        function loadQuestion() {
            const question = questions[currentQuestionIndex];
            document.getElementById('questionText').innerHTML = `
                <strong>C√¢u ${question.id}:</strong><br><br>
                ${question.text}
            `;
            
            // Set question type indicator
            const typeElement = document.getElementById('questionType');
            if (question.type === 'multiple') {
                typeElement.textContent = `Multiple Choice (Choose ${question.correct.length})`;
                typeElement.style.background = '#fff3cd';
                typeElement.style.color = '#856404';
            } else {
                typeElement.textContent = 'Single Choice';
                typeElement.style.background = '#e3f2fd';
                typeElement.style.color = '#1976d2';
            }
            
            const optionsContainer = document.getElementById('optionsContainer');
            optionsContainer.innerHTML = '';
            
            question.options.forEach((option, index) => {
                const optionDiv = document.createElement('div');
                optionDiv.className = 'option';
                optionDiv.innerHTML = `
                    <strong>${String.fromCharCode(65 + index)}.</strong> ${option}
                    ${question.type === 'multiple' ? '<input type="checkbox" class="option-checkbox">' : ''}
                `;
                
                if (question.type === 'multiple') {
                    optionDiv.onclick = () => toggleMultipleOption(index);
                } else {
                    optionDiv.onclick = () => selectSingleOption(index);
                }
                
                optionDiv.dataset.index = index;
                optionsContainer.appendChild(optionDiv);
            });

            document.getElementById('currentQuestion').textContent = currentQuestionIndex + 1;
            document.getElementById('submitBtn').disabled = true;
            document.getElementById('nextBtn').disabled = true;
            updateProgressBar();
        }

        function selectSingleOption(index) {
            document.querySelectorAll('.option').forEach(opt => opt.classList.remove('selected'));
            document.querySelector(`[data-index="${index}"]`).classList.add('selected');
            document.getElementById('submitBtn').disabled = false;
        }

        function toggleMultipleOption(index) {
            const option = document.querySelector(`[data-index="${index}"]`);
            const checkbox = option.querySelector('.option-checkbox');
            
            if (option.classList.contains('selected')) {
                option.classList.remove('selected');
                checkbox.checked = false;
            } else {
                option.classList.add('selected');
                checkbox.checked = true;
            }
            
            // Enable submit if at least one option is selected
            const selectedCount = document.querySelectorAll('.option.selected').length;
            document.getElementById('submitBtn').disabled = selectedCount === 0;
        }

        function getSelectedAnswers() {
            const question = questions[currentQuestionIndex];
            const selected = [];
            
            document.querySelectorAll('.option.selected').forEach(opt => {
                selected.push(parseInt(opt.dataset.index));
            });
            
            return selected.sort((a, b) => a - b); // Sort for comparison
        }

        function submitAnswer() {
            const selectedAnswers = getSelectedAnswers();
            if (selectedAnswers.length === 0) return;

            const question = questions[currentQuestionIndex];
            const correctAnswers = [...question.correct].sort((a, b) => a - b);
            
            // Calculate correctness
            let isCorrect = false;
            let isPartial = false;
            
            if (question.type === 'single') {
                isCorrect = selectedAnswers.length === 1 && selectedAnswers[0] === correctAnswers[0];
            } else {
                // Multiple choice scoring
                const selectedSet = new Set(selectedAnswers);
                const correctSet = new Set(correctAnswers);
                
                if (selectedAnswers.length === correctAnswers.length && 
                    selectedAnswers.every(ans => correctSet.has(ans))) {
                    isCorrect = true;
                } else {
                    // Partial credit if some answers are correct
                    const correctSelected = selectedAnswers.filter(ans => correctSet.has(ans));
                    const incorrectSelected = selectedAnswers.filter(ans => !correctSet.has(ans));
                    
                    if (correctSelected.length > 0 && incorrectSelected.length === 0) {
                        isPartial = true; // Selected some correct, no incorrect
                    }
                }
            }

            userAnswers[currentQuestionIndex] = {
                questionId: question.id,
                selected: selectedAnswers,
                correct: correctAnswers,
                isCorrect: isCorrect,
                isPartial: isPartial,
                timeSpent: Date.now() - startTime,
                type: question.type
            };

            // Show results
            document.querySelectorAll('.option').forEach((opt, index) => {
                const isSelectedCorrect = correctAnswers.includes(index);
                const isSelectedByUser = selectedAnswers.includes(index);
                
                if (isSelectedCorrect) {
                    opt.classList.add('correct');
                } else if (isSelectedByUser) {
                    opt.classList.add('incorrect');
                }
                
                opt.onclick = null; // Disable clicking
            });

            // Show explanation
            const explanationDiv = document.createElement('div');
            let resultClass = 'incorrect';
            let resultText = '‚ùå Sai r·ªìi!';
            
            if (isCorrect) {
                resultClass = 'correct';
                resultText = '‚úÖ Ch√≠nh x√°c!';
            } else if (isPartial) {
                resultClass = 'partial';
                resultText = '‚ö†Ô∏è ƒê√∫ng m·ªôt ph·∫ßn!';
            }
            
            explanationDiv.className = `explanation ${resultClass}`;
            explanationDiv.innerHTML = `
                <strong>${resultText}</strong><br>
                <strong>ƒê√°p √°n ƒë√∫ng:</strong> ${correctAnswers.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                <strong>B·∫°n ch·ªçn:</strong> ${selectedAnswers.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                <em>Gi·∫£i th√≠ch:</em> ${question.explanation}
            `;
            document.getElementById('optionsContainer').appendChild(explanationDiv);

            document.getElementById('submitBtn').style.display = 'none';
            document.getElementById('nextBtn').disabled = false;
            updateStats();
        }

        function nextQuestion() {
            if (currentQuestionIndex < questions.length - 1) {
                currentQuestionIndex++;
                loadQuestion();
                document.getElementById('submitBtn').style.display = 'inline-block';
            } else {
                showReview();
            }
        }

        function previousQuestion() {
            if (currentQuestionIndex > 0) {
                currentQuestionIndex--;
                loadQuestion();
                document.getElementById('submitBtn').style.display = 'inline-block';
            }
        }

        function updateStats() {
            const answered = userAnswers.filter(a => a).length;
            const correct = userAnswers.filter(a => a && a.isCorrect).length;
            const partial = userAnswers.filter(a => a && a.isPartial).length;
            const accuracy = answered > 0 ? Math.round(((correct + partial * 0.5) / answered) * 100) : 0;

            document.getElementById('correctCount').textContent = correct + (partial > 0 ? ` (+${partial} partial)` : '');
            document.getElementById('wrongCount').textContent = answered - correct - partial;
            document.getElementById('accuracy').textContent = accuracy + '%';
        }

        function updateProgressBar() {
            const progress = ((currentQuestionIndex + 1) / questions.length) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        }

        function startTimer() {
            timer = setInterval(() => {
                const elapsed = Math.floor((Date.now() - startTime) / 1000);
                const minutes = Math.floor(elapsed / 60);
                const seconds = elapsed % 60;
                document.getElementById('timeSpent').textContent = 
                    `${minutes}:${seconds.toString().padStart(2, '0')}`;
            }, 1000);
        }

        function showReview() {
            clearInterval(timer);
            document.getElementById('studyMode').classList.add('hidden');
            document.getElementById('reviewMode').classList.remove('hidden');

            const correct = userAnswers.filter(a => a.isCorrect).length;
            const partial = userAnswers.filter(a => a.isPartial).length;
            const total = userAnswers.length;
            const accuracy = Math.round(((correct + partial * 0.5) / total) * 100);

            document.getElementById('reviewStats').innerHTML = `
                <div class="stats">
                    <div class="stat-card">
                        <div class="stat-number">${correct}/${total}</div>
                        <div>Ho√†n to√†n ƒë√∫ng</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">${partial}</div>
                        <div>ƒê√∫ng m·ªôt ph·∫ßn</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">${accuracy}%</div>
                        <div>ƒêi·ªÉm t·ªïng</div>
                    </div>
                </div>
            `;

            // Show wrong answers for review
            const wrongAnswers = userAnswers.filter(a => !a.isCorrect);
            if (wrongAnswers.length > 0) {
                document.getElementById('wrongAnswers').innerHTML = `
                    <h3>üîÑ C√¢u c·∫ßn √¥n l·∫°i (${wrongAnswers.length} c√¢u):</h3>
                    ${wrongAnswers.map(a => `
                        <div class="wrong-answer">
                            <strong>C√¢u ${a.questionId} (${a.type === 'multiple' ? 'Multiple' : 'Single'} Choice):</strong><br>
                            B·∫°n ch·ªçn: ${a.selected.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                            ƒê√°p √°n ƒë√∫ng: ${a.correct.map(i => String.fromCharCode(65 + i)).join(', ')}
                            ${a.isPartial ? ' <span style="color: #856404;">(ƒê√∫ng m·ªôt ph·∫ßn)</span>' : ''}
                        </div>
                    `).join('')}
                `;
            }
        }

        function restartStudy() {
            currentQuestionIndex = 0;
            userAnswers = [];
            startTime = Date.now();
            document.getElementById('studyMode').classList.remove('hidden');
            document.getElementById('reviewMode').classList.add('hidden');
            initializeApp();
        }

        function exportResults() {
            const results = {
                date: new Date().toLocaleDateString('vi-VN'),
                day: 1,
                questions: questions.length,
                correct: userAnswers.filter(a => a.isCorrect).length,
                partial: userAnswers.filter(a => a.isPartial).length,
                accuracy: Math.round(((userAnswers.filter(a => a.isCorrect).length + userAnswers.filter(a => a.isPartial).length * 0.5) / userAnswers.length) * 100),
                wrongQuestions: userAnswers.filter(a => !a.isCorrect).map(a => ({
                    id: a.questionId,
                    type: a.type,
                    selected: a.selected,
                    correct: a.correct,
                    isPartial: a.isPartial
                })),
                timeSpent: document.getElementById('timeSpent').textContent
            };

            const blob = new Blob([JSON.stringify(results, null, 2)], {type: 'application/json'});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `aws-devops-results-${new Date().toISOString().split('T')[0]}.json`;
            a.click();
        }

        // Initialize app when page loads
        window.onload = initializeApp;
    </script>
</body>
</html>
