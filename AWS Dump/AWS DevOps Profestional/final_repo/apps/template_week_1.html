<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS DevOps Study App</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #f5f5f5; }
        .container { max-width: 900px; margin: 0 auto; padding: 20px; }
        .header { background: #232f3e; color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; }
        .progress-bar { background: #ddd; height: 10px; border-radius: 5px; margin: 10px 0; }
        .progress { background: #ff9900; height: 100%; border-radius: 5px; transition: width 0.3s; }
        .question-card { background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-bottom: 20px; }
        .question-text { font-size: 18px; line-height: 1.6; margin-bottom: 20px; }
        .question-type { background: #e3f2fd; color: #1976d2; padding: 8px 16px; border-radius: 20px; font-size: 14px; font-weight: bold; margin-bottom: 15px; display: inline-block; }
        .options { margin: 20px 0; }
        .option { background: #f8f9fa; border: 2px solid #e9ecef; padding: 15px; margin: 10px 0; border-radius: 8px; cursor: pointer; transition: all 0.3s; position: relative; }
        .option:hover { border-color: #ff9900; }
        .option.selected { border-color: #ff9900; background: #fff3cd; }
        .option.correct { border-color: #28a745; background: #d4edda; }
        .option.incorrect { border-color: #dc3545; background: #f8d7da; }
        .option.partial { border-color: #ffc107; background: #fff3cd; }
        .option-checkbox { position: absolute; right: 15px; top: 50%; transform: translateY(-50%); width: 20px; height: 20px; }
        .controls { display: flex; gap: 15px; justify-content: center; margin-top: 20px; }
        .btn { padding: 12px 24px; border: none; border-radius: 6px; cursor: pointer; font-size: 16px; transition: all 0.3s; }
        .btn-primary { background: #ff9900; color: white; }
        .btn-primary:hover { background: #e68900; }
        .btn-secondary { background: #6c757d; color: white; }
        .btn-secondary:hover { background: #545b62; }
        .btn:disabled { background: #ccc; cursor: not-allowed; }
        .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px; }
        .stat-card { background: white; padding: 20px; border-radius: 8px; text-align: center; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        .stat-number { font-size: 24px; font-weight: bold; color: #ff9900; }
        .review-section { background: white; padding: 20px; border-radius: 10px; margin-top: 20px; }
        .wrong-answer { background: #fff3cd; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #ffc107; }
        .hidden { display: none; }
        .explanation { margin-top: 20px; padding: 15px; border-radius: 8px; }
        .explanation.correct { background: #d4edda; border-left: 4px solid #28a745; }
        .explanation.incorrect { background: #f8d7da; border-left: 4px solid #dc3545; }
        .explanation.partial { background: #fff3cd; border-left: 4px solid #ffc107; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üöÄ AWS DevOps Professional Study App</h1>
            <div class="progress-bar">
                <div class="progress" id="progressBar"></div>
            </div>
            <p>Ng√†y <span id="currentDay">1</span> - C√¢u <span id="currentQuestion">1</span>/<span id="totalQuestions">0</span></p>
        </div>

        <div class="stats">
            <div class="stat-card">
                <div class="stat-number" id="correctCount">0</div>
                <div>C√¢u ƒë√∫ng</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="wrongCount">0</div>
                <div>C√¢u sai</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="accuracy">0%</div>
                <div>ƒê·ªô ch√≠nh x√°c</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="timeSpent">0:00</div>
                <div>Th·ªùi gian</div>
            </div>
        </div>

        <div id="studyMode" class="question-card">
            <div class="question-type" id="questionType">Single Choice</div>
            <div class="question-text" id="questionText">
                ƒêang t·∫£i c√¢u h·ªèi...
            </div>
            <div class="options" id="optionsContainer">
                <!-- Options will be loaded here -->
            </div>
            <div class="controls">
                <button class="btn btn-secondary" onclick="previousQuestion()">‚¨ÖÔ∏è C√¢u tr∆∞·ªõc</button>
                <button class="btn btn-primary" onclick="submitAnswer()" id="submitBtn" disabled>X√°c nh·∫≠n</button>
                <button class="btn btn-secondary" onclick="nextQuestion()" id="nextBtn" disabled>C√¢u ti·∫øp ‚û°Ô∏è</button>
            </div>
        </div>

        <div id="reviewMode" class="review-section hidden">
            <h2>üìä K·∫øt qu·∫£ h·ªçc t·∫≠p</h2>
            <div id="reviewStats"></div>
            <div id="wrongAnswers"></div>
            <div class="controls">
                <button class="btn btn-primary" onclick="restartStudy()">üîÑ H·ªçc l·∫°i</button>
                <button class="btn btn-secondary" onclick="exportResults()">üíæ Xu·∫•t k·∫øt qu·∫£</button>
            </div>
        </div>
    </div>

    <script>
        // Sample questions with both single and multiple choice
        const questions =  [
    {
        "id": 1,
        "text": "A company must encrypt all AMIs that the company shares across accounts. A DevOps engineer has access to a source account where an unencrypted custom AMI has been built. The DevOps engineer also has access to a target account where an Amazon EC2 Auto Scaling group will launch EC2 instances from the AMI. The DevOps engineer must share the AMI with the target account.The company has created an AWS Key Management Service (AWS KMS) key in the source account.Which additional steps should the DevOps engineer perform to meet the requirements? (Choose three.)",
        "options": [
            "In the source account, copy the unencrypted AMI to an encrypted AMI. Specify the KMS key in the copy action.",
            "In the source account, modify the key policy to give the target account permissions to create a grant. In the target account, create a KMS grant that delegates permissions to the Auto Scaling group service-linked role.",
            "In the source account, create a KMS grant that delegates permissions to the Auto Scaling group service-linked role in the target account.",
            "In the source account, share the unencrypted AMI with the target account.",
            "In the source account, share the encrypted AMI with the target account.",
            "In the source account, copy the unencrypted AMI to an encrypted AMI. Specify the default Amazon Elastic Block Store (Amazon EBS) encryption key in the copy action."
        ],
        "correct": [
            0,
            1,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 2,
        "text": "A company uses AWS Storage Gateway in file gateway mode in front of an Amazon S3 bucket that is used by multiple resources. In the morning when business begins, users do not see the objects processed by a third party the previous evening. When a DevOps engineer looks directly at the S3 bucket, the data is there, but it is missing in Storage Gateway.Which solution ensures that all the updated third-party files are available in the morning?",
        "options": [
            "Instruct the third party to put data into the S3 bucket using AWS Transfer for SFTP.",
            "Configure a nightly Amazon EventBridge event to invoke an AWS Lambda function to run the RefreshCache command for Storage Gateway.",
            "Use S3 Same-Region Replication to replicate any changes made directly in the S3 bucket to Storage Gateway.",
            "Modify Storage Gateway to run in volume gateway mode."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 3,
        "text": "A company wants to use AWS CloudFormation for infrastructure deployment. The company has strict tagging and resource requirements and wants to limit the deployment to two Regions. Developers will need to deploy multiple versions of the same application.Which solution ensures resources are deployed in accordance with company policy?",
        "options": [
            "Create a Cloud Formation drift detection operation to find and remediate unapproved CloudFormation StackSets.",
            "Create AWS Trusted Advisor checks to find and remediate unapproved CloudFormation StackSets.",
            "Create AWS Service Catalog products with approved CloudFormation templates.",
            "Create CloudFormation StackSets with approved CloudFormation templates."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 4,
        "text": "A company hosts a security auditing application in an AWS account. The auditing application uses an IAM role to access other AWS accounts. All the accounts are in the same organization in AWS Organizations.A recent security audit revealed that users in the audited AWS accounts could modify or delete the auditing application's IAM role. The company needs to prevent any modification to the auditing application's IAM role by any entity other than a trusted administrator IAM role.Which solution will meet these requirements?",
        "options": [
            "Create an SCP that includes a Deny statement for changes to the auditing application's IAM role. Include a condition that allows the trusted administrator IAM role to make changes. Attach the SCP to the root of the organization.",
            "Create an IAM permissions boundary that includes a Deny statement for changes to the auditing application‚Äôs IAM role. Include a condition that allows the trusted administrator IAM role to make changes. Attach the permissions boundary to the auditing application's IAM role in the AWS accounts.",
            "Create an IAM permissions boundary that includes a Deny statement for changes to the auditing application's IAM role. Include a condition that allows the trusted administrator IAM role to make changes. Attach the permissions boundary to the audited AWS accounts.",
            "Create an SCP that includes an Allow statement for changes to the auditing application's IAM role by the trusted administrator IAM role. Include a Deny statement for changes by all other IAM principals. Attach the SCP to the IAM service in each AWS account where the auditing application has an IAM role."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 5,
        "text": "A DevOps engineer is creating an AWS CloudFormation template to deploy a web service. The web service will run on Amazon EC2 instances in a private subnet behind an Application Load Balancer (ALB). The DevOps engineer must ensure that the service can accept requests from clients that have IPv6 addresses.What should the DevOps engineer do with the CloudFormation template so that IPv6 clients can access the web service?",
        "options": [
            "Assign each EC2 instance an IPv6 Elastic IP address. Create a target group, and add the EC2 instances as targets. Create a listener on port 443 of the ALB, and associate the target group with the ALB.",
            "Replace the ALB with a Network Load Balancer (NLB). Add an IPv6 CIDR block to the VPC and subnets for the NLB, and assign the NLB an IPv6 Elastic IP address.",
            "Add an IPv6 CIDR block to the VPC and the private subnet for the EC2 instances. Create route table entries for the IPv6 network, use EC2 instance types that support IPv6, and assign IPv6 addresses to each EC2 instance.",
            "Add an IPv6 CIDR block to the VPC and subnets for the ALB. Create a listener on port 443. and specify the dualstack IP address type on the ALB. Create a target group, and add the EC2 instances as targets. Associate the target group with the ALB."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 6,
        "text": "A company has migrated its container-based applications to Amazon EKS and want to establish automated email notifications. The notifications sent to each email address are for specific activities related to EKS components. The solution will include Amazon SNS topics and an AWS Lambda function to evaluate incoming log events and publish messages to the correct SNS topic.Which logging solution will support these requirements?",
        "options": [
            "Enable Amazon S3 logging for the EKS components. Configure an Amazon CloudWatch subscription filter for each component with Lambda as the subscription feed destination.",
            "Enable Amazon S3 logging for the EKS components. Configure S3 PUT Object event notifications with AWS Lambda as the destination.",
            "Enable Amazon CloudWatch Logs to log the EKS components. Create a CloudWatch subscription filter for each component with Lambda as the subscription feed destination.",
            "Enable Amazon CloudWatch Logs to log the EKS components. Create CloudWatch Logs Insights queries linked to Amazon EventBridge events that invoke Lambda."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 7,
        "text": "A company requires that its internally facing web application be highly available. The architecture is made up of one Amazon EC2 web server instance and one NAT instance that provides outbound internet access for updates and accessing public data.Which combination of architecture adjustments should the company implement to achieve high availability? (Choose two.)",
        "options": [
            "Replace the NAT instance with a NAT gateway that spans multiple Availability Zones. Update the route tables.",
            "Create additional EC2 instances spanning multiple Availability Zones. Add an Application Load Balancer to split the load between them.",
            "Configure an Application Load Balancer in front of the EC2 instance. Configure Amazon CloudWatch alarms to recover the EC2 instance upon host failure.",
            "Add the NAT instance to an EC2 Auto Scaling group that spans multiple Availability Zones. Update the route tables.",
            "Replace the NAT instance with a NAT gateway in each Availability Zone. Update the route tables."
        ],
        "correct": [
            1,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 8,
        "text": "A company has an on-premises application that is written in Go. A DevOps engineer must move the application to AWS. The company's development team wants to enable blue/green deployments and perform A/B testing.Which solution will meet these requirements?",
        "options": [
            "Use AWS Elastic Beanstalk to host the application. Store a zipped version of the application in Amazon S3. Use that location to deploy new versions of the application. Use Elastic Beanstalk to manage the deployment options.",
            "Use Amazon Lightsail to deploy the application. Store the application in a zipped format in an Amazon S3 bucket. Use this zipped version to deploy new versions of the application to Lightsail. Use Lightsail deployment options to manage the deployment.",
            "Use AWS CodeArtifact to store the application code. Use AWS CodeDeploy to deploy the application to a fleet of Amazon EC2 instances. Use Elastic Load Balancing to distribute the traffic to the EC2 instances. When making changes to the application, upload a new version to CodeArtifact and create a new CodeDeploy deployment.",
            "Deploy the application on an Amazon EC2 instance, and create an AMI of the instance. Use the AMI to create an automatic scaling launch configuration that is used in an Auto Scaling group. Use Elastic Load Balancing to distribute traffic. When changes are made to the application, a new AMI will be created, which will initiate an EC2 instance refresh."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 9,
        "text": "A company wants to use AWS development tools to replace its current bash deployment scripts. The company currently deploys a LAMP application to a group of Amazon EC2 instances behind an Application Load Balancer (ALB). During the deployments, the company unit tests the committed application, stops and starts services, unregisters and re-registers instances with the load balancer, and updates file permissions. The company wants to maintain the same deployment functionality through the shift to using AWS services.Which solution will meet these requirements?",
        "options": [
            "Use AWS CodePipeline to trigger AWS CodeBuild to test the application. Use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services. Unregister and re-register the instances in the AWS CodeDeploy deployment group with the ALB. Update the appspec.yml file to update file permissions without a custom script.",
            "Use AWS CodePipeline to move the application from the AWS CodeCommit repository to AWS CodeDeploy. Use CodeDeploy's deployment group to test the application, unregister and re-register instances with the ALand restart services. Use the appspec.yml file to update file permissions without a custom script.",
            "Use AWS CodeBuild to test the application. Use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services, and deregister and register instances with the ALB. Use the appspec.yml file to update file permissions without a custom script.",
            "Use AWS CodePipeline to move the application source code from the AWS CodeCommit repository to AWS CodeDeploy. Use CodeDeploy to test the application. Use CodeDeploy's appspec.yml file to restart services and update permissions without a custom script. Use AWS CodeBuild to unregister and re-register instances with the ALB."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 10,
        "text": "A DevOps engineer is building a multistage pipeline with AWS CodePipeline to build, verify, stage, test, and deploy an application. A manual approval stage is required between the test stage and the deploy stage. The development team uses a custom chat tool with webhook support that requires near-real-time notifications.How should the DevOps engineer configure status updates for pipeline activity and approval requests to post to the chat tool?",
        "options": [
            "Create an Amazon CloudWatch Logs subscription that filters on CodePipeline Pipeline Execution State Change. Publish subscription events to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the chat webhook URL to the SNS topic, and complete the subscription validation.",
            "Create an AWS Lambda function that is invoked by AWS CloudTrail events. When a CodePipeline Pipeline Execution State Change event is detected, send the event details to the chat webhook URL.",
            "Modify the pipeline code to send the event details to the chat webhook URL at the end of each stage. Parameterize the URL so that each pipeline can send to a different URL based on the pipeline environment.",
            "Create an Amazon EventBridge rule that filters on CodePipeline Pipeline Execution State Change. Publish the events to an Amazon Simple Notification Service (Amazon SNS) topic. Create an AWS Lambda function that sends event details to the chat webhook URL. Subscribe the function to the SNS topic."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 11,
        "text": "A space exploration company receives telemetry data from multiple satellites. Small packets of data are received through Amazon API Gateway and are placed directly into an Amazon Simple Queue Service (Amazon SQS) standard queue. A custom application is subscribed to the queue and transforms the data into a standard format.Because of inconsistencies in the data that the satellites produce, the application is occasionally unable to transform the data. In these cases, the messages remain in the SQS queue. A DevOps engineer must develop a solution that retains the failed messages and makes them available to scientists for review and future processing.Which solution will meet these requirements?",
        "options": [
            "Configure API Gateway to send messages to different SQS virtual queues that are named for each of the satellites. Update the application to use a new virtual queue for any data that it cannot transform, and send the message to the new virtual queue. Instruct the scientists to use the virtual queue to review the data that is not valid. Reprocess this data at a later time.",
            "Convert the SQS standard queue to an SQS FIFO queue. Configure AWS Lambda to poll the SQS queue every 10 minutes by using an Amazon EventBridge schedule. Invoke the Lambda function to identify any messages with a SentTimestamp value that is older than 5 minutes, push the data to the same location as the application's output location, and remove the messages from the queue.",
            "Configure AWS Lambda to poll the SQS queue and invoke a Lambda function to check whether the queue messages are valid. If validation fails, send a copy of the data that is not valid to an Amazon S3 bucket so that the scientists can review and correct the data. When the data is corrected, amend the message in the SQS queue by using a replay Lambda function with the corrected data.",
            "Create an SQS dead-letter queue. Modify the existing queue by including a redrive policy that sets the Maximum Receives setting to 1 and sets the dead-letter queue ARN to the ARN of the newly created queue. Instruct the scientists to use the dead-letter queue to review the data that is not valid. Reprocess this data at a later time."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 12,
        "text": "A company runs an application with an Amazon EC2 and on-premises configuration. A DevOps engineer needs to standardize patching across both environments. Company policy dictates that patching only happens during non-business hours.Which combination of actions will meet these requirements? (Choose three.)",
        "options": [
            "Create IAM access keys for the on-premises machines to interact with AWS Systems Manager.",
            "Use Amazon EventBridge scheduled events to schedule a patch window.",
            "Add the physical machines into AWS Systems Manager using Systems Manager Hybrid Activations.",
            "Use AWS Systems Manager Maintenance Windows to schedule a patch window.",
            "Run an AWS Systems Manager Automation document to patch the systems every hour",
            "Attach an IAM role to the EC2 instances, allowing them to be managed by AWS Systems Manager."
        ],
        "correct": [
            2,
            3,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 13,
        "text": "A company that uses electronic health records is running a fleet of Amazon EC2 instances with an Amazon Linux operating system. As part of patient privacy requirements, the company must ensure continuous compliance for patches for operating system and applications running on the EC2 instances.How can the deployments of the operating system and application patches be automated using a default and custom repository?",
        "options": [
            "Use yum-config-manager to add the custom repository under /etc/yum.repos.d and run yum-config-manager-enable to activate the repository.",
            "Use AWS Direct Connect to integrate the corporate repository and deploy the patches using Amazon CloudWatch scheduled events, then use the CloudWatch dashboard to create reports.",
            "Use AWS Systems Manager to create a new patch baseline including the corporate repository. Run the AWS-AmazonLinuxDefaultPatchBaseline document using the run command to verify and install patches.",
            "Use AWS Systems Manager to create a new patch baseline including the custom repository. Run the AWS-RunPatchBaseline document using the run command to verify and install patches."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 14,
        "text": "A company's DevOps engineer uses AWS Systems Manager to perform maintenance tasks during maintenance windows. The company has a few Amazon EC2 instances that require a restart after notifications from AWS Health. The DevOps engineer needs to implement an automated solution to remediate these notifications. The DevOps engineer creates an Amazon EventBridge rule.How should the DevOps engineer configure the EventBridge rule to meet these requirements?",
        "options": [
            "Configure an event source of AWS Health, a service of EC2, and an event type that indicates instance maintenance. Target a newly created AWS Lambda function that registers an automation task to restart the EC2 instance during a maintenance window.",
            "Configure an event source of AWS Health, a service of EC2. and an event type that indicates instance maintenance. Target a Systems Manager document to restart the EC2 instance.",
            "Configure an event source of Systems Manager and an event type that indicates a maintenance window. Target a Systems Manager document to restart the EC2 instance.",
            "Configure an event source of EC2 and an event type that indicates instance maintenance. Target a newly created AWS Lambda function that registers an automation task to restart the EC2 instance during a maintenance window."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 15,
        "text": "An online retail company based in the United States plans to expand its operations to Europe and Asia in the next six months. Its product currently runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. All data is stored in an Amazon Aurora database instance.When the product is deployed in multiple regions, the company wants a single product catalog across all regions, but for compliance purposes, its customer information and purchases must be kept in each region.How should the company meet these requirements with the LEAST amount of application changes?",
        "options": [
            "Use Amazon Redshift for the product catalog and Amazon DynamoDB tables for the customer information and purchases.",
            "Use Aurora for the product catalog and Amazon DynamoDB global tables for the customer information and purchases.",
            "Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases.",
            "Use Amazon DynamoDB global tables for the product catalog and regional tables for the customer information and purchases."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 16,
        "text": "A company hosts its staging website using an Amazon EC2 instance backed with Amazon EBS storage. The company wants to recover quickly with minimal data losses in the event of network connectivity issues or power failures on the EC2 instance.Which solution will meet these requirements?",
        "options": [
            "Create an Amazon CloudWatch alarm for the StatusCheckFailed Instance metric and select the EC2 action to reboot the instance.",
            "Add the instance to an EC2 Auto Scaling group with a lifecycle hook to detach the EBS volume when the EC2 instance shuts down or terminates.",
            "Create an Amazon CloudWatch alarm for the StatusCheckFailed System metric and select the EC2 action to recover the instance.",
            "Add the instance to an EC2 Auto Scaling group with the minimum, maximum, and desired capacity set to 1."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 17,
        "text": "A DevOps engineer is building a continuous deployment pipeline for a serverless application that uses AWS Lambda functions. The company wants to reduce the customer impact of an unsuccessful deployment. The company also wants to monitor for issues.Which deploy stage configuration will meet these requirements?",
        "options": [
            "Use an AWS Serverless Application Model (AWS SAM) template to define the serverless application. Use AWS CodeDeploy to deploy the Lambda functions with the Canary10Percent15Minutes Deployment Preference Type. Use Amazon CloudWatch alarms to monitor the health of the functions.",
            "Use AWS CloudFormation to publish a new stack update, and include Amazon CloudWatch alarms on all resources. Set up an AWS CodePipeline approval action for a developer to verify and approve the AWS CloudFormation change set.",
            "Use AWS CloudFormation to publish a new version on every stack update, and include Amazon CloudWatch alarms on all resources. Use the RoutingConfig property of the AWS::Lambda::Alias resource to update the traffic routing during the stack update.",
            "Use AWS CodeBuild to add sample event payloads for testing to the Lambda functions. Publish a new version of the functions, and include Amazon CloudWatch alarms. Update the production alias to point to the new version. Configure rollbacks to occur when an alarm is in the ALARM state."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 18,
        "text": "An IT team has built an AWS CloudFormation template so others in the company can quickly and reliably deploy and terminate an application. The template creates an Amazon EC2 instance with a user data script to install the application and an Amazon S3 bucket that the application uses to serve static webpages while it is running.All resources should be removed when the CloudFormation stack is deleted. However, the team observes that CloudFormation reports an error during stack deletion, and the S3 bucket created by the stack is not deleted.How can the team resolve the error in the MOST efficient manner to ensure that all resources are deleted without errors?",
        "options": [
            "Identify the resource that was not deleted. Manually empty the S3 bucket and then delete it.",
            "Replace the EC2 and S3 bucket resources with a single AWS OpsWorks Stacks resource. Define a custom recipe for the stack to create and delete the EC2 instance and the S3 bucket.",
            "Add a DelelionPolicy attribute to the S3 bucket resource, with the value Delete forcing the bucket to be removed when the stack is deleted.",
            "Add a custom resource with an AWS Lambda function with the DependsOn attribute specifying the S3 bucket, and an IAM role. Write the Lambda function to delete all objects from the bucket when RequestType is Delete."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 19,
        "text": "A company is implementing an Amazon Elastic Container Service (Amazon ECS) cluster to run its workload. The company architecture will run multiple ECS services on the cluster. The architecture includes an Application Load Balancer on the front end and uses multiple target groups to route traffic.A DevOps engineer must collect application and access logs. The DevOps engineer then needs to send the logs to an Amazon S3 bucket for near-real-time analysis.Which combination of steps must the DevOps engineer take to meet these requirements? (Choose three.)",
        "options": [
            "Install the Amazon CloudWatch Logs agent on the ECS instances. Change the logging driver in the ECS task definition to awslogs.",
            "Activate access logging on the target groups that the ECS services use. Then send the logs directly to the logging S3 bucket.",
            "Use Amazon EventBridge to schedule an AWS Lambda function that will run every 60 seconds and will run the Amazon CloudWatch Logs create-export-task command. Then point the output to the logging S3 bucket.",
            "Create an Amazon Kinesis Data Firehose delivery stream that has a destination of the logging S3 bucket. Then create an Amazon CloudWatch Logs subscription filter for Kinesis Data Firehose.",
            "Activate access logging on the ALB. Then point the ALB directly to the logging S3 bucket.",
            "Download the Amazon CloudWatch Logs container instance from AWS. Configure this instance as a task. Update the application service definitions to include the logging task."
        ],
        "correct": [
            0,
            3,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 20,
        "text": "A security review has identified that an AWS CodeBuild project is downloading a database population script from an Amazon S3 bucket using an unauthenticated request. The security team does not allow unauthenticated requests to S3 buckets for this project.How can this issue be corrected in the MOST secure manner?",
        "options": [
            "Modify the S3 bucket settings to enable HTTPS basic authentication and specify a token. Update the build spec to use cURL to pass the token and download the database population script.",
            "Remove unauthenticated access from the S3 bucket with a bucket policy. Use the AWS CLI to download the database population script using an IAM access key and a secret access key.",
            "Remove unauthenticated access from the S3 bucket with a bucket policy. Modify the service role for the CodeBuild project to include Amazon S3 access. Use the AWS CLI to download the database population script.",
            "Add the bucket name to the AllowedBuckets section of the CodeBuild project settings. Update the build spec to use the AWS CLI to download the database population script."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 21,
        "text": "A company is implementing a well-architected design for its globally accessible API stack. The design needs to ensure both high reliability and fast response times for users located in North America and Europe.The API stack contains the following three tiers:Amazon API Gateway -AWS Lambda -Amazon DynamoDB -Which solution will meet the requirements?",
        "options": [
            "Configure Amazon Route 53 to point to API Gateway APIs in North America and Europe using latency-based routing and health checks. Configure the APIs to forward requests to a Lambda function in that Region. Configure the Lambda functions to retrieve and update the data in a DynamoDB global table.",
            "Configure Amazon Route 53 to point to API Gateway API in North America using latency-based routing. Configure the API to forward requests to the Lambda function in the Region nearest to the user. Configure the Lambda function to retrieve and update the data in a DynamoDB table.",
            "Configure Amazon Route 53 to point to API Gateway APIs in North America and Europe using health checks. Configure the APIs to forward requests to a Lambda function in that Region. Configure the Lambda functions to retrieve and update the data in a DynamoDB table in the same Region as the Lambda function.",
            "Configure Amazon Route 53 to point to API Gateway in North America, create a disaster recovery API in Europe, and configure both APIs to forward requests to the Lambda functions in that Region. Retrieve the data from a DynamoDB global table. Deploy a Lambda function to check the North America API health every 5 minutes. In the event of a failure, update Route 53 to point to the disaster recovery API."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 22,
        "text": "A company has a mobile application that makes HTTP API calls to an Application Load Balancer (ALB). The ALB routes requests to an AWS Lambda function. Many different versions of the application are in use at any given time, including versions that are in testing by a subset of users. The version of the application is defined in the user-agent header that is sent with all requests to the API.After a series of recent changes to the API, the company has observed issues with the application. The company needs to gather a metric for each API operation by response code for each version of the application that is in use. A DevOps engineer has modified the Lambda function to extract the API operation name, version information from the user-agent header and response code.Which additional set of actions should the DevOps engineer take to gather the required metrics?",
        "options": [
            "Configure the ALB access logs to write to an Amazon CloudWatch Logs log group. Modify the Lambda function to respond to the ALB with the API operation name, response code, and version number as response metadata. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.",
            "Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.",
            "Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs Insights query to populate CloudWatch metrics from the log lines. Specify response code and application version as dimensions for the metric.",
            "Configure AWS X-Ray integration on the Lambda function. Modify the Lambda function to create an X-Ray subsegment with the API operation name, response code, and version number. Configure X-Ray insights to extract an aggregated metric for each API operation name and to publish the metric to Amazon CloudWatch. Specify response code and application version as dimensions for the metric."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 23,
        "text": "An ecommerce company is receiving reports that its order history page is experiencing delays in reflecting the processing status of orders. The order processing system consists of an AWS Lambda function that uses reserved concurrency. The Lambda function processes order messages from an Amazon Simple Queue Service (Amazon SQS) queue and inserts processed orders into an Amazon DynamoDB table. The DynamoDB table has auto scaling enabled for read and write capacity.Which actions should a DevOps engineer take to resolve this delay? (Choose two.)",
        "options": [
            "Check the WriteThrottleEvents metric for the DynamoDB table. Increase the maximum write capacity units (WCUs) for the table's scaling policy.",
            "Check the ApproximateAgeOfOldestMessage metric for the SQS queue. Increase the Lambda function concurrency limit.",
            "Check the NumberOfMessagesSent metric for the SQS queue. Increase the SQS queue visibility timeout.",
            "Check the ApproximateAgeOfOldestMessage metnc for the SQS queue Configure a redrive policy on the SQS queue.",
            "Check the Throttles metric for the Lambda function. Increase the Lambda function timeout."
        ],
        "correct": [
            0,
            1
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 24,
        "text": "A company provides an application to customers. The application has an Amazon API Gateway REST API that invokes an AWS Lambda function. On initialization, the Lambda function loads a large amount of data from an Amazon DynamoDB table. The data load process results in long cold-start times of 8-10 seconds. The DynamoDB table has DynamoDB Accelerator (DAX) configured.Customers report that the application intermittently takes a long time to respond to requests. The application receives thousands of requests throughout the day. In the middle of the day, the application experiences 10 times more requests than at any other time of the day. Near the end of the day, the application's request volume decreases to 10% of its normal total.A DevOps engineer needs to reduce the latency of the Lambda function at all times of the day.Which solution will meet these requirements?",
        "options": [
            "Configure reserved concurrency on the Lambda function. Configure AWS Application Auto Scaling on the API Gateway API with a reserved concurrency maximum value of 100.",
            "Configure provisioned concurrency on the Lambda function with a concurrency value of 1. Delete the DAX cluster for the DynamoDB table.",
            "Configure provisioned concurrency on the Lambda function. Configure AWS Application Auto Scaling on the Lambda function with provisioned concurrency values set to a minimum of 1 and a maximum of 100.",
            "Configure reserved concurrency on the Lambda function with a concurrency value of 0."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 25,
        "text": "A developer is maintaining a fleet of 50 Amazon EC2 Linux servers. The servers are part of an Amazon EC2 Auto Scaling group, and also use Elastic Load Balancing for load balancing.Occasionally, some application servers are being terminated after failing ELB HTTP health checks. The developer would like to perform a root cause analysis on the issue, but before being able to access application logs, the server is terminated.How can log collection be automated?",
        "options": [
            "Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an Amazon EventBridge rule for EC2 Instance-terminate Lifecycle Action and trigger an AWS Lambda function that invokes an SSM Run Command script to collect logs, push them to Amazon S3, and complete the lifecycle action once logs are collected.",
            "Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an Amazon CloudWatch subscription filter for EC2 Instance Terminate Successful and trigger a CloudWatch agent that invokes a script to collect logs, push them to Amazon S3, and complete the lifecycle action once logs are collected.",
            "Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an AWS Config rule for EC2 Instance-terminate Lifecycle Action and trigger a step function that invokes a script to collect logs, push them to Amazon S3, and complete the lifecycle action once logs are collected.",
            "Use Auto Scaling lifecycle hooks to put instances in a Pending:Wait state. Create an Amazon CloudWatch alarm for EC2 Instance Terminate Successful and trigger an AWS Lambda function that invokes an SSM Run Command script to collect logs, push them to Amazon S3, and complete the lifecycle action once logs are collected."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 26,
        "text": "A company requires its developers to tag all Amazon Elastic Block Store (Amazon EBS) volumes in an account to indicate a desired backup frequency. This requirement Includes EBS volumes that do not require backups. The company uses custom tags named Backup_Frequency that have values of none, dally, or weekly that correspond to the desired backup frequency. An audit finds that developers are occasionally not tagging the EBS volumes.A DevOps engineer needs to ensure that all EBS volumes always have the Backup_Frequency tag so that the company can perform backups at least weekly unless a different value is specified.Which solution will meet these requirements?",
        "options": [
            "Turn on AWS CloudTrail in the account. Create an Amazon EventBridge rule that reacts to EBS CreateVolume events or EBS ModifyVolume events. Configure a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly. Specify the runbook as the target of the rule.",
            "Set up AWS Config in the account. Use a managed rule that returns a compliance failure for EC2::Volume resources that do not have a Backup Frequency tag applied. Configure a remediation action that uses a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly.",
            "Set up AWS Config in the account. Create a custom rule that returns a compliance failure for all Amazon EC2 resources that do not have a Backup Frequency tag applied. Configure a remediation action that uses a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly.",
            "Turn on AWS CloudTrail in the account. Create an Amazon EventBridge rule that reacts to EBS CreateVolume events. Configure a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly. Specify the runbook as the target of the rule."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 27,
        "text": "A company has chosen AWS to host a new application. The company needs to implement a multi-account strategy. A DevOps engineer creates a new AWS account and an organization in AWS Organizations. The DevOps engineer also creates the OU structure for the organization and sets up a landing zone by using AWS Control Tower.The DevOps engineer must implement a solution that automatically deploys resources for new accounts that users create through AWS Control Tower Account Factory. When a user creates a new account, the solution must apply AWS CloudFormation templates and SCPs that are customized for the OU or the account to automatically deploy all the resources that are attached to the account. All the OUs are enrolled in AWS Control Tower.Which solution will meet these requirements in the MOST automated way?",
        "options": [
            "Deploy CloudFormation stack sets by using the required templates. Enable automatic deployment. Deploy stack instances to the required accounts. Deploy a CloudFormation stack set to the organization‚Äôs management account to deploy SCPs.",
            "Create an Amazon EventBridge rule to detect the CreateManagedAccount event. Configure AWS Service Catalog as the target to deploy resources to any new accounts. Deploy SCPs by using the AWS CLI and JSON documents.",
            "Use AWS Service Catalog with AWS Control Tower. Create portfolios and products in AWS Service Catalog. Grant granular permissions to provision these resources. Deploy SCPs by using the AWS CLI and JSON documents.",
            "Deploy the Customizations for AWS Control Tower (CfCT) solution. Use an AWS CodeCommit repository as the source. In the repository, create a custom package that includes the CloudFormation templates and the SCP JSON documents."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 28,
        "text": "A development team uses AWS CodeCommit for version control for applications. The development team uses AWS CodePipeline, AWS CodeBuild. and AWS CodeDeploy for CI/CD infrastructure. In CodeCommit, the development team recently merged pull requests that did not pass long-running tests in the code base. The development team needed to perform rollbacks to branches in the codebase, resulting in lost time and wasted effort.A DevOps engineer must automate testing of pull requests in CodeCommit to ensure that reviewers more easily see the results of automated tests as part of the pull request review.What should the DevOps engineer do to meet this requirement?",
        "options": [
            "Create an Amazon EventBridge rule that reacts to the pullRequestStatusChanged event. Create an AWS Lambda function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild badge as a comment on the pull request so that developers will see the badge in their code review.",
            "Create an Amazon EventBridge rule that reacts to the pullRequestCreated event. Create an AWS Lambda function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild test results as a comment on the pull request when the test results are complete.",
            "Create an Amazon EventBridge rule that reacts to pullRequestCreated and pullRequestSourceBranchUpdated events. Create an AWS Lambda function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild badge as a comment on the pull request so that developers will see the badge in their code review.",
            "Create an Amazon EventBridge rule that reacts to the pullRequestStatusChanged event. Create an AWS Lambda function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild test results as a comment on the pull request when the test results are complete."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 29,
        "text": "A company uses AWS CodePipeline pipelines to automate releases of its application A typical pipeline consists of three stages build, test, and deployment. The company has been using a separate AWS CodeBuild project to run scripts for each stage. However, the company now wants to use AWS CodeDeploy to handle the deployment stage of the pipelines.The company has packaged the application as an RPM package and must deploy the application to a fleet of Amazon EC2 instances. The EC2 instances are in an EC2 Auto Scaling group and are launched from a common AMI.Which combination of steps should a DevOps engineer perform to meet these requirements? (Choose two.)",
        "options": [
            "Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Add a step to the CodePipeline pipeline to use EC2 Image Builder to create a new AMI. Configure CodeDeploy to deploy the newly created AMI.",
            "Create an application in CodeDeploy. Configure an in-place deployment type. Specify the EC2 instances that are launched from the common AMI as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application.",
            "Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application.",
            "Create a new version of the common AMI with the CodeDeploy agent installed. Update the IAM role of the EC2 instances to allow access to CodeDeploy.",
            "Create a new version of the common AMI with the CodeDeploy agent installed. Create an AppSpec file that contains application deployment scripts and grants access to CodeDeploy."
        ],
        "correct": [
            2,
            3
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 30,
        "text": "A rapidly growing company wants to scale for developer demand for AWS development environments. Development environments are created manually in the AWS Management Console. The networking team uses AWS CloudFormation to manage the networking infrastructure, exporting stack output values for the Amazon VPC and all subnets. The development environments have common standards, such as Application Load Balancers, Amazon EC2 Auto Scaling groups, security groups, and Amazon DynamoDB tables.To keep up with demand, the DevOps engineer wants to automate the creation of development environments. Because the infrastructure required to support the application is expected to grow, there must be a way to easily update the deployed infrastructure. CloudFormation will be used to create a template for the development environments.Which approach will meet these requirements and quickly provide consistent AWS environments for developers?",
        "options": [
            "Use nested stacks to define common infrastructure components. To access the exported values, use TemplateURL to reference the networking team‚Äôs template. To retrieve Virtual Private Cloud (VPC) and subnet values, use Fn::ImportValue intrinsic functions in the Parameters section of the root template. Use the CreateChangeSet and ExecuteChangeSet commands to update existing development environments.",
            "Use nested stacks to define common infrastructure components. Use Fn::ImportValue intrinsic functions with the resources of the nested stack to retrieve Virtual Private Cloud (VPC) and subnet values. Use the CreateChangeSet and ExecuteChangeSet commands to update existing development environments.",
            "Use Fn::ImportValue intrinsic functions in the Parameters section of the root template to retrieve Virtual Private Cloud (VPC) and subnet values. Define the development resources in the order they need to be created in the CloudFormation nested stacks. Use the CreateChangeSet. and ExecuteChangeSet commands to update existing development environments.",
            "Use Fn::ImportValue intrinsic functions in the Resources section of the template to retrieve Virtual Private Cloud (VPC) and subnet values. Use CloudFormation StackSets for the development environments, using the Count input parameter to indicate the number of environments needed. Use the UpdateStackSet command to update existing development environments."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 31,
        "text": "A company has an organization in AWS Organizations. The organization includes workload accounts that contain enterprise applications. The company centrally manages users from an operations account. No users can be created in the workload accounts. The company recently added an operations team and must provide the operations team members with administrator access to each workload account.Which combination of actions will provide this access? (Choose three.)",
        "options": [
            "Create a SysAdmin role in the operations account. Attach the AdministratorAccess policy to the role. Modify the trust relationship to allow the sts:AssumeRole action from the workload accounts.",
            "Create an Amazon Cognito identity pool in the operations account. Attach the SysAdmin role as an authenticated role.",
            "Create an Amazon Cognito user pool in the operations account. Create an Amazon Cognito user for each operations team member.",
            "In the operations account, create an IAM user group that is named SysAdmins. Add an IAM policy that allows the sts:AssumeRole action for the SysAdmin role in each workload account. Add all operations team members to the group.",
            "In the operations account, create an IAM user for each operations team member.",
            "Create a SysAdmin role in each workload account. Attach the AdministratorAccess policy to the role. Modify the trust relationship to allow the sts:AssumeRole action from the operations account."
        ],
        "correct": [
            3,
            4,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 32,
        "text": "A DevOps engineer needs to back up sensitive Amazon S3 objects that are stored within an S3 bucket with a private bucket policy using S3 cross-Region replication functionality. The objects need to be copied to a target bucket in a different AWS Region and account.Which combination of actions should be performed to enable this replication? (Choose three.)",
        "options": [
            "Add statements to the source bucket policy allowing the replication IAM role to replicate objects.",
            "Create a replication rule in the source bucket to enable the replication.",
            "Create a replication rule in the target bucket to enable the replication.",
            "Create a replication IAM role in the source account",
            "Create a replication I AM role in the target account.",
            "Add statements to the target bucket policy allowing the replication IAM role to replicate objects."
        ],
        "correct": [
            1,
            3,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 33,
        "text": "A company has an application that is using a MySQL-compatible Amazon Aurora Multi-AZ DB cluster as the database. A cross-Region read replica has been created for disaster recovery purposes. A DevOps engineer wants to automate the promotion of the replica so it becomes the primary database instance in the event of a failure.Which solution will accomplish this?",
        "options": [
            "Create an AWS Lambda function to modify the application's AWS CloudFormation template to promote the replica, apply the template to update the stack, and point the application to the newly promoted instance. Create an Amazon CloudWatch alarm to invoke this Lambda function after the failure event occurs.",
            "Configure a latency-based Amazon Route 53 CNAME with health checks so it points to both the primary and replica endpoints. Subscribe an Amazon SNS topic to Amazon RDS failure notifications from AWS CloudTrail and use that topic to invoke an AWS Lambda function that will promote the replica instance as the primary.",
            "Store the Aurora endpoint in AWS Systems Manager Parameter Store. Create an Amazon EventBridge event that detects the database failure and runs an AWS Lambda function to promote the replica instance and update the endpoint URL stored in AWS Systems Manager Parameter Store. Code the application to reload the endpoint from Parameter Store if a database connection fails.",
            "Create an Aurora custom endpoint to point to the primary database instance. Configure the application to use this endpoint. Configure AWS CloudTrail to run an AWS Lambda function to promote the replica instance and modify the custom endpoint to point to the newly promoted instance."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 34,
        "text": "A company has multiple member accounts that are part of an organization in AWS Organizations. The security team needs to review every Amazon EC2 security group and their inbound and outbound rules. The security team wants to programmatically retrieve this information from the member accounts using an AWS Lambda function in the management account of the organization.Which combination of access changes will meet these requirements? (Choose three.)",
        "options": [
            "Create an I AM role in the management account that allows the sts:AssumeRole action against the member account IAM role's ARN.",
            "Create a trust relationship that allows users in the member accounts to assume the management account IAM role.",
            "Create an I AM role in each member account to allow the sts:AssumeRole action against the management account IAM role's ARN.",
            "Create a trust relationship that allows users in the management account to assume the IAM roles of the member accounts.",
            "Create an IAM role in each member account that has access to the AmazonEC2ReadOnlyAccess managed policy.",
            "Create an IAM role in the management account that has access to the AmazonEC2ReadOnlyAccess managed policy."
        ],
        "correct": [
            0,
            3,
            4
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 35,
        "text": "A development team is using AWS CodeCommit to version control application code and AWS CodePipeline to orchestrate software deployments. The team has decided to use a remote main branch as the trigger for the pipeline to integrate code changes. A developer has pushed code changes to the CodeCommit repository, but noticed that the pipeline had no reaction, even after 10 minutes.Which of the following actions should be taken to troubleshoot this issue?",
        "options": [
            "Check that the developer‚Äôs IAM role has permission to push to the CodeCommit repository.",
            "Check that an Amazon EventBridge rule has been created for the main branch to trigger the pipeline.",
            "Check that the CodePipeline service role has permission to access the CodeCommit repository.",
            "Check to see if the pipeline failed to start because of CodeCommit errors in Amazon CloudWatch Logs."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 36,
        "text": "A company uses AWS Key Management Service (AWS KMS) keys and manual key rotation to meet regulatory compliance requirements. The security team wants to be notified when any keys have not been rotated after 90 days.Which solution will accomplish this?",
        "options": [
            "Configure an Amazon EventBridge event to launch an AWS Lambda function to call the AWS Trusted Advisor API and publish to an Amazon Simple Notification Service (Amazon SNS) topic.",
            "Develop an AWS Config custom rule that publishes to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old.",
            "Configure AWS Security Hub to publish to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old.",
            "Configure AWS KMS to publish to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 37,
        "text": "A company has containerized all of its in-house quality control applications. The company is running Jenkins on Amazon EC2 instances, which require patching and upgrading. The compliance officer has requested a DevOps engineer begin encrypting build artifacts since they contain company intellectual property.What should the DevOps engineer do to accomplish this in the MOST maintainable manner?",
        "options": [
            "Deploy Jenkins to an Amazon ECS cluster and copy build artifacts to an Amazon S3 bucket with default encryption enabled.",
            "Automate patching and upgrading using AWS Systems Manager on EC2 instances and encrypt Amazon EBS volumes by default.",
            "Use AWS CodeBuild with artifact encryption to replace the Jenkins instance running on EC2 instances.",
            "Leverage AWS CodePipeline with a build action and encrypt the artifacts using AWS Secrets Manager."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 38,
        "text": "A company has multiple accounts in an organization in AWS Organizations. The company's SecOps team needs to receive an Amazon Simple Notification Service (Amazon SNS) notification if any account in the organization turns off the Block Public Access feature on an Amazon S3 bucket. A DevOps engineer must implement this change without affecting the operation of any AWS accounts. The implementation must ensure that individual member accounts in the organization cannot turn off the notification.Which solution will meet these requirements?",
        "options": [
            "Designate an account to be the delegated Amazon GuardDuty administrator account. Turn on GuardDuty for all accounts across the organization. In the GuardDuty administrator account, create an SNS topic. Subscribe the SecOps team's email address to the SNS topic. In the same account, create an Amazon EventBridge rule that uses an event pattern for GuardDuty findings and a target of the SNS topic.",
            "Turn on Amazon Inspector across the organization. In the Amazon Inspector delegated administrator account, create an SNS topic. Subscribe the SecOps team‚Äôs email address to the SNS topic. In the same account, create an Amazon EventBridge rule that uses an event pattern for public network exposure of the S3 bucket and publishes an event to the SNS topic to notify the SecOps team.",
            "Turn on AWS Config across the organization. In the delegated administrator account, create an SNS topic. Subscribe the SecOps team's email address to the SNS topic. Deploy a conformance pack that uses the s3-bucket-level-public-access-prohibited AWS Config managed rule in each account and uses an AWS Systems Manager document to publish an event to the SNS topic to notify the SecOps team.",
            "Create an AWS CloudFormation template that creates an SNS topic and subscribes the SecOps team‚Äôs email address to the SNS topic. In the template, include an Amazon EventBridge rule that uses an event pattern of CloudTrail activity for s3:PutBucketPublicAccessBlock and a target of the SNS topic. Deploy the stack to every account in the organization by using CloudFormation StackSets."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 39,
        "text": "A company‚Äôs security team requires that all external Application Load Balancers (ALBs) and Amazon API Gateway APIs are associated with AWS WAF web ACLs. The company has hundreds of AWS accounts, all of which are included in a single organization in AWS Organizations. The company has configured AWS Config for the organization. During an audit, the company finds some externally facing ALBs that are not associated with AWS WAF web ACLs.Which combination of steps should a DevOps engineer take to prevent future violations? (Choose two.)",
        "options": [
            "Delegate AWS Firewall Manager to a security account.",
            "Configure an AWS Config managed rule to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.",
            "Create an Amazon GuardDuty policy to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.",
            "Create an AWS Firewall Manager policy to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.",
            "Delegate Amazon GuardDuty to a security account."
        ],
        "correct": [
            0,
            3
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 40,
        "text": "A company has an AWS CodePipeline pipeline that is configured with an Amazon S3 bucket in the eu-west-1 Region. The pipeline deploys an AWS Lambda application to the same Region. The pipeline consists of an AWS CodeBuild project build action and an AWS CloudFormation deploy action.The CodeBuild project uses the aws cloudformation package AWS CLI command to build an artifact that contains the Lambda function code‚Äôs .zip file and the CloudFormation template. The CloudFormation deploy action references the CloudFormation template from the output artifact of the CodeBuild project‚Äôs build action.The company wants to also deploy the Lambda application to the us-east-1 Region by using the pipeline in eu-west-1. A DevOps engineer has already updated the CodeBuild project to use the aws cloudformation package command to produce an additional output artifact for us-east-1.Which combination of additional steps should the DevOps engineer take to meet these requirements? (Choose two.)",
        "options": [
            "Create an S3 bucket in us-east-1. Configure S3 Cross-Region Replication (CRR) from the S3 bucket in eu-west-1 to the S3 bucket in us-east-1.",
            "Modify the CloudFormation template to include a parameter for the Lambda function code‚Äôs zip file location. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to pass in the us-east-1 artifact location as a parameter override.",
            "Modify the pipeline to include the S3 bucket for us-east-1 as an artifact store. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the us-east-1 output artifact.",
            "Create an S3 bucket in us-east-1. Configure the S3 bucket policy to allow CodePipeline to have read and write access.",
            "Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the us-east-1 output artifact."
        ],
        "correct": [
            2,
            3
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 41,
        "text": "A DevOps team manages an API running on-premises that serves as a backend for an Amazon API Gateway endpoint. Customers have been complaining about high response latencies, which the development team has verified using the API Gateway latency metrics in Amazon CloudWatch. To identify the cause, the team needs to collect relevant data without introducing additional latency.Which actions should be taken to accomplish this? (Choose two.)",
        "options": [
            "Install the CloudWatch agent server side and configure the agent to upload relevant logs to CloudWatch.",
            "Enable AWS X-Ray tracing in API Gateway, modify the application to capture request segments, and use the X-Ray daemon to upload segments to X-Ray.",
            "Modify the on-premises application to send log information back to API Gateway with each request.",
            "Modify the on-premises application to calculate and upload statistical data relevant to the API service requests to CloudWatch metrics.",
            "Enable AWS X-Ray tracing in API Gateway, modify the application to capture request segments, and upload those segments to X-Ray during each request."
        ],
        "correct": [
            0,
            1
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 42,
        "text": "An ecommerce company has chosen AWS to host its new platform. The company's DevOps team has started building an AWS Control Tower landing zone. The DevOps team has set the identity store within AWS IAM Identity Center (AWS Single Sign-On) to external identity provider (IdP) and has configured SAML 2.0.The DevOps team wants a robust permission model that applies the principle of least privilege. The model must allow the team to build and manage only the team's own resources.Which combination of steps will meet these requirements? (Choose three.)",
        "options": [
            "Create permission sets. Attach an inline policy that includes the required permissions and uses the aws:PrincipalTag condition key to scope the permissions.",
            "Create a group in the IdP. Place users in the group. Assign the group to accounts and the permission sets in IAM Identity Center.",
            "Create IAM policies that include the required permissions. Include the aws:PrincipalTag condition key.",
            "Enable attributes for access control in IAM Identity Center. Apply tags to users. Map the tags as key-value pairs.",
            "Create a group in the IdP. Place users in the group. Assign the group to OUs and IAM policies.",
            "Enable attributes for access control in IAM Identity Center. Map attributes from the IdP as key-value pairs."
        ],
        "correct": [
            0,
            1,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 43,
        "text": "A company uses AWS Organizations and AWS Control Tower to manage all the company's AWS accounts. The company uses the Enterprise Support plan.A DevOps engineer is using Account Factory for Terraform (AFT) to provision new accounts. When new accounts are provisioned, the DevOps engineer notices that the support plan for the new accounts is set to the Basic Support plan. The DevOps engineer needs to implement a solution to provision the new accounts with the Enterprise Support plan.Which solution will meet these requirements?",
        "options": [
            "Create an AWS Lambda function to create a ticket for AWS Support to add the account to the Enterprise Support plan. Grant the Lambda function the support:ResolveCase permission.",
            "Use an AWS Config conformance pack to deploy the account-part-of-organizations AWS Config rule and to automatically remediate any noncompliant accounts.",
            "Add an additional value to the control_tower_parameters input to set the AWSEnterpriseSupport parameter as the organization's management account number.",
            "Set the aft_feature_enterprise_support feature flag to True in the AFT deployment input configuration. Redeploy AFT and apply the changes."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 44,
        "text": "A company runs an application on one Amazon EC2 instance. Application metadata is stored in Amazon S3 and must be retrieved if the instance is restarted. The instance must restart or relaunch automatically if the instance becomes unresponsive.Which solution will meet these requirements?",
        "options": [
            "Use AWS CloudFormation to create an EC2 instance that includes the UserData property for the EC2 resource. Add a command in UserData to retrieve the application metadata from Amazon S3.",
            "Create an Amazon CloudWatch alarm for the StatusCheckFailed metric. Use the recover action to stop and start the instance. Use an S3 event notification to push the metadata to the instance when the instance is back up and running.",
            "Configure AWS OpsWorks, and use the auto healing feature to stop and start the instance. Use a lifecycle event in OpsWorks to pull the metadata from Amazon S3 and update it on the instance.",
            "Use EC2 Auto Recovery to automatically stop and start the instance in case of a failure. Use an S3 event notification to push the metadata to the instance when the instance is back up and running."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 45,
        "text": "A company is using AWS CodePipeline to automate its release pipeline. AWS CodeDeploy is being used in the pipeline to deploy an application to Amazon Elastic Container Service (Amazon ECS) using the blue/green deployment model. The company wants to implement scripts to test the green version of the application before shifting traffic. These scripts will complete in 5 minutes or less. If errors are discovered during these tests, the application must be rolled back.Which strategy will meet these requirements?",
        "options": [
            "Add a hooks section to the CodeDeploy AppSpec file. Use the AfterAllowTestTraffic lifecycle event to invoke an AWS Lambda function to run the test scripts. If errors are found, exit the Lambda function with an error to initiate rollback.",
            "Add a stage to the CodePipeline pipeline between the source and deploy stages. Use this stage to invoke an AWS Lambda function that will run the test scripts. If errors are found, use the aws deploy stop-deployment command to stop the deployment.",
            "Add a hooks section to the CodeDeploy AppSpec file. Use the AfterAllowTraffic lifecycle event to invoke the test scripts. If errors are found, use the aws deploy stop-deployment CLI command to stop the deployment.",
            "Add a stage to the CodePipeline pipeline between the source and deploy stages. Use AWS CodeBuild to create a runtime environment and build commands in the buildspec file to invoke test scripts. If errors are found, use the aws deploy stop-deployment command to stop the deployment."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 46,
        "text": "A company is adopting AWS CodeDeploy to automate its application deployments for a Java-Apache Tomcat application with an Apache Webserver. The development team started with a proof of concept, created a deployment group for a developer environment, and performed functional tests within the application. After completion, the team will create additional deployment groups for staging and production.The current log level is configured within the Apache settings, but the team wants to change this configuration dynamically when the deployment occurs, so that they can set different log level configurations depending on the deployment group without having a different application revision for each group.How can these requirements be met with the LEAST management overhead and without requiring different script versions for each deployment group?",
        "options": [
            "Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_ NAME to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the BeforeInstall lifecycle hook in the appspec.yml file.",
            "Create a CodeDeploy custom environment variable for each environment. Then place a script into the application revision that checks this environment variable to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the ValidateService lifecycle hook in the appspec.yml file.",
            "Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_ID to identify which deployment group the instance is part of to configure the log level settings. Reference this script as part of the Install lifecycle hook in the appspec.yml file.",
            "Tag the Amazon EC2 instances depending on the deployment group. Then place a script into the application revision that calls the metadata service and the EC2 API to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference the script as part of the AfterInstall lifecycle hook in the appspec.yml file."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 47,
        "text": "A company's application development team uses Linux-based Amazon EC2 instances as bastion hosts. Inbound SSH access to the bastion hosts is restricted to specific IP addresses, as defined in the associated security groups. The company's security team wants to receive a notification if the security group rules are modified to allow SSH access from any IP address.What should a DevOps engineer do to meet this requirement?",
        "options": [
            "Enable Amazon Inspector. Include the Common Vulnerabilities and Exposures-1.1 rules package to check the security groups that are associated with the bastion hosts. Configure Amazon Inspector to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic.",
            "Create an AWS Config rule by using the restricted-ssh managed rule to check whether security groups disallow unrestricted incoming SSH traffic. Configure automatic remediation to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic.",
            "Create an Amazon EventBridge rule with a source of aws.cloudtrail and the event name AuthorizeSecurityGroupIngress. Define an Amazon Simple Notification Service (Amazon SNS) topic as the target.",
            "Enable Amazon GuardDuty and check the findings for security groups in AWS Security Hub. Configure an Amazon EventBridge rule with a custom pattern that matches GuardDuty events with an output of NON_COMPLIANT. Define an Amazon Simple Notification Service (Amazon SNS) topic as the target."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 48,
        "text": "To run an application, a DevOps engineer launches an Amazon EC2 instance with public IP addresses in a public subnet. A user data script obtains the application artifacts and installs them on the instances upon launch. A change to the security classification of the application now requires the instances to run with no access to the internet. While the instances launch successfully and show as healthy, the application does not seem to be installed.Which of the following should successfully install the application while complying with the new rule?",
        "options": [
            "Publish the application artifacts to an Amazon S3 bucket and create a VPC endpoint for S3. Assign an IAM instance profile to the EC2 instances so they can read the application artifacts from the S3 bucket.",
            "Launch the instances in a public subnet with Elastic IP addresses attached. Once the application is installed and running, run a script to disassociate the Elastic IP addresses afterwards.",
            "Set up a NAT gateway. Deploy the EC2 instances to a private subnet. Update the private subnet's route table to use the NAT gateway as the default route.",
            "Create a security group for the application instances and allow only outbound traffic to the artifact repository. Remove the security group rule once the install is complete."
        ],
        "correct": [
            0
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 49,
        "text": "A company uses AWS Organizations to manage multiple accounts. Information security policies require that all unencrypted Amazon EBS volumes be marked as non-compliant. A DevOps engineer needs to automatically deploy the solution and ensure that this compliance check is always present.Which solution will accomplish this?",
        "options": [
            "Create an AWS CloudFormation template that defines an AWS Inspector rule to check whether EBS encryption is enabled. Save the template to an Amazon S3 bucket that has been shared with all accounts within the company. Update the account creation script pointing to the CloudFormation template in Amazon S3.",
            "Create an SCP in Organizations. Set the policy to prevent the launch of Amazon EC2 instances without encryption on the EBS volumes using a conditional expression. Apply the SCP to all AWS accounts. Use Amazon Athena to analyze the AWS CloudTrail output, looking for events that deny an ec2:RunInstances action.",
            "Create an AWS Config organizational rule to check whether EBS encryption is enabled and deploy the rule using the AWS CLI. Create and apply an SCP to prohibit stopping and deleting AWS Config across the organization.",
            "Deploy an IAM role to all accounts from a single trusted account. Build a pipeline with AWS CodePipeline with a stage in AWS Lambda to assume the IAM role, and list all EBS volumes in the account. Publish a report to Amazon S3."
        ],
        "correct": [
            2
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 50,
        "text": "A company is using an Amazon Aurora cluster as the data store for its application. The Aurora cluster is configured with a single DB instance. The application performs read and write operations on the database by using the cluster's instance endpoint.The company has scheduled an update to be applied to the cluster during an upcoming maintenance window. The cluster must remain available with the least possible interruption during the maintenance window.What should a DevOps engineer do to meet these requirements?",
        "options": [
            "Add a reader instance to the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.",
            "Add a reader instance to the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads.",
            "Turn on the Multi-AZ option on the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster‚Äôs reader endpoint for reads.",
            "Turn on the Multi-AZ option on the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations"
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 51,
        "text": "A company's developers use Amazon EC2 instances as remote workstations. The company is concerned that users can create or modify EC2 security groups to allow unrestricted inbound access.A DevOps engineer needs to develop a solution to detect when users create unrestricted security group rules. The solution must detect changes to security group rules in near real time, remove unrestricted rules, and send email notifications to the security team. The DevOps engineer has created an AWS Lambda function that checks for security group ID from input, removes rules that grant unrestricted access, and sends notifications through Amazon Simple Notification Service (Amazon SNS).What should the DevOps engineer do next to meet the requirements?",
        "options": [
            "Create an Amazon EventBridge custom event bus that subscribes to events from all AWS services. Configure the Lambda function to be invoked by the custom event bus.",
            "Configure the Lambda function to be invoked by the SNS topic. Create an AWS CloudTrail subscription for the SNS topic. Configure a subscription filter for security group modification events.",
            "Create an Amazon EventBridge scheduled rule to invoke the Lambda function. Define a schedule pattern that runs the Lambda function every hour.",
            "Create an Amazon EventBridge event rule that has the default event bus as the source. Define the rule‚Äôs event pattern to match EC2 security group creation and modification events. Configure the rule to invoke the Lambda function."
        ],
        "correct": [
            3
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 52,
        "text": "A company has a single AWS account that runs hundreds of Amazon EC2 instances in a single AWS Region. New EC2 instances are launched and terminated each hour in the account. The account also includes existing EC2 instances that have been running for longer than a week.The company's security policy requires all running EC2 instances to use an EC2 instance profile. If an EC2 instance does not have an instance profile attached, the EC2 instance must use a default instance profile that has no IAM permissions assigned.A DevOps engineer reviews the account and discovers EC2 instances that are running without an instance profile. During the review, the DevOps engineer also observes that new EC2 instances are being launched without an instance profile.Which solution will ensure that an instance profile is attached to all existing and future EC2 instances in the Region?",
        "options": [
            "Configure an Amazon EventBridge rule that reacts to EC2 StartInstances API calls. Configure the rule to invoke an AWS Systems Manager Automation runbook to attach the default instance profile to the EC2 instances",
            "Configure the ec2-instance-profile-attached AWS Config managed rule with a trigger type of configuration changes. Configure an automatic remediation action that invokes an AWS Systems Manager Automation runbook to attach the default instance profile to the EC2 instances.",
            "Configure the iam-role-managed-policy-check AWS Config managed rule with a trigger type of configuration changes. Configure an automatic remediation action that invokes an AWS Lambda function to attach the default instance profile to the EC2 instances.",
            "Configure an Amazon EventBridge rule that reacts to EC2 RunInstances API calls. Configure the rule to invoke an AWS Lambda function to attach the default instance profile to the EC2 instances."
        ],
        "correct": [
            1
        ],
        "type": "single",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    },
    {
        "id": 53,
        "text": "A company is performing vulnerability scanning for all Amazon EC2 instances across many accounts. The accounts are in an organization in AWS Organizations. Each account's VPCs are attached to a shared transit gateway. The VPCs send traffic to the internet through a central egress VPC. The company has enabled Amazon Inspector in a delegated administrator account and has enabled scanning for all member accounts.A DevOps engineer discovers that some EC2 instances are listed in the \"not scanning\" tab in Amazon Inspector.Which combination of actions should the DevOps engineer take to resolve this issue? (Choose three.)",
        "options": [
            "Grant inspector:StartAssessmentRun permissions to the IAM role that the DevOps engineer is using.",
            "Create a managed-instance activation. Use the Activation Code and the Activation ID to register the EC2 instances.",
            "Associate the target EC2 instances with instance profiles that grant permissions to communicate with AWS Systems Manager.",
            "Configure EC2 Instance Connect for the EC2 instances that Amazon Inspector is not scanning.",
            "Associate the target EC2 instances with security groups that allow outbound communication on port 443 to the AWS Systems Manager service endpoint.",
            "Verify that AWS Systems Manager Agent is installed and is running on the EC2 instances that Amazon Inspector is not scanning."
        ],
        "correct": [
            2,
            4,
            5
        ],
        "type": "multiple",
        "explanation": "ƒê√°p √°n ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t trong c·ªông ƒë·ªìng. Xem th√™m gi·∫£i th√≠ch trong file g·ªëc."
    }
];

        // const questions = await fetch('data.json').json();

        let currentQuestionIndex = 0;
        let userAnswers = [];
        let startTime = Date.now();
        let timer;

        function initializeApp() {
            document.getElementById('totalQuestions').textContent = questions.length;
            loadQuestion();
            startTimer();
            updateStats();
        }

        function loadQuestion() {
            const question = questions[currentQuestionIndex];
            document.getElementById('questionText').innerHTML = `
                <strong>C√¢u ${question.id}:</strong><br><br>
                ${question.text}
            `;
            
            // Set question type indicator
            const typeElement = document.getElementById('questionType');
            if (question.type === 'multiple') {
                typeElement.textContent = `Multiple Choice (Choose ${question.correct.length})`;
                typeElement.style.background = '#fff3cd';
                typeElement.style.color = '#856404';
            } else {
                typeElement.textContent = 'Single Choice';
                typeElement.style.background = '#e3f2fd';
                typeElement.style.color = '#1976d2';
            }
            
            const optionsContainer = document.getElementById('optionsContainer');
            optionsContainer.innerHTML = '';
            
            question.options.forEach((option, index) => {
                const optionDiv = document.createElement('div');
                optionDiv.className = 'option';
                optionDiv.innerHTML = `
                    <strong>${String.fromCharCode(65 + index)}.</strong> ${option}
                    ${question.type === 'multiple' ? '<input type="checkbox" class="option-checkbox">' : ''}
                `;
                
                if (question.type === 'multiple') {
                    optionDiv.onclick = () => toggleMultipleOption(index);
                } else {
                    optionDiv.onclick = () => selectSingleOption(index);
                }
                
                optionDiv.dataset.index = index;
                optionsContainer.appendChild(optionDiv);
            });

            document.getElementById('currentQuestion').textContent = currentQuestionIndex + 1;
            document.getElementById('submitBtn').disabled = true;
            document.getElementById('nextBtn').disabled = true;
            updateProgressBar();
        }

        function selectSingleOption(index) {
            document.querySelectorAll('.option').forEach(opt => opt.classList.remove('selected'));
            document.querySelector(`[data-index="${index}"]`).classList.add('selected');
            document.getElementById('submitBtn').disabled = false;
        }

        function toggleMultipleOption(index) {
            const option = document.querySelector(`[data-index="${index}"]`);
            const checkbox = option.querySelector('.option-checkbox');
            
            if (option.classList.contains('selected')) {
                option.classList.remove('selected');
                checkbox.checked = false;
            } else {
                option.classList.add('selected');
                checkbox.checked = true;
            }
            
            // Enable submit if at least one option is selected
            const selectedCount = document.querySelectorAll('.option.selected').length;
            document.getElementById('submitBtn').disabled = selectedCount === 0;
        }

        function getSelectedAnswers() {
            const question = questions[currentQuestionIndex];
            const selected = [];
            
            document.querySelectorAll('.option.selected').forEach(opt => {
                selected.push(parseInt(opt.dataset.index));
            });
            
            return selected.sort((a, b) => a - b); // Sort for comparison
        }

        function submitAnswer() {
            const selectedAnswers = getSelectedAnswers();
            if (selectedAnswers.length === 0) return;

            const question = questions[currentQuestionIndex];
            const correctAnswers = [...question.correct].sort((a, b) => a - b);
            
            // Calculate correctness
            let isCorrect = false;
            let isPartial = false;
            
            if (question.type === 'single') {
                isCorrect = selectedAnswers.length === 1 && selectedAnswers[0] === correctAnswers[0];
            } else {
                // Multiple choice scoring
                const selectedSet = new Set(selectedAnswers);
                const correctSet = new Set(correctAnswers);
                
                if (selectedAnswers.length === correctAnswers.length && 
                    selectedAnswers.every(ans => correctSet.has(ans))) {
                    isCorrect = true;
                } else {
                    // Partial credit if some answers are correct
                    const correctSelected = selectedAnswers.filter(ans => correctSet.has(ans));
                    const incorrectSelected = selectedAnswers.filter(ans => !correctSet.has(ans));
                    
                    if (correctSelected.length > 0 && incorrectSelected.length === 0) {
                        isPartial = true; // Selected some correct, no incorrect
                    }
                }
            }

            userAnswers[currentQuestionIndex] = {
                questionId: question.id,
                selected: selectedAnswers,
                correct: correctAnswers,
                isCorrect: isCorrect,
                isPartial: isPartial,
                timeSpent: Date.now() - startTime,
                type: question.type
            };

            // Show results
            document.querySelectorAll('.option').forEach((opt, index) => {
                const isSelectedCorrect = correctAnswers.includes(index);
                const isSelectedByUser = selectedAnswers.includes(index);
                
                if (isSelectedCorrect) {
                    opt.classList.add('correct');
                } else if (isSelectedByUser) {
                    opt.classList.add('incorrect');
                }
                
                opt.onclick = null; // Disable clicking
            });

            // Show explanation
            const explanationDiv = document.createElement('div');
            let resultClass = 'incorrect';
            let resultText = '‚ùå Sai r·ªìi!';
            
            if (isCorrect) {
                resultClass = 'correct';
                resultText = '‚úÖ Ch√≠nh x√°c!';
            } else if (isPartial) {
                resultClass = 'partial';
                resultText = '‚ö†Ô∏è ƒê√∫ng m·ªôt ph·∫ßn!';
            }
            
            explanationDiv.className = `explanation ${resultClass}`;
            explanationDiv.innerHTML = `
                <strong>${resultText}</strong><br>
                <strong>ƒê√°p √°n ƒë√∫ng:</strong> ${correctAnswers.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                <strong>B·∫°n ch·ªçn:</strong> ${selectedAnswers.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                <em>Gi·∫£i th√≠ch:</em> ${question.explanation}
            `;
            document.getElementById('optionsContainer').appendChild(explanationDiv);

            document.getElementById('submitBtn').style.display = 'none';
            document.getElementById('nextBtn').disabled = false;
            updateStats();
        }

        function nextQuestion() {
            if (currentQuestionIndex < questions.length - 1) {
                currentQuestionIndex++;
                loadQuestion();
                document.getElementById('submitBtn').style.display = 'inline-block';
            } else {
                showReview();
            }
        }

        function previousQuestion() {
            if (currentQuestionIndex > 0) {
                currentQuestionIndex--;
                loadQuestion();
                document.getElementById('submitBtn').style.display = 'inline-block';
            }
        }

        function updateStats() {
            const answered = userAnswers.filter(a => a).length;
            const correct = userAnswers.filter(a => a && a.isCorrect).length;
            const partial = userAnswers.filter(a => a && a.isPartial).length;
            const accuracy = answered > 0 ? Math.round(((correct + partial * 0.5) / answered) * 100) : 0;

            document.getElementById('correctCount').textContent = correct + (partial > 0 ? ` (+${partial} partial)` : '');
            document.getElementById('wrongCount').textContent = answered - correct - partial;
            document.getElementById('accuracy').textContent = accuracy + '%';
        }

        function updateProgressBar() {
            const progress = ((currentQuestionIndex + 1) / questions.length) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        }

        function startTimer() {
            timer = setInterval(() => {
                const elapsed = Math.floor((Date.now() - startTime) / 1000);
                const minutes = Math.floor(elapsed / 60);
                const seconds = elapsed % 60;
                document.getElementById('timeSpent').textContent = 
                    `${minutes}:${seconds.toString().padStart(2, '0')}`;
            }, 1000);
        }

        function showReview() {
            clearInterval(timer);
            document.getElementById('studyMode').classList.add('hidden');
            document.getElementById('reviewMode').classList.remove('hidden');

            const correct = userAnswers.filter(a => a.isCorrect).length;
            const partial = userAnswers.filter(a => a.isPartial).length;
            const total = userAnswers.length;
            const accuracy = Math.round(((correct + partial * 0.5) / total) * 100);

            document.getElementById('reviewStats').innerHTML = `
                <div class="stats">
                    <div class="stat-card">
                        <div class="stat-number">${correct}/${total}</div>
                        <div>Ho√†n to√†n ƒë√∫ng</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">${partial}</div>
                        <div>ƒê√∫ng m·ªôt ph·∫ßn</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">${accuracy}%</div>
                        <div>ƒêi·ªÉm t·ªïng</div>
                    </div>
                </div>
            `;

            // Show wrong answers for review
            const wrongAnswers = userAnswers.filter(a => !a.isCorrect);
            if (wrongAnswers.length > 0) {
                document.getElementById('wrongAnswers').innerHTML = `
                    <h3>üîÑ C√¢u c·∫ßn √¥n l·∫°i (${wrongAnswers.length} c√¢u):</h3>
                    ${wrongAnswers.map(a => `
                        <div class="wrong-answer">
                            <strong>C√¢u ${a.questionId} (${a.type === 'multiple' ? 'Multiple' : 'Single'} Choice):</strong><br>
                            B·∫°n ch·ªçn: ${a.selected.map(i => String.fromCharCode(65 + i)).join(', ')}<br>
                            ƒê√°p √°n ƒë√∫ng: ${a.correct.map(i => String.fromCharCode(65 + i)).join(', ')}
                            ${a.isPartial ? ' <span style="color: #856404;">(ƒê√∫ng m·ªôt ph·∫ßn)</span>' : ''}
                        </div>
                    `).join('')}
                `;
            }
        }

        function restartStudy() {
            currentQuestionIndex = 0;
            userAnswers = [];
            startTime = Date.now();
            document.getElementById('studyMode').classList.remove('hidden');
            document.getElementById('reviewMode').classList.add('hidden');
            initializeApp();
        }

        function exportResults() {
            const results = {
                date: new Date().toLocaleDateString('vi-VN'),
                day: 1,
                questions: questions.length,
                correct: userAnswers.filter(a => a.isCorrect).length,
                partial: userAnswers.filter(a => a.isPartial).length,
                accuracy: Math.round(((userAnswers.filter(a => a.isCorrect).length + userAnswers.filter(a => a.isPartial).length * 0.5) / userAnswers.length) * 100),
                wrongQuestions: userAnswers.filter(a => !a.isCorrect).map(a => ({
                    id: a.questionId,
                    type: a.type,
                    selected: a.selected,
                    correct: a.correct,
                    isPartial: a.isPartial
                })),
                timeSpent: document.getElementById('timeSpent').textContent
            };

            const blob = new Blob([JSON.stringify(results, null, 2)], {type: 'application/json'});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `aws-devops-results-${new Date().toISOString().split('T')[0]}.json`;
            a.click();
        }

        // Initialize app when page loads
        window.onload = initializeApp;
    </script>
</body>
</html>
